// GourmetChat.astro - ã‚°ãƒ«ãƒ¡ã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
export interface Props {
  apiBaseUrl?: string;
}

const { apiBaseUrl = '' } = Astro.props;
---

<div class="gourmet-chat-container" data-api-base={apiBaseUrl}>
  <div class="splash-overlay" id="splashOverlay">
    <video id="splashVideo" class="splash-video" autoplay muted playsinline loop>
      <source src="/splash.mp4" type="video/mp4">
    </video>
    <div class="splash-loading"><div class="spinner"></div><p>æº–å‚™ä¸­...</p></div>
  </div>

  <div class="wait-overlay hidden" id="waitOverlay">
    <div class="wait-content">
      <video id="waitVideo" class="wait-video" muted playsinline loop>
        <source src="/wait.mp4" type="video/mp4">
      </video>
      <p class="wait-text">AIãŒãŠåº—ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™...</p>
    </div>
  </div>

  <div class="language-selector">
    <select id="languageSelect" class="language-dropdown">
      <option value="ja">æ—¥æœ¬èª (Japanese)</option>
      <option value="en">English</option>
      <option value="zh">ä¸­æ–‡ (Chinese)</option>
      <option value="ko">í•œêµ­ì–´ (Korean)</option>
    </select>
  </div>

  <div class="voice-status stopped" id="voiceStatus">ğŸ¤ éŸ³å£°èªè­˜: åœæ­¢ä¸­</div>
  <div class="chat-area" id="chatArea"></div>

  <div class="input-area">
    <div class="input-group">
      <input type="text" id="userInput" placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..." disabled />
      <button class="btn btn-icon btn-speaker" id="speakerBtn" title="éŸ³å£°èª­ã¿ä¸Šã’ON" disabled>ğŸ”Š</button>
      <button class="btn" id="sendBtn" disabled>é€ä¿¡</button>
    </div>
    <div class="input-actions">
      <button class="btn btn-reservation" id="reservationBtn" disabled>ğŸ“ äºˆç´„ä¾é ¼ã™ã‚‹</button>
    </div>
  </div>
  
  <div class="floating-buttons">
    <button class="btn-floating btn-stop" id="stopBtn" title="ä¸­æ­¢"></button>
    <button class="btn-floating btn-mic-float" id="micBtnFloat" title="éŸ³å£°å…¥åŠ›" disabled></button>
  </div>
</div>

<style>
  .gourmet-chat-container { background: white; border-radius: 16px; box-shadow: 0 20px 60px rgba(0,0,0,0.15); width: 100%; max-width: 800px; max-height: 600px; display: flex; flex-direction: column; overflow: hidden; margin: 0 auto; position: relative; }
  .language-selector { padding: 12px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); display: flex; justify-content: flex-end; align-items: center; }
  .language-dropdown { padding: 6px 12px; border: 2px solid white; border-radius: 20px; background: rgba(255,255,255,0.95); color: #667eea; font-size: 13px; font-weight: 600; cursor: pointer; outline: none; transition: all 0.2s; }
  .language-dropdown:hover { background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.15); }
  .language-dropdown:focus { border-color: #fbbf24; }
  .chat-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; text-align: center; }
  .chat-header h2 { font-size: 20px; font-weight: 600; margin: 0 0 4px 0; }
  .chat-header p { font-size: 13px; opacity: 0.9; margin: 0; }
  .voice-status { padding: 10px 15px; text-align: center; font-size: 12px; border-bottom: 1px solid #e0e0e0; font-weight: 500; }
  .voice-status.listening { background: #e8f5e9; color: #2e7d32; animation: pulse 2s infinite; }
  .voice-status.stopped { background: #ffebee; color: #c62828; }
  .voice-status.speaking { background: #e1f5fe; color: #0277bd; animation: pulse 2s infinite; }
  @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.8; } }
  .chat-area { flex: 1; overflow-y: auto; padding: 20px; background: #f7f9fc; min-height: 300px; }
  .message { margin-bottom: 16px; display: flex; gap: 10px; }
  .message.assistant { flex-direction: row; }
  .message.user { flex-direction: row-reverse; }
  .message.system { justify-content: center; }
  .message-avatar { width: 36px; height: 36px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 16px; flex-shrink: 0; }
  .message.assistant .message-avatar { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
  .message.user .message-avatar { background: #e0e7ff; color: #667eea; }
  .message.system .message-avatar { background: #fff3e0; color: #f57c00; }
  .message-content { max-width: 70%; padding: 10px 14px; border-radius: 12px; line-height: 1.5; font-size: 14px; white-space: pre-wrap; }
  .message.assistant .message-content { background: white; border: 1px solid #e5e7eb; color: #1f2937; }
  .message.user .message-content { background: #667eea; color: white; }
  .message.system .message-content { background: #fff3e0; color: #e65100; font-size: 12px; }
  .summary-box { margin-top: 10px; padding: 10px; background: #fef3c7; border-left: 4px solid #f59e0b; border-radius: 8px; font-size: 13px; color: #92400e; }
  .summary-box strong { display: block; margin-bottom: 6px; color: #78350f; }
  .final-summary { margin: 16px 0; padding: 16px; background: white; border: 2px solid #10b981; border-radius: 12px; }
  .final-summary h3 { color: #065f46; margin: 0 0 10px 0; font-size: 16px; }
  .final-summary-content { white-space: pre-wrap; line-height: 1.7; color: #1f2937; font-size: 13px; }
  .input-area { padding: 16px; background: white; border-top: 1px solid #e5e7eb; }
  .input-group { display: flex; gap: 10px; align-items: center; margin-bottom: 10px; }
  #userInput { flex: 1; padding: 10px 14px; border: 2px solid #e5e7eb; border-radius: 20px; font-size: 14px; outline: none; transition: border-color 0.2s; }
  #userInput:focus { border-color: #667eea; }
  .btn { padding: 10px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 20px; font-size: 14px; font-weight: 600; cursor: pointer; transition: transform 0.2s, box-shadow 0.2s; }
  .btn:hover:not(:disabled) { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4); }
  .btn:disabled { opacity: 0.5; cursor: not-allowed; }
  .btn-reservation { background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; font-size: 13px; padding: 10px 16px; font-weight: 600; box-shadow: 0 4px 12px rgba(245, 158, 11, 0.3); }
  .btn-reservation:hover:not(:disabled) { box-shadow: 0 6px 16px rgba(245, 158, 11, 0.4); transform: translateY(-1px); }
  .btn-reservation:disabled { opacity: 0.5; cursor: not-allowed; }
  .btn-icon { padding: 10px; width: 40px; height: 40px; display: flex; align-items: center; justify-content: center; }
  .btn-mic { background: #10b981; }
  .btn-mic:hover:not(:disabled) { box-shadow: 0 4px 12px rgba(16, 185, 129, 0.4); }
  .btn-mic.recording { background: #ef4444; animation: pulse-btn 1.5s infinite; }
  @keyframes pulse-btn { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
  .btn-speaker { background: #f59e0b; }
  .btn-speaker:hover:not(:disabled) { box-shadow: 0 4px 12px rgba(245, 158, 11, 0.4); }
  .btn-speaker.disabled { background: #9ca3af; }
  .input-actions { display: flex; justify-content: flex-end; }
  .loading { display: inline-block; width: 20px; height: 20px; border: 3px solid #e5e7eb; border-radius: 50%; border-top-color: #667eea; animation: spin 1s ease-in-out infinite; }
  @keyframes spin { to { transform: rotate(360deg); } }
  .error-message { background: #fee2e2; color: #b91c1c; padding: 10px; border-radius: 8px; margin: 10px 0; font-size: 13px; text-align: center; }
  .splash-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; justify-content: center; z-index: 9999; border-radius: 16px; overflow: hidden; transition: opacity 0.8s ease-out; pointer-events: all; }
  .splash-overlay.fade-out { opacity: 0; pointer-events: none; }
  .splash-overlay.hidden { display: none; }
  .splash-video { width: 100%; height: 100%; object-fit: contain; position: absolute; top: 0; left: 0; transform: scale(0.5); }
  .splash-loading { position: absolute; bottom: 60px; display: flex; flex-direction: column; align-items: center; gap: 12px; z-index: 1; }
  .splash-loading .spinner { width: 40px; height: 40px; border: 4px solid rgba(102, 126, 234, 0.3); border-top-color: #667eea; border-radius: 50%; animation: spin 1s linear infinite; }
  .splash-loading p { color: #667eea; font-size: 14px; font-weight: 600; margin: 0; text-shadow: 0 1px 2px rgba(255, 255, 255, 0.8); }
  .click-prompt { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); background: rgba(0, 0, 0, 0.8); color: white; padding: 20px; border-radius: 12px; text-align: center; z-index: 100; cursor: pointer; }
  .click-prompt p { margin: 5px 0; }
  .wait-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: rgba(255, 255, 255, 0.95); z-index: 500; display: flex; align-items: center; justify-content: center; border-radius: 16px; opacity: 1; transition: opacity 0.5s ease-out, visibility 0.5s; }
  .wait-overlay.hidden { opacity: 0; visibility: hidden; pointer-events: none; }
  .wait-content { text-align: center; width: 80%; max-width: 400px; }
  .wait-video { width: 100%; border-radius: 12px; box-shadow: 0 8px 30px rgba(0,0,0,0.1); margin-bottom: 16px; }
  .wait-text { color: #667eea; font-weight: 600; font-size: 14px; animation: pulse 1.5s infinite; }
  
  .floating-buttons {
    position: fixed;
    bottom: 20px;
    right: 20px;
    display: flex;
    gap: 12px;
    z-index: 1000;
    transition: bottom 0.3s ease;
  }
  
  .floating-buttons.keyboard-active {
    bottom: 320px;
  }
  
  @media (max-width: 768px) {
    .floating-buttons.keyboard-active {
      bottom: 280px;
    }
  }
  
  .btn-floating {
    width: 56px;
    height: 56px;
    border-radius: 50%;
    border: none;
    font-size: 24px;
    cursor: pointer;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    transition: transform 0.2s, box-shadow 0.2s;
  }
  
  .btn-floating:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
  }
  
  .btn-floating:active {
    transform: translateY(0);
  }
  
  .btn-stop {
    background: linear-gradient(135deg, #ff3b30 0%, #d32f2f 100%);
    color: white;
    position: relative;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  
  .btn-stop::before {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    background: url('/stop.svg') center/60% no-repeat;
  }
  
  .btn-mic-float {
    background: transparent;
    color: white;
    position: relative;
    display: flex;
    align-items: center;
    justify-content: center;
    overflow: visible;
    box-shadow: none;
  }
  
  .btn-mic-float::before {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    background: url('/mic-off.svg') center/100% no-repeat;
  }
  
  .btn-mic-float:disabled {
    cursor: not-allowed;
    opacity: 0.6;
  }
  
  .btn-mic-float:disabled::before {
    opacity: 0.5;
  }
  
  .btn-mic-float.recording {
    background: transparent;
  }
  
  .btn-mic-float.recording::before {
    background: url('/mic-on.svg') center/100% no-repeat;
  }
  
  .btn-mic-float.recording::after {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    border-radius: 50%;
    border: 3px solid #42A5F5;
    opacity: 0;
    animation: ripple 1.5s ease-out infinite;
  }
  
  @keyframes ripple {
    0% {
      transform: scale(1);
      opacity: 0.8;
    }
    100% {
      transform: scale(1.8);
      opacity: 0;
    }
  }
</style>

<script src="https://cdn.socket.io/4.7.2/socket.io.min.js"></script>

<script>
  // i18nã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å‹•çš„ã«å‡¦ç†
  let i18n;
  try {
    i18n = (await import('../constants/i18n')).i18n;
  } catch (e) {
    console.error('Failed to load i18n:', e);
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æœ€å°é™ã®i18n
    i18n = {
      ja: {
        voiceStatusStopped: 'ğŸ¤ éŸ³å£°èªè­˜: åœæ­¢ä¸­',
        inputPlaceholder: 'ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...',
        btnVoiceInput: 'éŸ³å£°å…¥åŠ›',
        btnTTSOn: 'éŸ³å£°èª­ã¿ä¸Šã’ON',
        btnTTSOff: 'éŸ³å£°èª­ã¿ä¸Šã’OFF',
        btnSend: 'é€ä¿¡',
        btnReservation: 'ğŸ“ äºˆç´„ä¾é ¼ã™ã‚‹',
        waitMessage: 'AIãŒãŠåº—ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™...',
        pageTitle: 'ã‚°ãƒ«ãƒ¡AIãƒãƒ£ãƒƒãƒˆ',
        pageSubtitle: 'ãŠåº—ã‚’æ¢ã—ã¦ãŠæ‰‹ä¼ã„ã—ã¾ã™',
        shopListTitle: 'ãŠã™ã™ã‚ã®ãŠåº—',
        shopListEmpty: 'ãŠåº—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ',
        footerMessage: 'Powered by AI',
        clickPrompt: 'ã‚¿ãƒƒãƒ—ã—ã¦éŸ³å£°ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„',
        initialGreeting: 'ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ¢ã—ã§ã™ã‹ï¼Ÿ',
        ackConfirm: 'ã‹ã—ã“ã¾ã‚Šã¾ã—ãŸ',
        ackSearch: 'ãŠåº—ã‚’æ¢ã—ã¾ã™ã­',
        ackUnderstood: 'ç†è§£ã—ã¾ã—ãŸ',
        ackYes: 'ã¯ã„',
        ttsIntro: 'ã”å¸Œæœ›ã«åˆã†ãŠåº—ã‚’ã”ç´¹ä»‹ã—ã¾ã™',
        dateWarningMsg: 'æ—¥æ™‚ã«é–¢ã™ã‚‹ã”è³ªå•ã«ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“',
        shortMsgWarning: 'ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ãã ã•ã„',
        fallbackResponse: (text) => `${text}ã«ã¤ã„ã¦ã§ã™ã­ã€‚è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚`,
        additionalResponse: 'ä»–ã«ã”å¸Œæœ›ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ',
        micAccessError: 'ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“',
        sttError: 'éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼',
        recordingTimeLimit: 'éŒ²éŸ³æ™‚é–“ã®ä¸Šé™ã«é”ã—ã¾ã—ãŸ',
        voiceStatusListening: 'ğŸ¤ éŸ³å£°èªè­˜ä¸­...',
        voiceStatusRecording: 'ğŸ¤ éŒ²éŸ³ä¸­...',
        voiceStatusWaiting: 'ğŸ¤ å¾…æ©Ÿä¸­...',
        voiceStatusRecognizing: 'ğŸ¤ èªè­˜ä¸­...',
        voiceStatusSynthesizing: 'ğŸ”Š éŸ³å£°åˆæˆä¸­...',
        voiceStatusSpeaking: 'ğŸ”Š éŸ³å£°å†ç”Ÿä¸­...',
        voiceStatusComplete: 'âœ… èªè­˜å®Œäº†',
        searchError: 'æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“'
      },
      en: {
        voiceStatusStopped: 'ğŸ¤ Voice Recognition: Stopped',
        inputPlaceholder: 'Type a message...',
        btnVoiceInput: 'Voice Input',
        btnTTSOn: 'TTS ON',
        btnTTSOff: 'TTS OFF',
        btnSend: 'Send',
        btnReservation: 'ğŸ“ Make Reservation',
        waitMessage: 'AI is searching for restaurants...',
        pageTitle: 'Gourmet AI Chat',
        pageSubtitle: 'Helping you find restaurants',
        shopListTitle: 'Recommended Restaurants',
        shopListEmpty: 'No restaurants found',
        footerMessage: 'Powered by AI',
        clickPrompt: 'Tap to enable audio',
        initialGreeting: 'Hello! What are you looking for?',
        ackConfirm: 'Understood',
        ackSearch: 'I will search for restaurants',
        ackUnderstood: 'Got it',
        ackYes: 'Yes',
        ttsIntro: 'Let me introduce restaurants that match your preferences',
        dateWarningMsg: 'I cannot answer questions about dates and times',
        shortMsgWarning: 'Please tell me more details',
        fallbackResponse: (text) => `About ${text}. Please tell me more.`,
        additionalResponse: 'Is there anything else?',
        micAccessError: 'Cannot access microphone',
        sttError: 'Speech recognition error',
        recordingTimeLimit: 'Recording time limit reached',
        voiceStatusListening: 'ğŸ¤ Listening...',
        voiceStatusRecording: 'ğŸ¤ Recording...',
        voiceStatusWaiting: 'ğŸ¤ Waiting...',
        voiceStatusRecognizing: 'ğŸ¤ Recognizing...',
        voiceStatusSynthesizing: 'ğŸ”Š Synthesizing...',
        voiceStatusSpeaking: 'ğŸ”Š Speaking...',
        voiceStatusComplete: 'âœ… Recognition complete',
        searchError: 'No search results'
      }
    };
  }

  const LANGUAGE_CODE_MAP = {
    ja: { tts: 'ja-JP', stt: 'ja-JP', voice: 'ja-JP-Chirp3-HD-Leda' },
    en: { tts: 'en-US', stt: 'en-US', voice: 'en-US-Studio-O' },
    zh: { tts: 'cmn-CN', stt: 'cmn-CN', voice: 'cmn-CN-Wavenet-A' },
    ko: { tts: 'ko-KR', stt: 'ko-KR', voice: 'ko-KR-Wavenet-A' }
  };

  document.addEventListener('DOMContentLoaded', async () => {
    const container = document.querySelector('.gourmet-chat-container') as HTMLElement;
    if (!container) return;

    const apiBase = container.dataset.apiBase || '';

    // ã‚¹ãƒ—ãƒ©ãƒƒã‚·ãƒ¥åˆ¶å¾¡
    const splashOverlay = document.getElementById('splashOverlay') as HTMLDivElement;
    const splashVideo = document.getElementById('splashVideo') as HTMLVideoElement;
    function hideSplash() {
      if (splashVideo) splashVideo.loop = false;
      if (splashOverlay) {
        splashOverlay.classList.add('fade-out');
        setTimeout(() => splashOverlay.classList.add('hidden'), 800);
      }
    }
    setTimeout(() => hideSplash(), 10000);

    // DOMè¦ç´ 
    const chatArea = document.getElementById('chatArea')!;
    const userInput = document.getElementById('userInput') as HTMLInputElement;
    const sendBtn = document.getElementById('sendBtn') as HTMLButtonElement;
    const speakerBtn = document.getElementById('speakerBtn') as HTMLButtonElement;
    const reservationBtn = document.getElementById('reservationBtn') as HTMLButtonElement;
    const voiceStatus = document.getElementById('voiceStatus')!;
    const languageSelect = document.getElementById('languageSelect') as HTMLSelectElement;
    const stopBtn = document.getElementById('stopBtn') as HTMLButtonElement;
    const micBtnFloat = document.getElementById('micBtnFloat') as HTMLButtonElement;
    const waitOverlay = document.getElementById('waitOverlay') as HTMLDivElement;
    const waitVideo = document.getElementById('waitVideo') as HTMLVideoElement;
    let waitOverlayTimer: number | null = null;

    // çŠ¶æ…‹å¤‰æ•°
    let currentLanguage: 'ja' | 'en' | 'zh' | 'ko' = 'ja';
    let sessionId: string | null = null;
    let isProcessing = false;
    let currentStage = 'conversation';
    let isRecording = false;
    let mediaRecorder: MediaRecorder | null = null;
    let audioChunks: Blob[] = [];
    let recordingTimer: number | null = null;
    const MAX_RECORDING_TIME = 55000;
    let isTTSEnabled = true;
    let isUserInteracted = false;
    let currentShops: any[] = [];
    let isFromVoiceInput = false;
    
    // ã‚¨ã‚³ãƒ¼å¯¾ç­–ï¼šChatã‚¢ãƒ—ãƒªç”¨ã«ã‚·ãƒ³ãƒ—ãƒ«åŒ–
    let lastAISpeech: string = '';
    let preGeneratedAcks: Map<string, string> = new Map();
    let audioContext: AudioContext | null = null;
    let analyser: AnalyserNode | null = null;
    let silenceTimer: number | null = null;
    let vadCheckInterval: number | null = null;
    let hasSpoken = false;
    let recordingStartTime = 0;
    let socket: any = null;
    let audioWorkletNode: AudioWorkletNode | null = null;
    let streamingTranscript = '';
    let isStreamingSTT = false;
    let isSendingAudio = true; // éŸ³å£°é€ä¿¡åˆ¶å¾¡ãƒ•ãƒ©ã‚°

    const ttsPlayer = new Audio();
    const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);
    const isAndroid = /Android/i.test(navigator.userAgent);
    const SILENCE_THRESHOLD = isIOS ? 30 : 35; // iPhone: 30, Android: 35
    const SILENCE_DURATION = isIOS ? 2500 : 2000; // iPhone: 2.5ç§’, Android: 2ç§’
    const MIN_RECORDING_TIME = 3000;
    
    // â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šç”»é¢ã«ãƒ­ã‚°è¡¨ç¤º â˜…â˜…â˜…
    function debugLog(message: string) {
      const debugDiv = document.getElementById('debugLog') || (() => {
        const div = document.createElement('div');
        div.id = 'debugLog';
        div.style.cssText = 'position: fixed; top: 0; left: 0; right: 0; background: rgba(0,0,0,0.9); color: lime; padding: 10px; max-height: 200px; overflow-y: auto; z-index: 99999; font-size: 11px; font-family: monospace;';
        document.body.appendChild(div);
        return div;
      })();
      const time = new Date().toLocaleTimeString();
      debugDiv.innerHTML = `[${time}] ${message}<br>` + debugDiv.innerHTML;
    }

    // --- ä¾¿åˆ©é–¢æ•°ç¾¤ ---

    function t(key: string, ...args: any[]): string {
      // @ts-ignore
      const translation = i18n[currentLanguage][key];
      if (typeof translation === 'function') return translation(...args);
      return translation || key;
    }

    (window as any).gourmetI18n = {
      i18n: i18n,
      getCurrentLanguage: () => currentLanguage,
      t: (key: string, ...args: any[]) => t(key, ...args)
    };

    function addMessage(role: string, content: string, summary: string | null = null, isInitial: boolean = false) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${role}`;
      if (isInitial) messageDiv.setAttribute('data-initial', 'true');
      const avatar = document.createElement('div');
      avatar.className = 'message-avatar';
      avatar.innerHTML = role === 'assistant' ? 'ğŸ½' : role === 'user' ? 'ğŸ‘¤' : 'âš ';
      const contentDiv = document.createElement('div');
      contentDiv.className = 'message-content';
      const messageText = document.createElement('span');
      messageText.className = 'message-text';
      messageText.textContent = content;
      contentDiv.appendChild(messageText);
      messageDiv.appendChild(avatar);
      const wrapper = document.createElement('div');
      wrapper.appendChild(contentDiv);
      if (summary) {
        const summaryDiv = document.createElement('div');
        summaryDiv.className = 'summary-box';
        summaryDiv.innerHTML = `<strong>ğŸ“ å†…å®¹ç¢ºèª</strong>${summary}`;
        wrapper.appendChild(summaryDiv);
      }
      messageDiv.appendChild(wrapper);
      chatArea.appendChild(messageDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showError(message: string) {
      const errorDiv = document.createElement('div');
      errorDiv.className = 'error-message';
      errorDiv.textContent = message;
      chatArea.appendChild(errorDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showWaitOverlay() {
      waitOverlay.classList.remove('hidden');
      if (waitVideo) {
        waitVideo.currentTime = 0;
        waitVideo.play().catch(e => console.log('Video err', e));
      }
    }

    function hideWaitOverlay() {
      if (waitOverlayTimer) { clearTimeout(waitOverlayTimer); waitOverlayTimer = null; }
      waitOverlay.classList.add('hidden');
      setTimeout(() => {
        if (waitVideo) waitVideo.pause();
      }, 500);
    }

    function unlockAudioParams() {
      ttsPlayer.play().then(() => { 
        ttsPlayer.pause(); 
        ttsPlayer.currentTime = 0; 
      }).catch(e => {});
    }

    function enableAudioPlayback() {
      if (!isUserInteracted) {
        isUserInteracted = true;
        const clickPrompt = container.querySelector('.click-prompt');
        if (clickPrompt) clickPrompt.remove();
        unlockAudioParams();
      }
    }

    function showClickPrompt() {
      const prompt = document.createElement('div');
      prompt.className = 'click-prompt';
      prompt.innerHTML = `<p>ğŸ”Š</p><p>${t('clickPrompt')}</p><p>ğŸ”Š</p>`;
      prompt.addEventListener('click', enableAudioPlayback);
      container.style.position = 'relative';
      container.appendChild(prompt);
    }

    function stopCurrentAudio() {
      ttsPlayer.pause();
      ttsPlayer.currentTime = 0;
    }

    function stripMarkdown(text: string): string {
      return text.replace(/\*\*([^*]+)\*\*/g, '$1')
                 .replace(/\*([^*]+)\*/g, '$1')
                 .replace(/__([^_]+)__/g, '$1')
                 .replace(/_([^_]+)_/g, '$1')
                 .replace(/^#+\s*/gm, '')
                 .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
                 .replace(/`([^`]+)`/g, '$1')
                 .replace(/^(\d+)\.\s+/gm, '$1ç•ªç›®ã€')
                 .replace(/\s+/g, ' ')
                 .trim();
    }

    // æ­£è¦åŒ–ï¼ˆã‚¨ã‚³ãƒ¼åˆ¤å®šç”¨ï¼šcore_logic.pyæ–¹å¼ï¼‰
    function normalizeText(text: string): string {
      // è¨˜å·ãƒ»ç©ºç™½ã‚’é™¤å»ã—ã€å°æ–‡å­—åŒ–
      return text.replace(/[!?,.ã€ã€‚\sã€€]/g, '').toLowerCase().trim();
    }

    function removeFillers(text: string): string {
      // @ts-ignore
      const pattern = i18n[currentLanguage].patterns?.fillers || /(ãˆãƒ¼ã¨|ã‚ã®|ã¾ã‚|ãã†ã§ã™ã­)/g;
      return text.replace(pattern, '');
    }

    function generateFallbackResponse(text: string): string {
      return t('fallbackResponse', text);
    }

    function selectSmartAcknowledgment(userMessage: string): { text: string, logText: string } {
      const messageLower = userMessage.trim();
      // @ts-ignore
      const p = i18n[currentLanguage].patterns || {};
      const ackQuestions = p.ackQuestions || /(ã©ã†ã—ã¦|ãªãœ|ã©ã†ã‚„ã£ã¦|æ•™ãˆã¦|èª¬æ˜)/;
      const ackLocation = p.ackLocation || /(è¿‘ã|å‘¨è¾º|ã‚¨ãƒªã‚¢|åœ°åŸŸ|å ´æ‰€)/;
      const ackSearch = p.ackSearch || /(æ¢ã—ã¦|æ¤œç´¢|ãŠã™ã™ã‚|æ•™ãˆã¦)/;
      
      if (ackQuestions.test(messageLower)) return { text: t('ackConfirm'), logText: `è³ªå•å½¢å¼` };
      if (ackLocation.test(messageLower)) return { text: t('ackSearch'), logText: `å ´æ‰€` };
      if (ackSearch.test(messageLower)) return { text: t('ackUnderstood'), logText: `æ¤œç´¢` };
      return { text: t('ackYes'), logText: `ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ` };
    }

    function extractShopsFromResponse(text: string): any[] {
      const shops: any[] = [];
      const pattern = /(\d+)\.\s*\*\*([^*]+)\*\*[ï¼š:]\s*([^\n]+)/g;
      let match;
      while ((match = pattern.exec(text)) !== null) {
        const fullName = match[2].trim();
        const description = match[3].trim();
        let name = fullName;
        const nameMatch = fullName.match(/^([^ï¼ˆ(]+)[ï¼ˆ(]([^ï¼‰)]+)[ï¼‰)]/);
        if (nameMatch) name = nameMatch[1].trim();
        const encodedName = encodeURIComponent(name);
        shops.push({ 
          name: name, 
          description: description, 
          category: 'ã‚¤ã‚¿ãƒªã‚¢ãƒ³', 
          hotpepper_url: `https://www.hotpepper.jp/SA11/srchRS/?keyword=${encodedName}`, 
          maps_url: `https://www.google.com/maps/search/${encodedName}`, 
          tabelog_url: `https://tabelog.com/rstLst/?vs=1&sa=&sk=${encodedName}` 
        });
      }
      return shops;
    }

    function updateUILanguage() {
      voiceStatus.innerHTML = t('voiceStatusStopped');
      userInput.placeholder = t('inputPlaceholder');
      micBtnFloat.title = t('btnVoiceInput');
      speakerBtn.title = isTTSEnabled ? t('btnTTSOn') : t('btnTTSOff');
      sendBtn.textContent = t('btnSend');
      reservationBtn.innerHTML = t('btnReservation');
      const waitText = document.querySelector('.wait-text');
      if (waitText) waitText.textContent = t('waitMessage');

      const pageTitle = document.getElementById('pageTitle');
      if (pageTitle) pageTitle.innerHTML = `<img src="/pwa-152x152.png" alt="Logo" class="app-logo" /> ${t('pageTitle')}`;
      const pageSubtitle = document.getElementById('pageSubtitle');
      if (pageSubtitle) pageSubtitle.textContent = t('pageSubtitle');
      const shopListTitle = document.getElementById('shopListTitle');
      if (shopListTitle) shopListTitle.innerHTML = `ğŸ½ ${t('shopListTitle')}`;
      const shopListEmpty = document.getElementById('shopListEmpty');
      if (shopListEmpty) shopListEmpty.textContent = t('shopListEmpty');
      const pageFooter = document.getElementById('pageFooter');
      if (pageFooter) pageFooter.innerHTML = `${t('footerMessage')} âœ¨`;

      const initialMessage = chatArea.querySelector('.message.assistant[data-initial="true"]');
      if (initialMessage) {
        const messageText = initialMessage.querySelector('.message-text');
        if (messageText) messageText.textContent = t('initialGreeting');
      }

      document.dispatchEvent(new CustomEvent('languageChange', { detail: { language: currentLanguage } }));
    }

    async function speakTextGCP(text: string, stopPrevious: boolean = true, autoRestartMic: boolean = false) {
      if (!isTTSEnabled || !text) return;
      if (stopPrevious) ttsPlayer.pause();
      
      const cleanText = stripMarkdown(text);

      try {
        // AIéŸ³å£°å†ç”Ÿé–‹å§‹
        isAISpeaking = true;
        // Android: ãƒã‚¤ã‚¯OFF
        if (isAndroid && isRecording) {
          stopStreamingSTT();
        }
        
        voiceStatus.innerHTML = t('voiceStatusSynthesizing');
        voiceStatus.className = 'voice-status speaking';
        const langConfig = LANGUAGE_CODE_MAP[currentLanguage];
        const response = await fetch(`${apiBase}/api/tts/synthesize`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ 
            text: cleanText, 
            language_code: langConfig.tts, 
            voice_name: langConfig.voice 
          })
        });
        const data = await response.json();
        if (data.success && data.audio) {
          ttsPlayer.src = `data:audio/mp3;base64,${data.audio}`;
          const playPromise = new Promise<void>((resolve) => {
            ttsPlayer.onended = async () => {
              voiceStatus.innerHTML = t('voiceStatusStopped');
              voiceStatus.className = 'voice-status stopped';
              // AIéŸ³å£°å†ç”Ÿçµ‚äº†
              isAISpeaking = false;
              
              // AIéŸ³å£°çµ‚äº†å¾Œï¼šãƒã‚¤ã‚¯è‡ªå‹•ONï¼ˆautoRestartMic=trueã®æ™‚ã®ã¿ï¼‰
              if (autoRestartMic) {
                if (isAndroid) {
                  try {
                    await startStreamingSTT();
                  } catch (error) {
                    showMicPrompt();
                  }
                } else if (!isRecording) {
                  // iPhone: ãƒã‚¤ã‚¯è‡ªå‹•ONã‚’è©¦ã¿ã‚‹
                  try {
                    await startStreamingSTT();
                  } catch (error) {
                    showMicPrompt();
                  }
                }
              }
              
              resolve();
            };
            ttsPlayer.onerror = () => { 
              // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚çµ‚äº†
              isAISpeaking = false;
              resolve(); 
            };
          });
          if (isUserInteracted) {
            lastAISpeech = normalizeText(cleanText);
            await ttsPlayer.play();
            await playPromise;
          } else {
            showClickPrompt();
            voiceStatus.innerHTML = t('voiceStatusStopped');
            voiceStatus.className = 'voice-status stopped';
            // å†ç”Ÿã—ãªã„å ´åˆã‚‚çµ‚äº†
            isAISpeaking = false;
          }
        } else {
          // å¤±æ•—æ™‚ã‚‚çµ‚äº†
          isAISpeaking = false;
        }
      } catch (error) {
        voiceStatus.innerHTML = t('voiceStatusStopped');
        voiceStatus.className = 'voice-status stopped';
        // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚çµ‚äº†
        isAISpeaking = false;
      }
    }

    // ãƒã‚¤ã‚¯ONä¿ƒé€²ãƒ¢ãƒ¼ãƒ€ãƒ«
    function showMicPrompt() {
      const modal = document.createElement('div');
      modal.id = 'mic-prompt-modal';
      modal.style.cssText = `
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: rgba(0, 0, 0, 0.8);
        display: flex;
        align-items: center;
        justify-content: center;
        z-index: 10000;
        animation: fadeIn 0.3s ease;
      `;
      
      modal.innerHTML = `
        <div style="
          background: white;
          border-radius: 16px;
          padding: 24px;
          max-width: 90%;
          width: 350px;
          text-align: center;
          box-shadow: 0 8px 32px rgba(0,0,0,0.3);
        ">
          <div style="font-size: 48px; margin-bottom: 16px;">ğŸ¤</div>
          <div style="font-size: 18px; font-weight: 700; margin-bottom: 8px; color: #333;">
            ãƒã‚¤ã‚¯ã‚’ONã«ã—ã¦ãã ã•ã„
          </div>
          <div style="font-size: 14px; color: #666; margin-bottom: 20px;">
            AIã®å›ç­”ãŒçµ‚ã‚ã‚Šã¾ã—ãŸã€‚<br>ç¶šã‘ã¦è©±ã™ã«ã¯ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’ã‚¿ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚
          </div>
          <button id="mic-prompt-btn" style="
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            color: white;
            border: none;
            padding: 14px 32px;
            border-radius: 24px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(16, 185, 129, 0.3);
          ">
            ğŸ¤ ãƒã‚¤ã‚¯ON
          </button>
        </div>
      `;
      
      const style = document.createElement('style');
      style.textContent = `
        @keyframes fadeIn {
          from { opacity: 0; }
          to { opacity: 1; }
        }
      `;
      document.head.appendChild(style);
      document.body.appendChild(modal);
      
      const btn = document.getElementById('mic-prompt-btn');
      btn?.addEventListener('click', async () => {
        modal.remove();
        await toggleRecording();
      });
      
      // 3ç§’å¾Œã«è‡ªå‹•ã§é–‰ã˜ã‚‹
      setTimeout(() => {
        if (document.getElementById('mic-prompt-modal')) {
          modal.remove();
        }
      }, 3000);
    }

    // --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° ---

    function stopVAD() {
      if (vadCheckInterval) { clearInterval(vadCheckInterval); vadCheckInterval = null; }
      if (silenceTimer) { clearTimeout(silenceTimer); silenceTimer = null; }
      if (audioContext) { 
        audioContext.close(); 
        audioContext = null; 
      }
      analyser = null;
      hasSpoken = false;
    }

    function autoStopRecording() {
      console.log('VAD Stop'); 
      stopVAD();
      if (mediaRecorder && mediaRecorder.state === 'recording') mediaRecorder.stop();
      if (recordingTimer) clearTimeout(recordingTimer);
      isRecording = false; 
      micBtnFloat.classList.remove('recording');
    }

    async function toggleRecording() {
      enableAudioPlayback();
      // AIè©±ä¸­ã§ã‚‚å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢
      userInput.value = '';
      
      stopCurrentAudio();
      if (isRecording) { 
        // ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã§åœæ­¢æ™‚ã‚‚ä¸­æ­¢å‡¦ç†ã‚’å®Ÿè¡Œ
        stopAllActivities();
        return; 
      }
      
      if (isStreamingSTT) { 
        await new Promise(r => setTimeout(r, 100));
        await startStreamingSTT(); 
      } else { 
        await startLegacyRecording();
      }
    }

    function toggleTTS() {
      if (!isUserInteracted) { 
        enableAudioPlayback();
        return; 
      }
      enableAudioPlayback();
      isTTSEnabled = !isTTSEnabled;
      speakerBtn.innerHTML = isTTSEnabled ? 'ğŸ”Š' : 'ğŸ”‡';
      speakerBtn.title = isTTSEnabled ? t('btnTTSOn') : t('btnTTSOff');
      speakerBtn.className = isTTSEnabled ? 'btn btn-icon btn-speaker' : 'btn btn-icon btn-speaker disabled';
      if (!isTTSEnabled) stopCurrentAudio();
    }

    let mediaStream: MediaStream | null = null;
    // ã‚°ãƒ­ãƒ¼ãƒãƒ«ã§ä¿æŒ

    // Androidåˆ¤å®š
    console.log('[ãƒ‡ãƒã‚¤ã‚¹åˆ¤å®š] isAndroid:', isAndroid);
    // AIéŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°
    let isAISpeaking = false;
    // AIéŸ³å£°å†ç”Ÿä¸­ã¯true

    // ã‚¨ã‚³ãƒ¼å¯¾ç­–ï¼šæ±ç”¨ãƒãƒ£ãƒƒãƒˆç”¨ï¼ˆAIç™ºè©±ã‚’è¨˜éŒ²ã—ã¦æ¯”è¼ƒï¼‰
    let currentAISpeech = "";

    // ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªå‘ã‘ã®ã‚¨ã‚³ãƒ¼åˆ¤å®šï¼ˆç›´å‰ã®AIç™ºè©±ã¨ä¸€è‡´ã™ã‚‹ã‹ï¼‰
    function isSemanticEcho(transcript: string, aiText: string): boolean {
      if (!aiText || !transcript) return false;
      const normTranscript = normalizeText(transcript);
      const normAI = normalizeText(aiText);
      
      // å®Œå…¨ä¸€è‡´ã¾ãŸã¯å¼·ã„åŒ…å«é–¢ä¿‚ã®ã¿ãƒã‚§ãƒƒã‚¯
      if (normAI === normTranscript) return true;
      if (normAI.includes(normTranscript) && normTranscript.length > 5) return true;
      
      return false;
    }

    // â˜…â˜…â˜… iPhoneã®ã¿ï¼šè¶…è»½é‡Base64å¤‰æ›é–¢æ•°ï¼ˆãƒ¡ãƒ¢ãƒªè² è·å¯¾ç­–ï¼‰â˜…â˜…â˜…
    const b64chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
    function fastArrayBufferToBase64(buffer: ArrayBuffer) {
      let binary = '';
      const bytes = new Uint8Array(buffer);
      const len = bytes.byteLength;
      for (let i = 0; i < len; i += 3) {
        const c1 = bytes[i];
        const c2 = bytes[i + 1];
        const c3 = bytes[i + 2];
        const enc1 = c1 >> 2;
        const enc2 = ((c1 & 3) << 4) | (c2 >> 4);
        const enc3 = ((c2 & 15) << 2) | (c3 >> 6);
        const enc4 = c3 & 63;
        binary += b64chars[enc1] + b64chars[enc2];
        if (Number.isNaN(c2)) { binary += '=='; } 
        else if (Number.isNaN(c3)) { binary += b64chars[enc3] + '='; } 
        else { binary += b64chars[enc3] + b64chars[enc4]; }
      }
      return binary;
    }

    async function startStreamingSTT() {
      try {
        // è¿½åŠ ï¼šè² è·è»½æ¸›ã®ãŸã‚è£ã§å‹•ã„ã¦ã„ã‚‹å‹•ç”»ã‚’ç¢ºå®Ÿã«åœæ­¢
        if (splashVideo) { splashVideo.pause(); }
        if (waitVideo) { waitVideo.pause(); }

        // å¤ã„éŒ²éŸ³ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
        if (recordingTimer) {
          clearTimeout(recordingTimer);
          recordingTimer = null;
        }
        
        // AudioWorkletNodeã¨AudioContextã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if (audioWorkletNode) {
          audioWorkletNode.port.onmessage = null;
          audioWorkletNode.disconnect();
          audioWorkletNode = null;
        }
        if (audioContext) {
          if (audioContext.state !== 'closed') {
            await audioContext.close();
          }
          audioContext = null;
        }
        
        // MediaStream: æ¯å›æ–°è¦å–å¾—
        if (mediaStream) {
          mediaStream.getTracks().forEach(track => track.stop());
          mediaStream = null;
        }
        
        try {
          // â˜…â˜…â˜… iPhoneã¨ãã‚Œä»¥å¤–ã§åˆ¶å¾¡ã‚’åˆ†ã‘ã‚‹ â˜…â˜…â˜…
          const audioConstraints: any = { 
            channelCount: 1,
            // iPhone: ã‚¨ã‚³ãƒ¼ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç­‰ã‚’OFFã«ã—ã¦å‡¦ç†è² è·ã‚’è»½æ¸›
            echoCancellation: isIOS ? false : true,
            noiseSuppression: isIOS ? false : true,
            autoGainControl: isIOS ? false : true
          };
          
          console.log('[Microphone] Constraints:', audioConstraints);

          mediaStream = await navigator.mediaDevices.getUserMedia({ 
            audio: audioConstraints
          });
        } catch (micError: any) {
          // â˜…â˜…â˜… iPhoneã®ã¿ï¼šè©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ â˜…â˜…â˜…
          let errorMessage = '';
          if (micError.name === 'NotAllowedError' || micError.name === 'PermissionDeniedError') {
            errorMessage = isIOS 
              ? 'ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nã€è§£æ±ºæ–¹æ³•ã€‘\n1. ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‹ã‚‰ãƒã‚¤ã‚¯ã‚’è¨±å¯\n2. iPhoneã®ã€Œè¨­å®šã€â†’ã€ŒSafariã€â†’ã€Œãƒã‚¤ã‚¯ã€ã‚’ONã«'
              : 'ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‹ã‚‰ãƒã‚¤ã‚¯ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚';
          } else if (micError.name === 'NotFoundError') {
            errorMessage = 'ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒã‚¤ã‚¹ã«ãƒã‚¤ã‚¯ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚';
          } else if (micError.name === 'NotReadableError' || micError.name === 'AbortError') {
            errorMessage = isIOS
              ? 'ãƒã‚¤ã‚¯ãŒä»–ã®ã‚¢ãƒ—ãƒªã§ä½¿ç”¨ä¸­ã§ã™ã€‚\n\nã€è§£æ±ºæ–¹æ³•ã€‘\n1. ä»–ã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚¿ãƒ–ã‚’é–‰ã˜ã‚‹\n2. ä»–ã®ã‚¢ãƒ—ãƒªã‚’çµ‚äº†\n3. iPhoneã‚’å†èµ·å‹•'
              : 'ãƒã‚¤ã‚¯ãŒä»–ã®ã‚¢ãƒ—ãƒªã§ä½¿ç”¨ä¸­ã§ã™ã€‚ä»–ã®ã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã—ã¦ãã ã•ã„ã€‚';
          } else {
            errorMessage = `ãƒã‚¤ã‚¯ã‚¨ãƒ©ãƒ¼: ${micError.message}\n\nãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚`;
          }
          
          addMessage('system', errorMessage);
          throw micError;
        }
        
        // AudioContextã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ¼ãƒˆã§ä½œæˆ
        try {
          // â˜…â˜…â˜… iPhoneã®ã¿ï¼šlatencyHintã‚’æŒ‡å®šã—ã¦ãƒãƒƒãƒ•ã‚¡ã‚’æœ€é©åŒ– â˜…â˜…â˜…
          audioContext = isIOS 
            ? new AudioContext({ latencyHint: 'interactive' })
            : new AudioContext();
        } catch (contextError: any) {
          addMessage('system', 'AudioContextä½œæˆã‚¨ãƒ©ãƒ¼ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚');
          throw contextError;
        }
        
        // ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        const targetSampleRate = 16000;
        const nativeSampleRate = audioContext.sampleRate;
        const downsampleRatio = nativeSampleRate / targetSampleRate;
        console.log(`[Audio] Native: ${nativeSampleRate}Hz, Target: ${targetSampleRate}Hz, Ratio: ${downsampleRatio}`);
        
        // AudioContextã®çŠ¶æ…‹ç¢ºèª
        if (audioContext.state === 'closed') {
          addMessage('system', 'AudioContextãŒã‚¯ãƒ­ãƒ¼ã‚ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚');
          throw new Error('AudioContext is closed');
        }
        
        const source = audioContext.createMediaStreamSource(mediaStream);
        
        // â˜…â˜…â˜… iPhoneã¨ãã‚Œä»¥å¤–ã§AudioWorkletã®å‡¦ç†ã‚’åˆ†ã‘ã‚‹ â˜…â˜…â˜…
        const audioProcessorCode = isIOS ? `
// iPhoneç”¨ï¼šã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†ã§è² è·ã‚’è»½æ¸›
class AudioProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.bufferSize = 4096; // å°ã•ã‚ã®ãƒãƒƒãƒ•ã‚¡
    this.buffer = new Int16Array(this.bufferSize); 
    this.writeIndex = 0;
    this.ratio = ${downsampleRatio}; 
    this.inputSampleCount = 0;
  }

  process(inputs, outputs, parameters) {
    const input = inputs[0];
    if (!input || input.length === 0) return true;
    const channelData = input[0];
    if (!channelData || channelData.length === 0) return true;
    
    for (let i = 0; i < channelData.length; i++) {
      this.inputSampleCount++;
      if (this.inputSampleCount >= this.ratio) {
        this.inputSampleCount -= this.ratio;
        
        if (this.writeIndex < this.bufferSize) {
          const s = Math.max(-1, Math.min(1, channelData[i]));
          const int16Value = s < 0 ? s * 0x8000 : s * 0x7FFF;
          this.buffer[this.writeIndex++] = int16Value;
        }
        
        if (this.writeIndex >= this.bufferSize) {
          this.flush();
        }
      }
    }
    return true;
  }
  
  flush() {
    if (this.writeIndex === 0) return;
    const chunk = this.buffer.slice(0, this.writeIndex);
    this.port.postMessage({ audioChunk: chunk }, [chunk.buffer]);
    this.writeIndex = 0;
  }
}
registerProcessor('audio-processor', AudioProcessor);
` : `
// PC/Androidç”¨ï¼šé€šå¸¸ã®å‡¦ç†
class AudioProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.bufferSize = 16000;
    this.buffer = new Int16Array(this.bufferSize); 
    this.writeIndex = 0;
    this.ratio = ${downsampleRatio}; 
    this.inputSampleCount = 0;
    this.flushThreshold = 8000;
  }

  process(inputs, outputs, parameters) {
    const input = inputs[0];
    if (!input || input.length === 0) return true;
    const channelData = input[0];
    if (!channelData || channelData.length === 0) return true;
    
    for (let i = 0; i < channelData.length; i++) {
      this.inputSampleCount++;
      if (this.inputSampleCount >= this.ratio) {
        this.inputSampleCount -= this.ratio;

        if (this.writeIndex < this.bufferSize) {
          const s = Math.max(-1, Math.min(1, channelData[i]));
          const int16Value = s < 0 ? s * 0x8000 : s * 0x7FFF;
          this.buffer[this.writeIndex++] = int16Value;
        }

        if (this.writeIndex >= this.flushThreshold) {
          this.flush();
        }
      }
    }
    return true;
  }
  
  flush() {
    if (this.writeIndex === 0) return;
    const chunk = this.buffer.slice(0, this.writeIndex);
    this.port.postMessage({ audioChunk: chunk }, [chunk.buffer]);
    this.writeIndex = 0;
  }
}
registerProcessor('audio-processor', AudioProcessor);
`;
        
        try {
          const blob = new Blob([audioProcessorCode], { type: 'application/javascript' });
          const processorUrl = URL.createObjectURL(blob);
          await audioContext.audioWorklet.addModule(processorUrl);
          URL.revokeObjectURL(processorUrl);
        } catch (workletError: any) {
          addMessage('system', `éŸ³å£°å‡¦ç†ã®åˆæœŸåŒ–ã«å¤±æ•—: ${workletError.message || workletError}`);
          throw workletError;
        }
        
        // AudioWorkletNodeä½œæˆ
        audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');
        audioWorkletNode.port.onmessage = (event) => {
          const { audioChunk } = event.data;
          
          if (!isSendingAudio || !socket || !socket.connected) return;
          
          // â˜…â˜…â˜… iPhoneã®ã¿ï¼šè»½é‡Base64å¤‰æ›ã‚’ä½¿ç”¨ â˜…â˜…â˜…
          if (isIOS) {
            try {
              const base64 = fastArrayBufferToBase64(audioChunk.buffer);
              socket.emit('audio_chunk', { 
                chunk: base64,
                sample_rate: 16000
              });
            } catch (e) {
              console.error('Audio convert error', e);
            }
          } else {
            // PC/Androidï¼šå¾“æ¥ã®FileReaderæ–¹å¼
            const blob = new Blob([audioChunk], { type: 'application/octet-stream' });
            const reader = new FileReader();
            
            reader.onload = () => {
              const result = reader.result as string;
              const base64 = result.split(',')[1];
              
              socket.emit('audio_chunk', { 
                chunk: base64,
                sample_rate: 16000
              });
            };
            
            reader.readAsDataURL(blob);
          }
        };
        
        source.connect(audioWorkletNode);
        audioWorkletNode.connect(audioContext.destination);
        
        // â˜…â˜…â˜… iPhoneã®ã¿ï¼šVADã‚’ç„¡åŠ¹åŒ–ã—ã¦è² è·ã‚’è»½æ¸› â˜…â˜…â˜…
        if (!isIOS) {
          analyser = audioContext.createAnalyser();
          analyser.fftSize = 512;
          source.connect(analyser);
          const dataArray = new Uint8Array(analyser.frequencyBinCount);
          hasSpoken = false; recordingStartTime = Date.now();
          vadCheckInterval = window.setInterval(() => {
            if (!analyser || !isRecording) return;
            if (Date.now() - recordingStartTime < MIN_RECORDING_TIME) return;
            analyser.getByteFrequencyData(dataArray);
            const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
            
            if (average > SILENCE_THRESHOLD) { 
              hasSpoken = true; 
              if (silenceTimer) clearTimeout(silenceTimer); 
              voiceStatus.innerHTML = t('voiceStatusRecording'); 
            } else if (hasSpoken && !silenceTimer) { 
              voiceStatus.innerHTML = t('voiceStatusWaiting'); 
              silenceTimer = window.setTimeout(() => { 
                stopStreamingSTT(); 
              }, SILENCE_DURATION); 
            }
          }, 100);
        }
        
        // WebSocketã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒªã‚»ãƒƒãƒˆ
        if (socket && socket.connected) {
          socket.emit('stop_stream');
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        socket.emit('start_stream', { 
          language_code: LANGUAGE_CODE_MAP[currentLanguage].stt,
          sample_rate: 16000
        });
        
        isSendingAudio = true;
        isRecording = true; 
        micBtnFloat.classList.add('recording');
        voiceStatus.innerHTML = t('voiceStatusListening');
        
        // éŒ²éŸ³ã‚¿ã‚¤ãƒãƒ¼è¨­å®š
        recordingTimer = window.setTimeout(() => { 
          if (isRecording) { 
            stopStreamingSTT(); 
            addMessage('system', t('recordingTimeLimit')); 
          } 
        }, MAX_RECORDING_TIME);
      } catch (error: any) {
        // ã‚¨ãƒ©ãƒ¼æ™‚ã¯MediaStreamã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæ¬¡å›ã¯å†å–å¾—ï¼‰
        if (mediaStream) {
          mediaStream.getTracks().forEach(track => track.stop());
          mediaStream = null;
        }
        
        // ã™ã§ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºæ¸ˆã¿ã§ãªã„å ´åˆã®ã¿è¡¨ç¤º
        if (!error.message?.includes('ãƒã‚¤ã‚¯')) {
          addMessage('system', `${t('micAccessError')} ${error.message || 'Unknown error'}`);
        }
      }
    }

    function stopStreamingSTT() {
      stopVAD();
      // éŒ²éŸ³ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
      if (recordingTimer) {
        clearTimeout(recordingTimer);
        recordingTimer = null;
      }
      
      // å…¨ãƒ‡ãƒã‚¤ã‚¹å…±é€š: å®Œå…¨åœæ­¢
      
      // AudioWorkletNodeåœæ­¢
      if (audioWorkletNode) {
        audioWorkletNode.port.onmessage = null;
        audioWorkletNode.disconnect();
        audioWorkletNode = null;
      }
      
      // AudioContextåœæ­¢
      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
        audioContext = null;
      }
      
      // MediaStreamåœæ­¢ï¼ˆæ¯å›ç ´æ£„ï¼‰
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
      
      // WebSocketåœæ­¢
      if (socket && socket.connected) {
        socket.emit('stop_stream');
      }
      
      // éŸ³å£°é€ä¿¡ãƒ•ãƒ©ã‚°ã‚’åœæ­¢
      isSendingAudio = false;
      isRecording = false; 
      micBtnFloat.classList.remove('recording');
    }

    async function startLegacyRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: { 
            channelCount: 1, 
            sampleRate: 16000, 
            echoCancellation: true, 
            noiseSuppression: true 
          } 
        });
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
        audioChunks = []; 
        hasSpoken = false; 
        recordingStartTime = Date.now();
        audioContext = new AudioContext();
        const source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        vadCheckInterval = window.setInterval(() => {
          if (!analyser || !isRecording) return;
          if (Date.now() - recordingStartTime < MIN_RECORDING_TIME) return;
          analyser.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
          if (average > SILENCE_THRESHOLD) { 
            hasSpoken = true; 
            if (silenceTimer) clearTimeout(silenceTimer); 
            voiceStatus.innerHTML = t('voiceStatusRecording'); 
          } else if (hasSpoken && !silenceTimer) { 
            voiceStatus.innerHTML = t('voiceStatusWaiting'); 
            silenceTimer = window.setTimeout(() => { 
              autoStopRecording(); 
            }, SILENCE_DURATION); 
          }
        }, 100);
        mediaRecorder.ondataavailable = (event) => { 
          if (event.data.size > 0) audioChunks.push(event.data); 
        };
        mediaRecorder.onstop = async () => {
          stopVAD(); 
          stream.getTracks().forEach(track => track.stop());
          if (recordingTimer) clearTimeout(recordingTimer);
          if (audioChunks.length > 0) { 
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' }); 
            await transcribeAudio(audioBlob);
          }
        };
        mediaRecorder.start();
        isRecording = true; 
        micBtnFloat.classList.add('recording'); 
        voiceStatus.innerHTML = t('voiceStatusListening');
        recordingTimer = window.setTimeout(() => { 
          if (isRecording && mediaRecorder && mediaRecorder.state === 'recording') { 
            stopVAD(); 
            mediaRecorder.stop(); 
            isRecording = false; 
            micBtnFloat.classList.remove('recording'); 
            addMessage('system', t('recordingTimeLimit')); 
          } 
        }, MAX_RECORDING_TIME);
      } catch (error) { 
        addMessage('system', `${t('micAccessError')} ${(error as Error).message}`); 
      }
    }

    async function transcribeAudio(audioBlob: Blob) {
      try {
        voiceStatus.innerHTML = t('voiceStatusRecognizing');
        voiceStatus.className = 'voice-status';
        const reader = new FileReader();
        reader.readAsDataURL(audioBlob);
        reader.onloadend = async () => {
          const base64Audio = (reader.result as string).split(',')[1];
          const response = await fetch(`${apiBase}/api/stt/transcribe`, { 
            method: 'POST', 
            headers: { 'Content-Type': 'application/json' }, 
            body: JSON.stringify({ 
              audio: base64Audio, 
              language_code: LANGUAGE_CODE_MAP[currentLanguage].stt 
            }) 
          });
          const data = await response.json();

          if (data.success && data.transcript) {
            
            // ã‚¨ã‚³ãƒ¼åˆ¤å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
            const normTranscript = normalizeText(data.transcript);
            if (isSemanticEcho(normTranscript, lastAISpeech)) {
                console.log('[ã‚¨ã‚³ãƒ¼æ¤œçŸ¥] ç„¡è¦–:', data.transcript);
                voiceStatus.innerHTML = t('voiceStatusStopped');
                voiceStatus.className = 'voice-status stopped';
                lastAISpeech = '';
                return;
            }

            userInput.value = data.transcript;
            voiceStatus.innerHTML = t('voiceStatusComplete');
            voiceStatus.className = 'voice-status';
            
            addMessage('user', data.transcript);
            // 1. æ—¥æ™‚ãƒã‚§ãƒƒã‚¯
            // @ts-ignore
            if (i18n[currentLanguage].patterns?.dateCheck?.test(data.transcript)) {
              const msg = t('dateWarningMsg');
              addMessage('assistant', msg);
              
              // AIéŸ³å£°å†ç”Ÿä¸­ã¯éŒ²éŸ³å®Œå…¨åœæ­¢
              const wasRecording = isRecording;
              if (wasRecording) {
                console.log('[éŒ²éŸ³åˆ¶å¾¡] AIéŸ³å£°å†ç”Ÿã®ãŸã‚ä¸€æ™‚åœæ­¢');
                // LegacyéŒ²éŸ³ã®åœæ­¢
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                  mediaRecorder.stop();
                }
                // WebSocketéŒ²éŸ³ã®åœæ­¢
                stopStreamingSTT();
                isRecording = false;
                micBtnFloat.classList.remove('recording');
              }
              
              if (isTTSEnabled && isUserInteracted) {
                await speakTextGCP(msg, true);
                // éŸ³å£°å†ç”Ÿå®Œäº†ã‚’å¾…ã¤
                await new Promise(r => setTimeout(r, 1000));
                // 1ç§’å¾…æ©Ÿï¼ˆéŸ³å£°ã®ä½™éŸ»ï¼‰
              } else {
                await new Promise(r => setTimeout(r, 2000));
              }
              
              userInput.value = '';
              voiceStatus.innerHTML = t('voiceStatusStopped');
              voiceStatus.className = 'voice-status stopped';
              
              // AIéŸ³å£°å†ç”Ÿå®Œäº†å¾Œã«éŒ²éŸ³å†é–‹
              if (wasRecording) {
                console.log('[éŒ²éŸ³åˆ¶å¾¡] éŒ²éŸ³å†é–‹');
                setTimeout(() => { 
                  toggleRecording().catch(e => {}); 
                }, 500);
              }
              return;
            }

            // 2. æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
            const textLength = data.transcript.trim().replace(/\s+/g, '').length;
            if (textLength < 4) {
                const msg = t('shortMsgWarning');
                addMessage('assistant', msg);
                if (isTTSEnabled && isUserInteracted) {
                  await speakTextGCP(msg, true);
                  await new Promise(r => setTimeout(r, 500));
                } else {
                  await new Promise(r => setTimeout(r, 2000));
                }
                userInput.value = '';
                voiceStatus.innerHTML = t('voiceStatusStopped');
                voiceStatus.className = 'voice-status stopped';
                setTimeout(() => { 
                  toggleRecording().catch(e => {}); 
                }, 500);
                return;
            }

            // 3. é€šå¸¸ãƒ•ãƒ­ãƒ¼
            const ack = selectSmartAcknowledgment(data.transcript);
            const preGeneratedAudio = preGeneratedAcks.get(ack.text);
            let firstAckPromise: Promise<void> | null = null;
            if (preGeneratedAudio && isTTSEnabled && isUserInteracted) {
              firstAckPromise = new Promise<void>((resolve) => {
                // preGeneratedAudioå†ç”Ÿæ™‚ã‚‚lastAISpeechã«è¨˜éŒ²
                lastAISpeech = normalizeText(ack.text);
                ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
  
                ttsPlayer.onended = () => resolve();
                ttsPlayer.play().catch(e => resolve());
              });
            } else if (isTTSEnabled) { 
              firstAckPromise = speakTextGCP(ack.text, false); 
            }
            addMessage('assistant', ack.text);
            (async () => {
                if (firstAckPromise) await firstAckPromise;
                const cleanText = removeFillers(data.transcript);
                const fallbackResponse = generateFallbackResponse(cleanText);
                if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
                addMessage('assistant', fallbackResponse);
 
                setTimeout(async () => {
                  const additionalResponse = t('additionalResponse');
                  if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
                  addMessage('assistant', additionalResponse);
                }, 3000);
 
                if (userInput.value.trim()) { 
                  isFromVoiceInput = true; 
                  sendMessage(); 
                }
            })();
            voiceStatus.innerHTML = t('voiceStatusStopped');
            voiceStatus.className = 'voice-status stopped';
          }
        };
      } catch (error) { 
        console.error('STT Error:', error); 
      }
    }

    function initializeWebSocketSTT() {
      try {
        const wsUrl = apiBase || window.location.origin;
        socket = io(wsUrl);
        socket.on('connect', () => { 
          isStreamingSTT = true; 
        });
        socket.on('disconnect', () => { 
          isStreamingSTT = false; 
        });
        socket.on('transcript', (data: any) => {
          const { text, is_final } = data;
          
          // â˜…â˜…â˜… iPhoneã®ã¿ï¼šAIéŸ³å£°å†ç”Ÿä¸­ã¯å…¨ã¦ç„¡è¦–ï¼ˆè‡ªå‹•ãƒã‚¤ã‚¯ã‚ªãƒ•ï¼‰â˜…â˜…â˜…
          if (isIOS && isAISpeaking) {
            return;
          }
          
          if (is_final) { 
            streamingTranscript = text; 
            handleStreamingSTTComplete(text);
            currentAISpeech = "";
          } else { 
            userInput.value = text;
          }
        });
        socket.on('error', (data: any) => { 
          addMessage('system', `${t('sttError')} ${data.message}`);
          // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒã‚¤ã‚¯ã‚’åœæ­¢ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
          if (isRecording) {
            stopStreamingSTT();
          }
        });
      } catch (error) { 
        isStreamingSTT = false; 
      }
    }

    async function handleStreamingSTTComplete(transcript: string) {
      // â˜…â˜…â˜… iPhoneã®ã¿ï¼šéŸ³å£°èªè­˜å®Œäº†å¾Œã€ãƒã‚¤ã‚¯ã‚’è‡ªå‹•OFFï¼ˆè‡ªå‹•ãƒã‚¤ã‚¯ã‚ªãƒ•æ©Ÿèƒ½ï¼‰â˜…â˜…â˜…
      if (isIOS) {
        stopStreamingSTT();
      }
      
      voiceStatus.innerHTML = t('voiceStatusComplete');
      voiceStatus.className = 'voice-status';

      // ã‚¨ã‚³ãƒ¼åˆ¤å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
      const normTranscript = normalizeText(transcript);
      if (isSemanticEcho(normTranscript, lastAISpeech)) {
          console.log('[ã‚¨ã‚³ãƒ¼æ¤œçŸ¥WS] ç„¡è¦–:', transcript);
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          lastAISpeech = '';
          return;
      }

      userInput.value = transcript;
      // æ—¥æ™‚ãƒã‚§ãƒƒã‚¯
      // @ts-ignore
      if (i18n[currentLanguage].patterns?.dateCheck?.test(transcript)) {
        const msg = t('dateWarningMsg');
        currentAISpeech = msg;
        addMessage('assistant', msg);
        
        if (isTTSEnabled && isUserInteracted) {
          await speakTextGCP(msg, true, true);
          // ç¬¬3å¼•æ•° autoRestartMic = true
        } else {
          await new Promise(r => setTimeout(r, 2000));
        }
        
        userInput.value = '';
        voiceStatus.innerHTML = t('voiceStatusStopped');
        voiceStatus.className = 'voice-status stopped';
        return;
      }

      addMessage('user', transcript);
      const textLength = transcript.trim().replace(/\s+/g, '').length;
      if (textLength < 4) {
          const msg = t('shortMsgWarning');
          addMessage('assistant', msg);
          
          // AIéŸ³å£°å†ç”Ÿå‰ã«STTé€ä¿¡åœæ­¢
          isSendingAudio = false;
          if (isTTSEnabled && isUserInteracted) {
            await speakTextGCP(msg, true);
          } else {
            await new Promise(r => setTimeout(r, 2000));
          }
          
          // éŸ³å£°å†ç”Ÿå®Œäº†å¾Œã€å³åº§ã«STTé€ä¿¡å†é–‹
          isSendingAudio = true;
          userInput.value = '';
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          return;
      }

      const ack = selectSmartAcknowledgment(transcript);
      const preGeneratedAudio = preGeneratedAcks.get(ack.text);
      let firstAckPromise: Promise<void> | null = null;
      if (preGeneratedAudio && isTTSEnabled && isUserInteracted) {
        firstAckPromise = new Promise<void>((resolve) => {
          // preGeneratedAudioå†ç”Ÿæ™‚ã‚‚lastAISpeechã«è¨˜éŒ²
          lastAISpeech = normalizeText(ack.text);
          ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
          ttsPlayer.onended = () => resolve();
          ttsPlayer.play().catch(e => resolve());
        });
      } else if (isTTSEnabled) { 
        firstAckPromise = speakTextGCP(ack.text, false);
      }
      addMessage('assistant', ack.text);

      (async () => {
        try {
          if (firstAckPromise) await firstAckPromise;
          const cleanText = removeFillers(transcript);
          const fallbackResponse = generateFallbackResponse(cleanText);
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
          addMessage('assistant', fallbackResponse);
          setTimeout(async () => {
            const additionalResponse = t('additionalResponse');
            if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
            addMessage('assistant', additionalResponse);
          }, 3000);
          
          if (userInput.value.trim()) {
            isFromVoiceInput = true;
            sendMessage();
          }
        } catch (error) { 
          if (userInput.value.trim()) {
            isFromVoiceInput = true;
            sendMessage();
          }
        }
      })();
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
    }

    async function sendMessage() {
      let firstAckPromise: Promise<void> | null = null; 
      unlockAudioParams();
      const message = userInput.value.trim();
      if (!message || isProcessing) return;
      isProcessing = true; 
      sendBtn.disabled = true;
      micBtnFloat.disabled = true; 
      userInput.disabled = true;

      if (!isFromVoiceInput) {
        addMessage('user', message);
        // @ts-ignore
        if (i18n[currentLanguage].patterns?.dateCheck?.test(message)) {
             const msg = t('dateWarningMsg');
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             addMessage('assistant', msg);
             userInput.value = ''; 
             isProcessing = false; 
             sendBtn.disabled = false;
             micBtnFloat.disabled = false; 
             userInput.disabled = false; 
             userInput.focus();
             return;
        }
        const textLength = message.trim().replace(/\s+/g, '').length;
        if (textLength < 4) {
             const msg = t('shortMsgWarning');
             addMessage('assistant', msg);
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             userInput.value = ''; 
             isProcessing = false; 
             sendBtn.disabled = false;
             micBtnFloat.disabled = false; 
             userInput.disabled = false; 
             userInput.focus();
             return;
        }
        userInput.value = '';
        const ack = selectSmartAcknowledgment(message);
        
        // ç›¸æ§Œã‚’è¨˜éŒ²ï¼ˆã‚¨ã‚³ãƒ¼åˆ¤å®šç”¨ï¼‰
        currentAISpeech = ack.text;
        
        addMessage('assistant', ack.text);
        if (isTTSEnabled) {
          try {
            const preGeneratedAudio = preGeneratedAcks.get(ack.text);
            if (preGeneratedAudio && isUserInteracted) {
              firstAckPromise = new Promise<void>((resolve) => {
                // preGeneratedAudioå†ç”Ÿæ™‚ã‚‚lastAISpeechã«è¨˜éŒ²
                lastAISpeech = normalizeText(ack.text);
                ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
                ttsPlayer.onended = () => resolve();
                ttsPlayer.play().catch(e => resolve());
              });
            } else { 
              firstAckPromise = speakTextGCP(ack.text, false); 
            }
          } catch (e) {}
        }
        if (firstAckPromise) await firstAckPromise;
        const cleanText = removeFillers(message);
        const fallbackResponse = generateFallbackResponse(cleanText);
        if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
        addMessage('assistant', fallbackResponse);
        setTimeout(async () => {
          const additionalResponse = t('additionalResponse');
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
          addMessage('assistant', additionalResponse);
        }, 3000);
      }

      const wasVoiceInput = isFromVoiceInput;
      isFromVoiceInput = false;
      if (waitOverlayTimer) clearTimeout(waitOverlayTimer);
      waitOverlayTimer = window.setTimeout(() => { 
        showWaitOverlay(); 
      }, 4000);

      try {
        const response = await fetch(`${apiBase}/api/chat`, { 
          method: 'POST', 
          headers: { 'Content-Type': 'application/json' }, 
          body: JSON.stringify({ 
            session_id: sessionId, 
            message: message, 
            stage: currentStage, 
            language: currentLanguage 
          }) 
        });
        const data = await response.json();
        hideWaitOverlay();
        
        // AIå¿œç­”ã‚’è¨˜éŒ²ï¼ˆã‚¨ã‚³ãƒ¼åˆ¤å®šç”¨ï¼‰
        currentAISpeech = data.response;
        addMessage('assistant', data.response, data.summary);
        stopCurrentAudio();

        if (data.shops && data.shops.length > 0) {
          currentShops = data.shops;
          reservationBtn.disabled = false;
          
          // å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢
          userInput.value = '';
          document.dispatchEvent(new CustomEvent('displayShops', { 
            detail: { shops: data.shops, language: currentLanguage } 
          }));
          const section = document.getElementById('shopListSection');
          if (section) section.classList.add('has-shops');
          // ã‚¹ãƒãƒ›ã®å ´åˆï¼šã‚·ãƒ§ãƒƒãƒ—ã‚«ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
          if (window.innerWidth < 1024) {
            setTimeout(() => {
              const shopSection = document.getElementById('shopListSection');
              if (shopSection) {
                shopSection.scrollIntoView({ 
                  behavior: 'smooth', 
                  block: 'start' 
                });
              }
            }, 300);
            // DOMãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾…ã¡
          }
          
          (async () => {
            try {
              // ã‚·ãƒ§ãƒƒãƒ—éŸ³å£°å†ç”Ÿé–‹å§‹
              isAISpeaking = true;
              if (isAndroid && isRecording) {
                stopStreamingSTT();
              }
              
              await speakTextGCP(t('ttsIntro'));
              const lines = data.response.split('\n\n');
              let introText = ""; 
              let shopLines = lines;
      
              if (lines[0].includes('ã”å¸Œæœ›ã«åˆã†ãŠåº—') && lines[0].includes('ã”ç´¹ä»‹ã—ã¾ã™')) { 
                introText = lines[0]; 
                shopLines = lines.slice(1); 
              }
              
              let introPart2Promise: Promise<void> | null = null;
              if (introText && isTTSEnabled && isUserInteracted) {
                const preGeneratedIntro = preGeneratedAcks.get(introText);
                if (preGeneratedIntro) {
                  introPart2Promise = new Promise<void>((resolve) => {
                    lastAISpeech = normalizeText(introText);
                    ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedIntro}`;
                    ttsPlayer.onended = () => resolve();
                    ttsPlayer.play();
                  });
                } else { 
                  introPart2Promise = speakTextGCP(introText, false);
                }
              }

              let firstShopAudioPromise: Promise<string | null> | null = null;
              let remainingAudioPromise: Promise<string | null> | null = null;
              const shopLangConfig = LANGUAGE_CODE_MAP[currentLanguage];
              if (shopLines.length > 0 && isTTSEnabled && isUserInteracted) {
                const firstShop = shopLines[0];
                const restShops = shopLines.slice(1).join('\n\n');
                firstShopAudioPromise = (async () => {
                  const cleanText = stripMarkdown(firstShop);
                  const response = await fetch(`${apiBase}/api/tts/synthesize`, { 
                    method: 'POST', 
                    headers: { 'Content-Type': 'application/json' }, 
                    body: JSON.stringify({ 
                      text: cleanText, 
                      language_code: shopLangConfig.tts, 
                      voice_name: shopLangConfig.voice 
                    }) 
                  });
                  const result = await response.json();
                  return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                })();
                if (restShops) {
                  remainingAudioPromise = (async () => {
                    const cleanText = stripMarkdown(restShops);
                    const response = await fetch(`${apiBase}/api/tts/synthesize`, { 
                      method: 'POST', 
                      headers: { 'Content-Type': 'application/json' }, 
                      body: JSON.stringify({ 
                        text: cleanText, 
                        language_code: shopLangConfig.tts, 
                        voice_name: shopLangConfig.voice 
                      }) 
                    });
                    const result = await response.json();
                    return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                  })();
                }
              }

              if (introPart2Promise) await introPart2Promise;
              if (firstShopAudioPromise) {
                const firstShopAudio = await firstShopAudioPromise;
                if (firstShopAudio) {
                  const firstShopText = stripMarkdown(shopLines[0]);
                  lastAISpeech = normalizeText(firstShopText);
                  
                  stopCurrentAudio(); 
                  ttsPlayer.src = firstShopAudio;
                  await new Promise<void>((resolve) => { 
                    ttsPlayer.onended = () => { 
                      voiceStatus.innerHTML = t('voiceStatusStopped'); 
                      voiceStatus.className = 'voice-status stopped'; 
                      resolve(); 
                    }; 
                    voiceStatus.innerHTML = t('voiceStatusSpeaking'); 
                    voiceStatus.className = 'voice-status speaking'; 
                    ttsPlayer.play(); 
                  });
                  if (remainingAudioPromise) {
                    const remainingAudio = await remainingAudioPromise;
                    if (remainingAudio) {
                      const restShopsText = stripMarkdown(shopLines.slice(1).join('\n\n'));
                      lastAISpeech = normalizeText(restShopsText);
                      
                      await new Promise(r => setTimeout(r, 500));
                      stopCurrentAudio(); 
                      ttsPlayer.src = remainingAudio;
                      await new Promise<void>((resolve) => { 
                        ttsPlayer.onended = () => { 
                          voiceStatus.innerHTML = 'ğŸ¤ éŸ³å£°èªè­˜: åœæ­¢ä¸­'; 
                          voiceStatus.className = 'voice-status stopped'; 
                          resolve(); 
                        }; 
                        voiceStatus.innerHTML = 'ğŸ”Š éŸ³å£°å†ç”Ÿä¸­...'; 
                        voiceStatus.className = 'voice-status speaking'; 
                        ttsPlayer.play(); 
                      });
                    }
                  }
                }
              }
              
              // ã‚·ãƒ§ãƒƒãƒ—éŸ³å£°å†ç”Ÿçµ‚äº†
              isAISpeaking = false;
            } catch (e) { 
              isAISpeaking = false;
            }
          })();
        } else {
          if (data.response) {
            const extractedShops = extractShopsFromResponse(data.response);
            if (extractedShops.length > 0) {
              currentShops = extractedShops;
              reservationBtn.disabled = false;
              document.dispatchEvent(new CustomEvent('displayShops', { 
                detail: { shops: extractedShops, language: currentLanguage } 
              }));
              const section = document.getElementById('shopListSection');
              if (section) section.classList.add('has-shops');
              speakTextGCP(data.response);
            } else { 
              speakTextGCP(data.response); 
            }
          }
        }
      } catch (error) { 
        console.error('é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
        hideWaitOverlay(); 
        showError('ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚'); 
      } finally { 
        isProcessing = false; 
        sendBtn.disabled = false; 
        micBtnFloat.disabled = false;
        userInput.disabled = false; 
        if (currentShops.length === 0) userInput.focus(); 
        else userInput.blur();
      }
    }

    // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
    function openReservationModal() {
      if (currentShops.length === 0) { 
        showError(t('searchError'));
        return; 
      }
      document.dispatchEvent(new CustomEvent('openReservationModal', { 
        detail: { shops: currentShops } 
      }));
    }

    // åˆæœŸåŒ–é–¢æ•°
    async function initialize() {
        try {
            const response = await fetch(`${apiBase}/api/session/start`, { 
              method: 'POST', 
              headers: { 'Content-Type': 'application/json' }, 
              body: JSON.stringify({ 
                user_info: {}, 
                language: currentLanguage 
              }) 
            });
            const data = await response.json(); 
            sessionId = data.session_id;
            addMessage('assistant', t('initialGreeting'), null, true);
            const ackTexts = [
              t('ackConfirm'), 
              t('ackSearch'), 
              t('ackUnderstood'), 
              t('ackYes'), 
              t('ttsIntro')
            ];
            const langConfig = LANGUAGE_CODE_MAP[currentLanguage];
            const ackPromises = ackTexts.map(async (text) => {
              try {
                const ackResponse = await fetch(`${apiBase}/api/tts/synthesize`, { 
                  method: 'POST', 
                  headers: { 'Content-Type': 'application/json' }, 
                  body: JSON.stringify({ 
                    text: text, 
                    language_code: langConfig.tts, 
                    voice_name: langConfig.voice 
                  }) 
                });
                const ackData = await ackResponse.json();
                if (ackData.success && ackData.audio) {
                  preGeneratedAcks.set(text, ackData.audio);
                }
              } catch (e) {}
            });
            await Promise.all([
              speakTextGCP(t('initialGreeting')), 
              ...ackPromises
            ]);
            userInput.disabled = false; 
            sendBtn.disabled = false; 
            micBtnFloat.disabled = false; 
            speakerBtn.disabled = false; 
            userInput.focus();
            if (splashOverlay) hideSplash();
            initializeWebSocketSTT();
            updateUILanguage();
        } catch(e) { 
          console.error(e); 
        }
    }

    // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ç™»éŒ²
    languageSelect.addEventListener('change', () => { 
      currentLanguage = languageSelect.value as any; 
      updateUILanguage(); 
    });
    sendBtn.addEventListener('click', sendMessage);
    micBtnFloat.addEventListener('click', toggleRecording);
    speakerBtn.addEventListener('click', toggleTTS);
    userInput.addEventListener('keypress', (e) => { 
      if (e.key === 'Enter') sendMessage(); 
    });
    reservationBtn.addEventListener('click', openReservationModal);
    
    // ã‚½ãƒ•ãƒˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰è¡¨ç¤ºæ¤œçŸ¥
    const floatingButtons = document.querySelector('.floating-buttons') as HTMLElement;
    userInput.addEventListener('focus', () => {
      // ãƒ•ã‚©ãƒ¼ã‚«ã‚¹æ™‚ã€å°‘ã—é…å»¶ã—ã¦ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰è¡¨ç¤ºã‚’æ¤œçŸ¥
      setTimeout(() => {
        if (floatingButtons) {
          floatingButtons.classList.add('keyboard-active');
        }
      }, 300);
    });
    userInput.addEventListener('blur', () => {
      // ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ãŒå¤–ã‚ŒãŸã‚‰ãƒœã‚¿ãƒ³ã‚’å…ƒã®ä½ç½®ã«
      if (floatingButtons) {
        floatingButtons.classList.remove('keyboard-active');
      }
    });
    
    // ä¸­æ­¢å‡¦ç†ï¼ˆå…±é€šé–¢æ•°ï¼‰
    function stopAllActivities() {
      // ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®LLMå‡¦ç†ã‚’ä¸­æ­¢
      if (isProcessing) {
        fetch(`${apiBase}/api/cancel`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ session_id: sessionId })
        }).catch(err => console.error('ä¸­æ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—:', err));
      }
      
      // éŒ²éŸ³ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
      if (recordingTimer) {
        clearTimeout(recordingTimer);
        recordingTimer = null;
      }
      
      // éŸ³å£°èªè­˜ã‚’åœæ­¢
      if (isRecording) {
        stopStreamingSTT();
      }
      
      // TTSå†ç”Ÿã‚’åœæ­¢
      stopCurrentAudio();
      
      // å¾…æ©Ÿã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’éè¡¨ç¤º
      waitOverlay.classList.add('hidden');
      if (waitOverlayTimer) {
        clearTimeout(waitOverlayTimer);
        waitOverlayTimer = null;
      }
      
      // ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
      isProcessing = false;
      isAISpeaking = false;
      
      // UIçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
      
      // å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒ•ã‚©ãƒ¼ã‚«ã‚¹
      userInput.value = '';
      userInput.focus();
      
      // ãƒãƒ£ãƒƒãƒˆç”»é¢ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼ˆã‚¹ãƒãƒ›å¯¾å¿œï¼‰
      if (window.innerWidth < 1024) {
        setTimeout(() => {
          chatArea.scrollIntoView({ 
            behavior: 'smooth', 
            block: 'start' 
          });
        }, 100);
      }
    }
    
    // ä¸­æ­¢ãƒœã‚¿ãƒ³
    stopBtn.addEventListener('click', () => {
      stopAllActivities();
    });
    
    // æœ€å¾Œã«åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
    initialize();
  });
</script>
