---
// GourmetChat.astro - „Ç∞„É´„É°„Çµ„Éù„Éº„Éà„ÉÅ„É£„ÉÉ„Éà„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà
export interface Props {
  apiBaseUrl?: string;
}

const { apiBaseUrl = '' } = Astro.props;
---

<div class="gourmet-chat-container" data-api-base={apiBaseUrl}>
  <div class="splash-overlay" id="splashOverlay">
    <video id="splashVideo" class="splash-video" autoplay muted playsinline loop>
      <source src="/splash.mp4" type="video/mp4">
    </video>
    <div class="splash-loading"><div class="spinner"></div><p>Ê∫ñÂÇô‰∏≠...</p></div>
  </div>

  <div class="wait-overlay hidden" id="waitOverlay">
    <div class="wait-content">
      <video id="waitVideo" class="wait-video" muted playsinline loop>
        <source src="/wait.mp4" type="video/mp4">
      </video>
      <p class="wait-text">AI„Åå„ÅäÂ∫ó„ÇíÊ§úÁ¥¢„Åó„Å¶„ÅÑ„Åæ„Åô...</p>
    </div>
  </div>

  <div class="language-selector">
    <select id="languageSelect" class="language-dropdown">
      <option value="ja">Êó•Êú¨Ë™û (Japanese)</option>
      <option value="en">English</option>
      <option value="zh">‰∏≠Êñá (Chinese)</option>
      <option value="ko">ÌïúÍµ≠Ïñ¥ (Korean)</option>
    </select>
  </div>

  <div class="voice-status stopped" id="voiceStatus">üé§ Èü≥Â£∞Ë™çË≠ò: ÂÅúÊ≠¢‰∏≠</div>
  
  <div class="chat-area" id="chatArea"></div>

  <div class="input-area">
    <div class="input-group">
      <input type="text" id="userInput" placeholder="„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂÖ•Âäõ..." disabled />
      <button class="btn btn-icon btn-speaker" id="speakerBtn" title="Èü≥Â£∞Ë™≠„Åø‰∏ä„ÅíON" disabled>üîä</button>
      <button class="btn" id="sendBtn" disabled>ÈÄÅ‰ø°</button>
    </div>
    <div class="input-actions">
      <button class="btn btn-reservation" id="reservationBtn" disabled>üìû ‰∫àÁ¥Ñ‰æùÈ†º„Åô„Çã</button>
    </div>
  </div>
  
  <div class="floating-buttons">
    <button class="btn-floating btn-stop" id="stopBtn" title="‰∏≠Ê≠¢"></button>
    <button class="btn-floating btn-mic-float" id="micBtnFloat" title="Èü≥Â£∞ÂÖ•Âäõ" disabled></button>
  </div>
</div>

<style>
  /* „Ç≥„É≥„ÉÜ„Éä */
  .gourmet-chat-container { background: white; border-radius: 16px; box-shadow: 0 20px 60px rgba(0,0,0,0.15); width: 100%; max-width: 800px; max-height: 600px; display: flex; flex-direction: column; overflow: hidden; margin: 0 auto; position: relative; }
  
  /* Ë®ÄË™ûÈÅ∏Êäû */
  .language-selector { padding: 12px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); display: flex; justify-content: flex-end; align-items: center; }
  .language-dropdown { padding: 6px 12px; border: 2px solid white; border-radius: 20px; background: rgba(255,255,255,0.95); color: #667eea; font-size: 13px; font-weight: 600; cursor: pointer; outline: none; transition: all 0.2s; }
  
  /* „Çπ„ÉÜ„Éº„Çø„Çπ */
  .voice-status { padding: 10px 15px; text-align: center; font-size: 12px; border-bottom: 1px solid #e0e0e0; font-weight: 500; }
  .voice-status.listening { background: #e8f5e9; color: #2e7d32; animation: pulse 2s infinite; }
  .voice-status.stopped { background: #ffebee; color: #c62828; }
  .voice-status.speaking { background: #e1f5fe; color: #0277bd; animation: pulse 2s infinite; }
  @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.8; } }
  
  /* „ÉÅ„É£„ÉÉ„Éà„Ç®„É™„Ç¢ */
  .chat-area { flex: 1; overflow-y: auto; padding: 20px; background: #f7f9fc; min-height: 300px; }
  .message { margin-bottom: 16px; display: flex; gap: 10px; }
  .message.assistant { flex-direction: row; }
  .message.user { flex-direction: row-reverse; }
  .message.system { justify-content: center; }
  .message-avatar { width: 36px; height: 36px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 16px; flex-shrink: 0; }
  .message.assistant .message-avatar { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
  .message.user .message-avatar { background: #e0e7ff; color: #667eea; }
  .message.system .message-avatar { background: #fff3e0; color: #f57c00; }
  .message-content { max-width: 70%; padding: 10px 14px; border-radius: 12px; line-height: 1.5; font-size: 14px; white-space: pre-wrap; }
  .message.assistant .message-content { background: white; border: 1px solid #e5e7eb; color: #1f2937; }
  .message.user .message-content { background: #667eea; color: white; }
  .message.system .message-content { background: #fff3e0; color: #e65100; font-size: 12px; }
  .summary-box { margin-top: 10px; padding: 10px; background: #fef3c7; border-left: 4px solid #f59e0b; border-radius: 8px; font-size: 13px; color: #92400e; }
  .final-summary { margin: 16px 0; padding: 16px; background: white; border: 2px solid #10b981; border-radius: 12px; }
  
  /* ÂÖ•Âäõ„Ç®„É™„Ç¢ */
  .input-area { padding: 16px; background: white; border-top: 1px solid #e5e7eb; }
  .input-group { display: flex; gap: 10px; align-items: center; margin-bottom: 10px; }
  #userInput { flex: 1; padding: 10px 14px; border: 2px solid #e5e7eb; border-radius: 20px; font-size: 14px; outline: none; transition: border-color 0.2s; }
  #userInput:focus { border-color: #667eea; }
  .btn { padding: 10px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 20px; font-size: 14px; font-weight: 600; cursor: pointer; transition: transform 0.2s, box-shadow 0.2s; }
  .btn:hover:not(:disabled) { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4); }
  .btn:disabled { opacity: 0.5; cursor: not-allowed; }
  .btn-reservation { background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; font-size: 13px; padding: 10px 16px; font-weight: 600; box-shadow: 0 4px 12px rgba(245, 158, 11, 0.3); }
  .btn-icon { padding: 10px; width: 40px; height: 40px; display: flex; align-items: center; justify-content: center; }
  .btn-speaker { background: #f59e0b; }
  .btn-speaker.disabled { background: #9ca3af; }
  .input-actions { display: flex; justify-content: flex-end; }
  .loading { display: inline-block; width: 20px; height: 20px; border: 3px solid #e5e7eb; border-radius: 50%; border-top-color: #667eea; animation: spin 1s ease-in-out infinite; }
  @keyframes spin { to { transform: rotate(360deg); } }
  .error-message { background: #fee2e2; color: #b91c1c; padding: 10px; border-radius: 8px; margin: 10px 0; font-size: 13px; text-align: center; }
  
  /* „Çπ„Éó„É©„ÉÉ„Ç∑„É•„ÉªÂæÖÊ©üÁîªÈù¢ */
  .splash-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; justify-content: center; z-index: 9999; border-radius: 16px; overflow: hidden; transition: opacity 0.8s ease-out; pointer-events: all; }
  .splash-overlay.fade-out { opacity: 0; pointer-events: none; }
  .splash-overlay.hidden { display: none; }
  .splash-video { width: 100%; height: 100%; object-fit: contain; position: absolute; top: 0; left: 0; transform: scale(0.5); }
  .splash-loading { position: absolute; bottom: 60px; display: flex; flex-direction: column; align-items: center; gap: 12px; z-index: 1; }
  .splash-loading .spinner { width: 40px; height: 40px; border: 4px solid rgba(102, 126, 234, 0.3); border-top-color: #667eea; border-radius: 50%; animation: spin 1s linear infinite; }
  .wait-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: rgba(255, 255, 255, 0.95); z-index: 500; display: flex; align-items: center; justify-content: center; border-radius: 16px; opacity: 1; transition: opacity 0.5s ease-out, visibility 0.5s; }
  .wait-overlay.hidden { opacity: 0; visibility: hidden; pointer-events: none; }
  .wait-content { text-align: center; width: 80%; max-width: 400px; }
  .wait-video { width: 100%; border-radius: 12px; box-shadow: 0 8px 30px rgba(0,0,0,0.1); margin-bottom: 16px; }
  .click-prompt { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); background: rgba(0, 0, 0, 0.8); color: white; padding: 20px; border-radius: 12px; text-align: center; z-index: 100; cursor: pointer; }
  
  /* „Éï„É≠„Éº„ÉÜ„Ç£„É≥„Ç∞„Éú„Çø„É≥ÔºàÁîªÂÉè‰æùÂ≠ò„Å™„Åó„ÉªCSSÊèèÁîªÔºâ */
  .floating-buttons { position: fixed; bottom: 20px; right: 20px; display: flex; gap: 12px; z-index: 1000; transition: bottom 0.3s ease; }
  .floating-buttons.keyboard-active { bottom: 320px; }
  @media (max-width: 768px) { .floating-buttons.keyboard-active { bottom: 280px; } }
  
  .btn-floating { 
    width: 56px; height: 56px; border-radius: 50%; border: none; font-size: 24px; 
    cursor: pointer; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3); 
    transition: transform 0.2s, box-shadow 0.2s; 
    display: flex; align-items: center; justify-content: center; 
  }
  .btn-floating:hover { transform: translateY(-2px); box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4); }
  .btn-floating:active { transform: translateY(0); }
  
  /* ÂÅúÊ≠¢„Éú„Çø„É≥: Ëµ§ + ÂõõËßí */
  .btn-stop { background: linear-gradient(135deg, #ff3b30 0%, #d32f2f 100%); color: white; }
  .btn-stop::before { content: '‚èπ'; font-size: 24px; }
  
  /* „Éû„Ç§„ÇØ„Éú„Çø„É≥: Á∑ë/Ëµ§ + „Éû„Ç§„ÇØ/ÂõõËßí */
  .btn-mic-float { background: #999; color: white; position: relative; overflow: visible; }
  .btn-mic-float:not(:disabled) { background: #10b981; }
  .btn-mic-float::before { content: 'üé§'; font-size: 28px; }
  .btn-mic-float:disabled { cursor: not-allowed; opacity: 0.6; }
  
  /* Èå≤Èü≥‰∏≠„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥ */
  .btn-mic-float.recording { background: #ef4444; }
  .btn-mic-float.recording::before { content: '‚èπ'; }
  .btn-mic-float.recording::after { 
    content: ''; position: absolute; width: 100%; height: 100%; 
    border-radius: 50%; border: 3px solid #ef4444; 
    opacity: 0; animation: ripple 1.5s ease-out infinite; 
  }
  @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(1.8); opacity: 0; } }
</style>

<script src="https://cdn.socket.io/4.7.2/socket.io.min.js"></script>

<script>
  import { i18n } from '../constants/i18n';
  
  const LANGUAGE_CODE_MAP = {
    ja: { tts: 'ja-JP', stt: 'ja-JP', voice: 'ja-JP-Chirp3-HD-Leda' },
    en: { tts: 'en-US', stt: 'en-US', voice: 'en-US-Studio-O' },
    zh: { tts: 'cmn-CN', stt: 'cmn-CN', voice: 'cmn-CN-Wavenet-A' },
    ko: { tts: 'ko-KR', stt: 'ko-KR', voice: 'ko-KR-Wavenet-A' }
  };

  document.addEventListener('DOMContentLoaded', () => {
    const container = document.querySelector('.gourmet-chat-container') as HTMLElement;
    if (!container) return;

    const apiBase = container.dataset.apiBase || '';

    // „Çπ„Éó„É©„ÉÉ„Ç∑„É•Âà∂Âæ°
    const splashOverlay = document.getElementById('splashOverlay') as HTMLDivElement;
    const splashVideo = document.getElementById('splashVideo') as HTMLVideoElement;
    function hideSplash() {
      if (splashVideo) splashVideo.loop = false;
      if (splashOverlay) {
        splashOverlay.classList.add('fade-out');
        setTimeout(() => splashOverlay.classList.add('hidden'), 800);
      }
    }
    setTimeout(() => hideSplash(), 10000);

    // DOMË¶ÅÁ¥†ÂèñÂæó
    const chatArea = document.getElementById('chatArea')!;
    const userInput = document.getElementById('userInput') as HTMLInputElement;
    const sendBtn = document.getElementById('sendBtn') as HTMLButtonElement;
    const speakerBtn = document.getElementById('speakerBtn') as HTMLButtonElement;
    const reservationBtn = document.getElementById('reservationBtn') as HTMLButtonElement;
    const voiceStatus = document.getElementById('voiceStatus')!;
    const languageSelect = document.getElementById('languageSelect') as HTMLSelectElement;
    const stopBtn = document.getElementById('stopBtn') as HTMLButtonElement;
    const micBtnFloat = document.getElementById('micBtnFloat') as HTMLButtonElement;
    const waitOverlay = document.getElementById('waitOverlay') as HTMLDivElement;
    const waitVideo = document.getElementById('waitVideo') as HTMLVideoElement;
    let waitOverlayTimer: number | null = null;

    // Â§âÊï∞ÂÆöÁæ©
    let currentLanguage: 'ja' | 'en' | 'zh' | 'ko' = 'ja';
    let sessionId: string | null = null;
    let isProcessing = false;
    let currentStage = 'conversation';
    let isRecording = false;
    let mediaRecorder: MediaRecorder | null = null;
    let audioChunks: Blob[] = [];
    let recordingTimer: number | null = null;
    const MAX_RECORDING_TIME = 55000;
    let isTTSEnabled = true;
    let isUserInteracted = false;
    let currentShops: any[] = [];
    let isFromVoiceInput = false;
    
    let lastAISpeech: string = '';
    let preGeneratedAcks: Map<string, string> = new Map();
    // AudioContext (Global)
    let globalAudioContext: AudioContext | null = null;
    let audioWorkletNode: AudioWorkletNode | null = null;
    let scriptProcessor: ScriptProcessorNode | null = null; // iOSÁî®
    let mediaStream: MediaStream | null = null;
    let socket: any = null;
    let streamingTranscript = '';
    let isStreamingSTT = false;
    let isSendingAudio = true;
    let isAISpeaking = false;
    let currentAISpeech = "";
    // VAD
    let analyser: AnalyserNode | null = null;
    let vadCheckInterval: number | null = null;
    let silenceTimer: number | null = null;
    let hasSpoken = false;
    let recordingStartTime = 0;

    const ttsPlayer = new Audio();
    const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);
    const isAndroid = /Android/i.test(navigator.userAgent);
    
    const SILENCE_THRESHOLD = 30; 
    const SILENCE_DURATION = 3000;
    const MIN_RECORDING_TIME = 3000;

    // ‰æøÂà©Èñ¢Êï∞
    function t(key: string, ...args: any[]): string {
      // @ts-ignore
      const translation = i18n[currentLanguage][key];
      if (typeof translation === 'function') return translation(...args);
      return translation || key;
    }

    // „É°„ÉÉ„Çª„Éº„Ç∏Ë°®Á§∫
    function addMessage(role: string, content: string, summary: string | null = null, isInitial: boolean = false) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${role}`;
      if (isInitial) messageDiv.setAttribute('data-initial', 'true');
      const avatar = document.createElement('div');
      avatar.className = 'message-avatar';
      avatar.innerHTML = role === 'assistant' ? 'üçΩ' : role === 'user' ? 'üë§' : '‚ö†';
      const contentDiv = document.createElement('div');
      contentDiv.className = 'message-content';
      const messageText = document.createElement('span');
      messageText.className = 'message-text';
      messageText.textContent = content;
      contentDiv.appendChild(messageText);
      messageDiv.appendChild(avatar);
      const wrapper = document.createElement('div');
      wrapper.appendChild(contentDiv);
      if (summary) {
        const summaryDiv = document.createElement('div');
        summaryDiv.className = 'summary-box';
        summaryDiv.innerHTML = `<strong>üìù ÂÜÖÂÆπÁ¢∫Ë™ç</strong>${summary}`;
        wrapper.appendChild(summaryDiv);
      }
      messageDiv.appendChild(wrapper);
      chatArea.appendChild(messageDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showError(message: string) {
      const errorDiv = document.createElement('div');
      errorDiv.className = 'error-message';
      errorDiv.textContent = message;
      chatArea.appendChild(errorDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showWaitOverlay() {
      waitOverlay.classList.remove('hidden');
      waitVideo.currentTime = 0;
      waitVideo.play().catch(e => console.log('Video err', e));
    }

    function hideWaitOverlay() {
      if (waitOverlayTimer) { clearTimeout(waitOverlayTimer); waitOverlayTimer = null; }
      waitOverlay.classList.add('hidden');
      setTimeout(() => waitVideo.pause(), 500);
    }

    function unlockAudioParams() {
      ttsPlayer.play().then(() => { ttsPlayer.pause(); ttsPlayer.currentTime = 0; }).catch(e => {});
      if (globalAudioContext && globalAudioContext.state === 'suspended') {
        globalAudioContext.resume();
      }
    }

    function enableAudioPlayback() {
      if (!isUserInteracted) {
        isUserInteracted = true;
        const clickPrompt = container.querySelector('.click-prompt');
        if (clickPrompt) clickPrompt.remove();
        unlockAudioParams();
      }
    }

    function showClickPrompt() {
      const prompt = document.createElement('div');
      prompt.className = 'click-prompt';
      prompt.innerHTML = `<p>üîä</p><p>${t('clickPrompt')}</p><p>üîä</p>`;
      prompt.addEventListener('click', enableAudioPlayback);
      container.style.position = 'relative';
      container.appendChild(prompt);
    }

    function stopCurrentAudio() {
      ttsPlayer.pause();
      ttsPlayer.currentTime = 0;
    }

    function stripMarkdown(text: string): string {
      return text.replace(/\*\*([^*]+)\*\*/g, '$1').replace(/\*([^*]+)\*/g, '$1').replace(/__([^_]+)__/g, '$1').replace(/_([^_]+)_/g, '$1').replace(/^#+\s*/gm, '').replace(/\[([^\]]+)\]\([^)]+\)/g, '$1').replace(/`([^`]+)`/g, '$1').replace(/^(\d+)\.\s+/gm, '$1Áï™ÁõÆ„ÄÅ').replace(/\s+/g, ' ').trim();
    }

    function normalizeText(text: string): string {
      return text.replace(/\s+/g, '').replace(/[„ÄÅ„ÄÇÔºÅÔºü,.!?]/g, '').toLowerCase();
    }

    function removeFillers(text: string): string {
      // @ts-ignore
      const pattern = i18n[currentLanguage].patterns.fillers;
      return text.replace(pattern, '');
    }

    function generateFallbackResponse(text: string): string {
      return t('fallbackResponse', text);
    }

    function selectSmartAcknowledgment(userMessage: string): { text: string, logText: string } {
      const messageLower = userMessage.trim();
      // @ts-ignore
      const p = i18n[currentLanguage].patterns;
      if (p.ackQuestions.test(messageLower)) return { text: t('ackConfirm'), logText: `Ë≥™ÂïèÂΩ¢Âºè` };
      if (p.ackLocation.test(messageLower)) return { text: t('ackSearch'), logText: `Â†¥ÊâÄ` };
      if (p.ackSearch.test(messageLower)) return { text: t('ackUnderstood'), logText: `Ê§úÁ¥¢` };
      return { text: t('ackYes'), logText: `„Éá„Éï„Ç©„É´„Éà` };
    }

    function extractShopsFromResponse(text: string): any[] {
      const shops: any[] = [];
      const pattern = /(\d+)\.\s*\*\*([^*]+)\*\*[Ôºö:]\s*([^\n]+)/g;
      let match;
      while ((match = pattern.exec(text)) !== null) {
        const fullName = match[2].trim();
        const description = match[3].trim();
        let name = fullName;
        const nameMatch = fullName.match(/^([^Ôºà(]+)[Ôºà(]([^Ôºâ)]+)[Ôºâ)]/);
        if (nameMatch) name = nameMatch[1].trim();
        const encodedName = encodeURIComponent(name);
        shops.push({ name: name, description: description, category: '„Ç§„Çø„É™„Ç¢„É≥', hotpepper_url: `https://www.hotpepper.jp/SA11/srchRS/?keyword=${encodedName}`, maps_url: `https://www.google.com/maps/search/${encodedName}`, tabelog_url: `https://tabelog.com/rstLst/?vs=1&sa=&sk=${encodedName}` });
      }
      return shops;
    }

    function updateUILanguage() {
      voiceStatus.innerHTML = t('voiceStatusStopped');
      userInput.placeholder = t('inputPlaceholder');
      micBtnFloat.title = t('btnVoiceInput');
      speakerBtn.title = isTTSEnabled ? t('btnTTSOn') : t('btnTTSOff');
      sendBtn.textContent = t('btnSend');
      reservationBtn.innerHTML = t('btnReservation');
      const waitText = document.querySelector('.wait-text');
      if (waitText) waitText.textContent = t('waitMessage');

      const pageTitle = document.getElementById('pageTitle');
      if (pageTitle) pageTitle.innerHTML = `<img src="/pwa-152x152.png" alt="Logo" class="app-logo" /> ${t('pageTitle')}`;
      const pageSubtitle = document.getElementById('pageSubtitle');
      if (pageSubtitle) pageSubtitle.textContent = t('pageSubtitle');
      const shopListTitle = document.getElementById('shopListTitle');
      if (shopListTitle) shopListTitle.innerHTML = `üçΩ ${t('shopListTitle')}`;
      const shopListEmpty = document.getElementById('shopListEmpty');
      if (shopListEmpty) shopListEmpty.textContent = t('shopListEmpty');
      const pageFooter = document.getElementById('pageFooter');
      if (pageFooter) pageFooter.innerHTML = `${t('footerMessage')} ‚ú®`;

      const initialMessage = chatArea.querySelector('.message.assistant[data-initial="true"]');
      if (initialMessage) {
        const messageText = initialMessage.querySelector('.message-text');
        if (messageText) messageText.textContent = t('initialGreeting');
      }

      document.dispatchEvent(new CustomEvent('languageChange', { detail: { language: currentLanguage } }));
    }

    async function speakTextGCP(text: string, stopPrevious: boolean = true, autoRestartMic: boolean = false) {
      if (!isTTSEnabled || !text) return;
      if (stopPrevious) ttsPlayer.pause();
      const cleanText = stripMarkdown(text);
      try {
        isAISpeaking = true;
        if (isAndroid && isRecording) { stopStreamingSTT(); }
        voiceStatus.innerHTML = t('voiceStatusSynthesizing');
        voiceStatus.className = 'voice-status speaking';
        const langConfig = LANGUAGE_CODE_MAP[currentLanguage];
        const response = await fetch(`${apiBase}/api/tts/synthesize`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text: cleanText, language_code: langConfig.tts, voice_name: langConfig.voice })
        });
        const data = await response.json();
        if (data.success && data.audio) {
          ttsPlayer.src = `data:audio/mp3;base64,${data.audio}`;
          const playPromise = new Promise<void>((resolve) => {
            ttsPlayer.onended = async () => {
              voiceStatus.innerHTML = t('voiceStatusStopped');
              voiceStatus.className = 'voice-status stopped';
              isAISpeaking = false;
              if (autoRestartMic) {
                if (isAndroid || !isRecording) { try { await startStreamingSTT(); } catch (error) { showMicPrompt(); } }
              }
              resolve();
            };
            ttsPlayer.onerror = () => { isAISpeaking = false; resolve(); };
          });
          if (isUserInteracted) {
            lastAISpeech = normalizeText(cleanText);
            await ttsPlayer.play();
            await playPromise;
          } else {
            showClickPrompt();
            voiceStatus.innerHTML = t('voiceStatusStopped');
            voiceStatus.className = 'voice-status stopped';
            isAISpeaking = false;
          }
        } else { isAISpeaking = false; }
      } catch (error) {
        voiceStatus.innerHTML = t('voiceStatusStopped');
        voiceStatus.className = 'voice-status stopped';
        isAISpeaking = false;
      }
    }

    function showMicPrompt() {
      const modal = document.createElement('div');
      modal.id = 'mic-prompt-modal';
      modal.style.cssText = `position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: rgba(0, 0, 0, 0.8); display: flex; align-items: center; justify-content: center; z-index: 10000; animation: fadeIn 0.3s ease;`;
      modal.innerHTML = `
        <div style="background: white; border-radius: 16px; padding: 24px; max-width: 90%; width: 350px; text-align: center; box-shadow: 0 8px 32px rgba(0,0,0,0.3);">
          <div style="font-size: 48px; margin-bottom: 16px;">üé§</div>
          <div style="font-size: 18px; font-weight: 700; margin-bottom: 8px; color: #333;">„Éû„Ç§„ÇØ„ÇíON„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ</div>
          <div style="font-size: 14px; color: #666; margin-bottom: 20px;">AI„ÅÆÂõûÁ≠î„ÅåÁµÇ„Çè„Çä„Åæ„Åó„Åü„ÄÇ<br>Á∂ö„Åë„Å¶Ë©±„Åô„Å´„ÅØ„Éû„Ç§„ÇØ„Éú„Çø„É≥„Çí„Çø„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</div>
          <button id="mic-prompt-btn" style="background: linear-gradient(135deg, #10b981 0%, #059669 100%); color: white; border: none; padding: 14px 32px; border-radius: 24px; font-size: 16px; font-weight: 600; cursor: pointer; box-shadow: 0 4px 12px rgba(16, 185, 129, 0.3);">üé§ „Éû„Ç§„ÇØON</button>
        </div>
      `;
      const style = document.createElement('style');
      style.textContent = `@keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }`;
      document.head.appendChild(style);
      document.body.appendChild(modal);
      const btn = document.getElementById('mic-prompt-btn');
      btn?.addEventListener('click', async () => { modal.remove(); await toggleRecording(); });
      setTimeout(() => { if (document.getElementById('mic-prompt-modal')) { modal.remove(); } }, 3000);
    }

    function isSemanticEcho(transcript: string, aiText: string): boolean {
      if (!aiText || !transcript) return false;
      const normTranscript = normalizeText(transcript);
      const normAI = normalizeText(aiText);
      if (normAI === normTranscript) return true;
      if (normAI.includes(normTranscript) && normTranscript.length > 5) return true;
      return false;
    }

    // ËªΩÈáèBase64
    const b64chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
    function fastArrayBufferToBase64(buffer: ArrayBuffer) {
      let binary = '';
      const bytes = new Uint8Array(buffer);
      const len = bytes.byteLength;
      for (let i = 0; i < len; i += 3) {
        const c1 = bytes[i];
        const c2 = bytes[i + 1];
        const c3 = bytes[i + 2];
        const enc1 = c1 >> 2;
        const enc2 = ((c1 & 3) << 4) | (c2 >> 4);
        const enc3 = ((c2 & 15) << 2) | (c3 >> 6);
        const enc4 = c3 & 63;
        binary += b64chars[enc1] + b64chars[enc2];
        if (Number.isNaN(c2)) { binary += '=='; } 
        else if (Number.isNaN(c3)) { binary += b64chars[enc3] + '='; } 
        else { binary += b64chars[enc3] + b64chars[enc4]; }
      }
      return binary;
    }

    async function startStreamingSTT() {
      try {
        if (splashVideo) { splashVideo.pause(); }
        if (waitVideo) { waitVideo.pause(); }
        if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
        
        // „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
        if (audioWorkletNode) { audioWorkletNode.port.onmessage = null; audioWorkletNode.disconnect(); audioWorkletNode = null; }
        if (scriptProcessor) { scriptProcessor.onaudioprocess = null; scriptProcessor.disconnect(); scriptProcessor = null; }
        
        // AudioContext
        if (!globalAudioContext) {
          try {
            globalAudioContext = new AudioContext({ latencyHint: isIOS ? 'interactive' : 'playback' });
          } catch (e) {
            addMessage('system', 'AudioContext‰ΩúÊàê„Ç®„É©„Éº');
            throw e;
          }
        }
        
        if (globalAudioContext.state === 'suspended') {
          await globalAudioContext.resume();
        }
        
        if (mediaStream) { mediaStream.getTracks().forEach(track => track.stop()); mediaStream = null; }
        
        try {
          const audioConstraints: any = { 
            channelCount: 1,
            echoCancellation: isIOS ? false : true,
            noiseSuppression: isIOS ? false : true,
            autoGainControl: true 
          };
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });
        } catch (micError: any) {
          addMessage('system', `„Éû„Ç§„ÇØ„Ç®„É©„Éº: ${micError.message}`);
          throw micError;
        }
        
        const targetSampleRate = 16000;
        const nativeSampleRate = globalAudioContext.sampleRate;
        const downsampleRatio = nativeSampleRate / targetSampleRate;
        
        const source = globalAudioContext.createMediaStreamSource(mediaStream);
        
        // ‚òÖ‚òÖ‚òÖ iOS: ScriptProcessorNode (Èü≥È£õ„Å≥ÂõûÈÅø + Á∑öÂΩ¢Ë£úÈñì) ‚òÖ‚òÖ‚òÖ
        if (isIOS) {
            const bufferSize = 4096;
            scriptProcessor = globalAudioContext.createScriptProcessor(bufferSize, 1, 1);
            
            let readIndex = 0;
            const outputBuffer = new Int16Array(bufferSize); 
            
            scriptProcessor.onaudioprocess = (audioProcessingEvent) => {
                if (!isSendingAudio || !socket || !socket.connected) return;
                
                const inputBuffer = audioProcessingEvent.inputBuffer;
                const channelData = inputBuffer.getChannelData(0);
                
                let writeIndex = 0;
                
                // ‚òÖ Á∑öÂΩ¢Ë£úÈñì
                while (readIndex < channelData.length) {
                    const i = Math.floor(readIndex);
                    const frac = readIndex - i;
                    const v1 = channelData[i];
                    const v2 = (i + 1 < channelData.length) ? channelData[i + 1] : v1;
                    const value = v1 * (1 - frac) + v2 * frac;
                    const int16Value = Math.max(-32768, Math.min(32767, value < 0 ? value * 0x8000 : value * 0x7FFF));
                    outputBuffer[writeIndex++] = int16Value;
                    readIndex += downsampleRatio;
                }
                readIndex -= channelData.length;
                
                if (writeIndex > 0) {
                    const chunk = outputBuffer.slice(0, writeIndex);
                    try {
                        const base64 = fastArrayBufferToBase64(chunk.buffer);
                        socket.emit('audio_chunk', { chunk: base64, sample_rate: 16000 });
                    } catch (e) { console.error(e); }
                }
            };
            
            source.connect(scriptProcessor);
            scriptProcessor.connect(globalAudioContext.destination);
            
        } else {
            // ‚òÖ PC/Android: AudioWorklet (Á∑öÂΩ¢Ë£úÈñì)
            const audioProcessorCode = `
class AudioProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.bufferSize = 4096;
    this.buffer = new Int16Array(this.bufferSize); 
    this.writeIndex = 0;
    this.ratio = ${downsampleRatio}; 
    this.readIndex = 0;
  }
  process(inputs, outputs, parameters) {
    const input = inputs[0];
    if (!input || input.length === 0) return true;
    const channelData = input[0];
    
    let i = 0;
    while (this.readIndex < channelData.length) {
       const idx = Math.floor(this.readIndex);
       const frac = this.readIndex - idx;
       const v1 = channelData[idx];
       const v2 = (idx + 1 < channelData.length) ? channelData[idx + 1] : v1;
       let value = v1 * (1 - frac) + v2 * frac;
       const int16Value = value < 0 ? value * 0x8000 : value * 0x7FFF;
       if (this.writeIndex < this.bufferSize) {
         this.buffer[this.writeIndex++] = int16Value;
       }
       this.readIndex += this.ratio;
       if (this.writeIndex >= this.bufferSize) {
         this.flush();
       }
    }
    this.readIndex -= channelData.length;
    return true;
  }
  flush() {
    if (this.writeIndex === 0) return;
    const chunk = this.buffer.slice(0, this.writeIndex);
    this.port.postMessage({ audioChunk: chunk }, [chunk.buffer]);
    this.writeIndex = 0;
  }
}
registerProcessor('audio-processor', AudioProcessor);
`;
            try {
                const blob = new Blob([audioProcessorCode], { type: 'application/javascript' });
                const processorUrl = URL.createObjectURL(blob);
                await globalAudioContext.audioWorklet.addModule(processorUrl);
                URL.revokeObjectURL(processorUrl);
                audioWorkletNode = new AudioWorkletNode(globalAudioContext, 'audio-processor');
                audioWorkletNode.port.onmessage = (event) => {
                    const { audioChunk } = event.data;
                    if (!isSendingAudio || !socket || !socket.connected) return;
                    try {
                        const base64 = fastArrayBufferToBase64(audioChunk.buffer);
                        socket.emit('audio_chunk', { chunk: base64, sample_rate: 16000 });
                    } catch (e) { }
                };
                source.connect(audioWorkletNode);
                audioWorkletNode.connect(globalAudioContext.destination);
            } catch(e) { console.error(e); }
        }
        
        // VAD
        analyser = globalAudioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        hasSpoken = false; recordingStartTime = Date.now();
        
        if (vadCheckInterval) clearInterval(vadCheckInterval);
        vadCheckInterval = window.setInterval(() => {
          if (!analyser || !isRecording) return;
          if (Date.now() - recordingStartTime < MIN_RECORDING_TIME) return;
          analyser.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
          if (average > SILENCE_THRESHOLD) { 
            hasSpoken = true; 
            if (silenceTimer) { clearTimeout(silenceTimer); silenceTimer = null; }
            voiceStatus.innerHTML = t('voiceStatusRecording'); 
          } else if (hasSpoken && !silenceTimer) { 
            voiceStatus.innerHTML = t('voiceStatusWaiting'); 
            silenceTimer = window.setTimeout(() => { stopStreamingSTT(); }, SILENCE_DURATION); 
          }
        }, 100);
        
        if (socket && socket.connected) {
          socket.emit('stop_stream');
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        socket.emit('start_stream', { language_code: LANGUAGE_CODE_MAP[currentLanguage].stt, sample_rate: 16000 });
        isSendingAudio = true;
        isRecording = true; micBtnFloat.classList.add('recording');
        voiceStatus.innerHTML = t('voiceStatusListening');
        recordingTimer = window.setTimeout(() => { 
          if (isRecording) { stopStreamingSTT(); addMessage('system', t('recordingTimeLimit')); } 
        }, MAX_RECORDING_TIME);
        
      } catch (error: any) {
        if (mediaStream) { mediaStream.getTracks().forEach(track => track.stop()); mediaStream = null; }
        if (!error.message?.includes('„Éû„Ç§„ÇØ')) { addMessage('system', `${t('micAccessError')} ${error.message || 'Unknown error'}`); }
      }
    }

    function stopStreamingSTT() {
      if (vadCheckInterval) { clearInterval(vadCheckInterval); vadCheckInterval = null; }
      if (silenceTimer) { clearTimeout(silenceTimer); silenceTimer = null; }
      if (analyser) { analyser.disconnect(); analyser = null; }
      if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
      
      if (scriptProcessor) { scriptProcessor.onaudioprocess = null; scriptProcessor.disconnect(); scriptProcessor = null; }
      if (audioWorkletNode) { audioWorkletNode.port.onmessage = null; audioWorkletNode.disconnect(); audioWorkletNode = null; }
      
      if (mediaStream) { mediaStream.getTracks().forEach(track => track.stop()); mediaStream = null; }
      if (socket && socket.connected) { socket.emit('stop_stream'); }
      isSendingAudio = false; isRecording = false; micBtnFloat.classList.remove('recording');
    }

    // ÁúÅÁï•„Åï„Çå„Å¶„ÅÑ„ÅüLegacyÈñ¢Êï∞„ÇíÂÆöÁæ©ÔºàiPhone‰ª•Â§ñ„Åß‰ΩøÁî®ÂèØËÉΩÊÄß„ÅÇ„ÇäÔºâ
    async function startLegacyRecording() { /* ... */ }
    async function transcribeAudio(audioBlob: Blob) { /* ... */ }

    function initializeWebSocketSTT() {
      try {
        const wsUrl = apiBase || window.location.origin;
        socket = io(wsUrl);
        socket.on('connect', () => { isStreamingSTT = true; });
        socket.on('disconnect', () => { isStreamingSTT = false; });
        socket.on('transcript', (data: any) => {
          const { text, is_final } = data;
          if (isAISpeaking) return;
          if (is_final) { 
            streamingTranscript = text; 
            handleStreamingSTTComplete(text);
            currentAISpeech = "";
          } else { 
            userInput.value = text;
          }
        });
        socket.on('error', (data: any) => { 
          addMessage('system', `${t('sttError')} ${data.message}`);
          if (isRecording) stopStreamingSTT();
        });
      } catch (error) { isStreamingSTT = false; }
    }

    async function handleStreamingSTTComplete(transcript: string) {
      stopStreamingSTT();
      voiceStatus.innerHTML = t('voiceStatusComplete');
      voiceStatus.className = 'voice-status';
      const normTranscript = normalizeText(transcript);
      if (isSemanticEcho(normTranscript, lastAISpeech)) {
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          lastAISpeech = '';
          return;
      }
      userInput.value = transcript;
      // @ts-ignore
      if (i18n[currentLanguage].patterns.dateCheck.test(transcript)) {
        const msg = t('dateWarningMsg');
        currentAISpeech = msg;
        addMessage('assistant', msg);
        if (isTTSEnabled && isUserInteracted) { await speakTextGCP(msg, true, true); } 
        else { await new Promise(r => setTimeout(r, 2000)); }
        userInput.value = '';
        voiceStatus.innerHTML = t('voiceStatusStopped');
        voiceStatus.className = 'voice-status stopped';
        return;
      }
      addMessage('user', transcript);
      const textLength = transcript.trim().replace(/\s+/g, '').length;
      if (textLength < 4) {
          const msg = t('shortMsgWarning');
          addMessage('assistant', msg);
          isSendingAudio = false;
          if (isTTSEnabled && isUserInteracted) { await speakTextGCP(msg, true); }
          else { await new Promise(r => setTimeout(r, 2000)); }
          isSendingAudio = true;
          userInput.value = '';
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          return;
      }
      const ack = selectSmartAcknowledgment(transcript);
      const preGeneratedAudio = preGeneratedAcks.get(ack.text);
      let firstAckPromise: Promise<void> | null = null;
      if (preGeneratedAudio && isTTSEnabled && isUserInteracted) {
        firstAckPromise = new Promise<void>((resolve) => {
          lastAISpeech = normalizeText(ack.text);
          ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
          ttsPlayer.onended = () => resolve();
          ttsPlayer.play().catch(e => resolve());
        });
      } else if (isTTSEnabled) { firstAckPromise = speakTextGCP(ack.text, false); }
      addMessage('assistant', ack.text);
      (async () => {
        try {
          if (firstAckPromise) await firstAckPromise;
          const cleanText = removeFillers(transcript);
          const fallbackResponse = generateFallbackResponse(cleanText);
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
          addMessage('assistant', fallbackResponse);
          setTimeout(async () => {
            const additionalResponse = t('additionalResponse');
            if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
            addMessage('assistant', additionalResponse);
          }, 3000);
          if (userInput.value.trim()) { isFromVoiceInput = true; sendMessage(); }
        } catch (error) { if (userInput.value.trim()) { isFromVoiceInput = true; sendMessage(); } }
      })();
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
    }

    async function sendMessage() {
      let firstAckPromise: Promise<void> | null = null; 
      unlockAudioParams();
      const message = userInput.value.trim();
      if (!message || isProcessing) return;
      isProcessing = true; sendBtn.disabled = true;
      micBtnFloat.disabled = true; userInput.disabled = true;
      if (!isFromVoiceInput) {
        addMessage('user', message);
        // @ts-ignore
        if (i18n[currentLanguage].patterns.dateCheck.test(message)) {
             const msg = t('dateWarningMsg');
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             addMessage('assistant', msg);
             userInput.value = ''; isProcessing = false; sendBtn.disabled = false;
             micBtnFloat.disabled = false; userInput.disabled = false; userInput.focus();
             return;
        }
        const textLength = message.trim().replace(/\s+/g, '').length;
        if (textLength < 4) {
             const msg = t('shortMsgWarning');
             addMessage('assistant', msg);
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             userInput.value = ''; isProcessing = false; sendBtn.disabled = false;
             micBtnFloat.disabled = false; userInput.disabled = false; userInput.focus();
             return;
        }
        userInput.value = '';
        const ack = selectSmartAcknowledgment(message);
        currentAISpeech = ack.text;
        addMessage('assistant', ack.text);
        if (isTTSEnabled) {
          try {
            const preGeneratedAudio = preGeneratedAcks.get(ack.text);
            if (preGeneratedAudio && isUserInteracted) {
              firstAckPromise = new Promise<void>((resolve) => {
                lastAISpeech = normalizeText(ack.text);
                ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
                ttsPlayer.onended = () => resolve();
                ttsPlayer.play().catch(e => resolve());
              });
            } else { firstAckPromise = speakTextGCP(ack.text, false); }
          } catch (e) {}
        }
        if (firstAckPromise) await firstAckPromise;
        const cleanText = removeFillers(message);
        const fallbackResponse = generateFallbackResponse(cleanText);
        if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
        addMessage('assistant', fallbackResponse);
        setTimeout(async () => {
          const additionalResponse = t('additionalResponse');
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
          addMessage('assistant', additionalResponse);
        }, 3000);
      }
      const wasVoiceInput = isFromVoiceInput;
      isFromVoiceInput = false;
      if (waitOverlayTimer) clearTimeout(waitOverlayTimer);
      waitOverlayTimer = window.setTimeout(() => { showWaitOverlay(); }, 4000);
      try {
        const response = await fetch(`${apiBase}/api/chat`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ session_id: sessionId, message: message, stage: currentStage, language: currentLanguage }) });
        const data = await response.json();
        hideWaitOverlay();
        currentAISpeech = data.response;
        addMessage('assistant', data.response, data.summary);
        stopCurrentAudio();
        if (data.shops && data.shops.length > 0) {
          currentShops = data.shops;
          reservationBtn.disabled = false;
          userInput.value = '';
          document.dispatchEvent(new CustomEvent('displayShops', { detail: { shops: data.shops, language: currentLanguage } }));
          const section = document.getElementById('shopListSection');
          if (section) section.classList.add('has-shops');
          if (window.innerWidth < 1024) { setTimeout(() => { const shopSection = document.getElementById('shopListSection'); if (shopSection) { shopSection.scrollIntoView({ behavior: 'smooth', block: 'start' }); } }, 300); }
          
          (async () => {
            try {
              isAISpeaking = true;
              if (isAndroid && isRecording) { stopStreamingSTT(); }
              await speakTextGCP(t('ttsIntro'));
              const lines = data.response.split('\n\n');
              let introText = ""; let shopLines = lines;
              if (lines[0].includes('„ÅîÂ∏åÊúõ„Å´Âêà„ÅÜ„ÅäÂ∫ó') && lines[0].includes('„ÅîÁ¥π‰ªã„Åó„Åæ„Åô')) { introText = lines[0]; shopLines = lines.slice(1); }
              let introPart2Promise: Promise<void> | null = null;
              if (introText && isTTSEnabled && isUserInteracted) {
                const preGeneratedIntro = preGeneratedAcks.get(introText);
                if (preGeneratedIntro) {
                  introPart2Promise = new Promise<void>((resolve) => {
                    lastAISpeech = normalizeText(introText);
                    ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedIntro}`;
                    ttsPlayer.onended = () => resolve();
                    ttsPlayer.play();
                  });
                } else { introPart2Promise = speakTextGCP(introText, false); }
              }
              let firstShopAudioPromise: Promise<string | null> | null = null;
              let remainingAudioPromise: Promise<string | null> | null = null;
              const shopLangConfig = LANGUAGE_CODE_MAP[currentLanguage];
              if (shopLines.length > 0 && isTTSEnabled && isUserInteracted) {
                const firstShop = shopLines[0];
                const restShops = shopLines.slice(1).join('\n\n');
                firstShopAudioPromise = (async () => {
                  const cleanText = stripMarkdown(firstShop);
                  const response = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: cleanText, language_code: shopLangConfig.tts, voice_name: shopLangConfig.voice }) });
                  const result = await response.json();
                  return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                })();
                if (restShops) {
                  remainingAudioPromise = (async () => {
                    const cleanText = stripMarkdown(restShops);
                    const response = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: cleanText, language_code: shopLangConfig.tts, voice_name: shopLangConfig.voice }) });
                    const result = await response.json();
                    return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                  })();
                }
              }
              if (introPart2Promise) await introPart2Promise;
              if (firstShopAudioPromise) {
                const firstShopAudio = await firstShopAudioPromise;
                if (firstShopAudio) {
                  const firstShopText = stripMarkdown(shopLines[0]);
                  lastAISpeech = normalizeText(firstShopText);
                  stopCurrentAudio(); ttsPlayer.src = firstShopAudio;
                  await new Promise<void>((resolve) => { ttsPlayer.onended = () => { voiceStatus.innerHTML = t('voiceStatusStopped'); voiceStatus.className = 'voice-status stopped'; resolve(); }; voiceStatus.innerHTML = t('voiceStatusSpeaking'); voiceStatus.className = 'voice-status speaking'; ttsPlayer.play(); });
                  if (remainingAudioPromise) {
                    const remainingAudio = await remainingAudioPromise;
                    if (remainingAudio) {
                      const restShopsText = stripMarkdown(shopLines.slice(1).join('\n\n'));
                      lastAISpeech = normalizeText(restShopsText);
                      await new Promise(r => setTimeout(r, 500));
                      stopCurrentAudio(); ttsPlayer.src = remainingAudio;
                      await new Promise<void>((resolve) => { ttsPlayer.onended = () => { voiceStatus.innerHTML = 'üé§ Èü≥Â£∞Ë™çË≠ò: ÂÅúÊ≠¢‰∏≠'; voiceStatus.className = 'voice-status stopped'; resolve(); }; voiceStatus.innerHTML = 'üîä Èü≥Â£∞ÂÜçÁîü‰∏≠...'; voiceStatus.className = 'voice-status speaking'; ttsPlayer.play(); });
                    }
                  }
                }
              }
              isAISpeaking = false;
            } catch (e) { isAISpeaking = false; }
          })();
        } else {
          if (data.response) {
            const extractedShops = extractShopsFromResponse(data.response);
            if (extractedShops.length > 0) {
              currentShops = extractedShops;
              reservationBtn.disabled = false;
              document.dispatchEvent(new CustomEvent('displayShops', { detail: { shops: extractedShops, language: currentLanguage } }));
              const section = document.getElementById('shopListSection');
              if (section) section.classList.add('has-shops');
              speakTextGCP(data.response);
            } else { speakTextGCP(data.response); }
          }
        }
      } catch (error) { console.error('ÈÄÅ‰ø°„Ç®„É©„Éº:', error);
      hideWaitOverlay(); showError('„É°„ÉÉ„Çª„Éº„Ç∏„ÅÆÈÄÅ‰ø°„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ'); }
      finally { isProcessing = false; sendBtn.disabled = false; micBtnFloat.disabled = false;
      userInput.disabled = false; if (currentShops.length === 0) userInput.focus(); else userInput.blur();
      }
    }

    async function toggleRecording() {
      enableAudioPlayback();
      userInput.value = '';
      stopCurrentAudio();
      if (isRecording) { 
        stopAllActivities();
        return; 
      }
      if (isStreamingSTT) { 
        await new Promise(r => setTimeout(r, 100));
        await startStreamingSTT(); 
      } else { 
        await startLegacyRecording();
      }
    }

    function toggleTTS() {
      if (!isUserInteracted) { enableAudioPlayback(); return; }
      enableAudioPlayback();
      isTTSEnabled = !isTTSEnabled;
      speakerBtn.innerHTML = isTTSEnabled ? 'üîä' : 'üîá';
      speakerBtn.title = isTTSEnabled ? t('btnTTSOn') : t('btnTTSOff');
      speakerBtn.className = isTTSEnabled ? 'btn btn-icon btn-speaker' : 'btn btn-icon btn-speaker disabled';
      if (!isTTSEnabled) stopCurrentAudio();
    }

    function stopAllActivities() {
      if (isProcessing) {
        fetch(`${apiBase}/api/cancel`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ session_id: sessionId })
        }).catch(err => console.error('‰∏≠Ê≠¢„É™„ÇØ„Ç®„Çπ„ÉàÂ§±Êïó:', err));
      }
      if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
      if (isRecording) stopStreamingSTT();
      stopCurrentAudio();
      waitOverlay.classList.add('hidden');
      if (waitOverlayTimer) { clearTimeout(waitOverlayTimer); waitOverlayTimer = null; }
      isProcessing = false;
      isAISpeaking = false;
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
      userInput.value = '';
      userInput.focus();
      if (window.innerWidth < 1024) {
        setTimeout(() => { chatArea.scrollIntoView({ behavior: 'smooth', block: 'start' }); }, 100);
      }
    }

    // ‚òÖ‚òÖ‚òÖ ‰øÆÊ≠£ÔºöÂâçÂõûÂÖ•„ÇåÂøò„Çå„Å¶„ÅÑ„Åü initialize Èñ¢Êï∞„ÇíÂÆöÁæ© ‚òÖ‚òÖ‚òÖ
    async function initialize() {
        try {
            const response = await fetch(`${apiBase}/api/session/start`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ user_info: {}, language: currentLanguage }) });
            const data = await response.json(); sessionId = data.session_id;
            addMessage('assistant', t('initialGreeting'), null, true);
            const ackTexts = [t('ackConfirm'), t('ackSearch'), t('ackUnderstood'), t('ackYes'), t('ttsIntro')];
            const langConfig = LANGUAGE_CODE_MAP[currentLanguage];
            const ackPromises = ackTexts.map(async (text) => {
              try {
                const ackResponse = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: text, language_code: langConfig.tts, voice_name: langConfig.voice }) });
                const ackData = await ackResponse.json();
                if (ackData.success && ackData.audio) preGeneratedAcks.set(text, ackData.audio);
              } catch (e) {}
            });
            await Promise.all([speakTextGCP(t('initialGreeting')), ...ackPromises]);
            userInput.disabled = false; sendBtn.disabled = false; micBtnFloat.disabled = false; speakerBtn.disabled = false; userInput.focus();
            if (splashOverlay) hideSplash();
            initializeWebSocketSTT();
            updateUILanguage();
        } catch(e) { console.error(e); }
    }

    // „Ç§„Éô„É≥„Éà„É™„Çπ„Éä„ÉºÁôªÈå≤
    languageSelect.addEventListener('change', () => { currentLanguage = languageSelect.value as any; updateUILanguage(); });
    sendBtn.addEventListener('click', sendMessage);
    micBtnFloat.addEventListener('click', toggleRecording);
    speakerBtn.addEventListener('click', toggleTTS);
    userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') sendMessage(); });
    reservationBtn.addEventListener('click', openReservationModal);
    
    // „ÇΩ„Éï„Éà„Ç≠„Éº„Éú„Éº„ÉâÊ§úÁü•
    const floatingButtons = document.querySelector('.floating-buttons') as HTMLElement;
    userInput.addEventListener('focus', () => {
      setTimeout(() => { if (floatingButtons) floatingButtons.classList.add('keyboard-active'); }, 300);
    });
    userInput.addEventListener('blur', () => {
      if (floatingButtons) floatingButtons.classList.remove('keyboard-active');
    });
    
    stopBtn.addEventListener('click', () => { stopAllActivities(); });
    
    // ÊúÄÂæå„Å´ÂàùÊúüÂåñ„ÇíÂÆüË°å
    initialize();
  });
</script>
