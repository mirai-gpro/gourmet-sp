---
// GourmetChat.astro - iPhoneå¯¾å¿œãƒ»ä¿å®ˆæ€§é‡è¦–ãƒ»i18nå¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ç¶­æŒç‰ˆ
import { i18n as sourceI18n } from '../constants/i18n';

export interface Props {
  apiBaseUrl?: string;
}

const { apiBaseUrl = '' } = Astro.props;

// ã€ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰å‡¦ç†ã€‘
// ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ï¼‰ã«æ¸¡ã™ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢ã—ã¾ã™ã€‚
// define:varsã§æ¸¡ã™éš›ã€æ­£è¦è¡¨ç¾(RegExp)ã‚„é–¢æ•°ã¯æ¶ˆãˆã¦ã—ã¾ã†ãŸã‚ã€æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦æ¸¡ã—ã¾ã™ã€‚
const clientI18n = {};

// è¨€èªã”ã¨ã«ãƒ«ãƒ¼ãƒ—ã—ã¦å‡¦ç†
Object.keys(sourceI18n).forEach(lang => {
  const source = sourceI18n[lang];
  // å¿…è¦ãªãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã ã‘ã‚’ã‚³ãƒ”ãƒ¼
  clientI18n[lang] = {
    ...source,
    // é–¢æ•°ã¯æ¸¡ã›ãªã„ã®ã§nullã«ã—ã¦ãŠãï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§å†å®šç¾©ã™ã‚‹ï¼‰
    fallbackResponse: null, 
    patterns: {}
  };

  // æ­£è¦è¡¨ç¾(RegExp)ã‚’æ–‡å­—åˆ—(.source)ã«å¤‰æ›ã—ã¦æ ¼ç´
  // ã“ã‚Œã«ã‚ˆã‚ŠJSONåŒ–ã•ã‚Œã¦ã‚‚æ­£è¦è¡¨ç¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±ãŒç¶­æŒã•ã‚Œã¾ã™
  if (source.patterns) {
    Object.keys(source.patterns).forEach(key => {
      const regex = source.patterns[key];
      // æ­£è¦è¡¨ç¾ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãªã‚‰sourceï¼ˆæ–‡å­—åˆ—ï¼‰ã‚’ã€ãã†ã§ãªã‘ã‚Œã°ãã®ã¾ã¾æ¸¡ã™
      clientI18n[lang].patterns[key] = regex instanceof RegExp ? regex.source : regex;
    });
  }
});
---

<div class="gourmet-chat-container" data-api-base={apiBaseUrl}>
  <div class="splash-overlay" id="splashOverlay">
    <video id="splashVideo" class="splash-video" autoplay muted playsinline loop>
      <source src="/splash.mp4" type="video/mp4">
    </video>
    <div class="splash-loading"><div class="spinner"></div><p>æº–å‚™ä¸­...</p></div>
  </div>

  <div class="wait-overlay hidden" id="waitOverlay">
    <div class="wait-content">
      <video id="waitVideo" class="wait-video" muted playsinline loop>
        <source src="/wait.mp4" type="video/mp4">
      </video>
      <p class="wait-text">AIãŒãŠåº—ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™...</p>
    </div>
  </div>

  <div class="language-selector">
    <select id="languageSelect" class="language-dropdown">
      <option value="ja">æ—¥æœ¬èª (Japanese)</option>
      <option value="en">English</option>
      <option value="zh">ä¸­æ–‡ (Chinese)</option>
      <option value="ko">í•œêµ­ì–´ (Korean)</option>
    </select>
  </div>

  <div class="voice-status stopped" id="voiceStatus">ğŸ¤ éŸ³å£°èªè­˜: åœæ­¢ä¸­</div>
  <div class="chat-area" id="chatArea"></div>

  <div class="input-area">
    <div class="input-group">
      <input type="text" id="userInput" placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..." disabled />
      <button class="btn btn-icon btn-speaker" id="speakerBtn" title="éŸ³å£°èª­ã¿ä¸Šã’ON" disabled>ğŸ”Š</button>
      <button class="btn" id="sendBtn" disabled>é€ä¿¡</button>
    </div>
    <div class="input-actions">
      <button class="btn btn-reservation" id="reservationBtn" disabled>ğŸ“ äºˆç´„ä¾é ¼ã™ã‚‹</button>
    </div>
  </div>
  
  <div class="floating-buttons">
    <button class="btn-floating btn-stop" id="stopBtn" title="ä¸­æ­¢"></button>
    <button class="btn-floating btn-mic-float" id="micBtnFloat" title="éŸ³å£°å…¥åŠ›" disabled></button>
  </div>
</div>

<style>
  .gourmet-chat-container { background: white; border-radius: 16px; box-shadow: 0 20px 60px rgba(0,0,0,0.15); width: 100%; max-width: 800px; max-height: 600px; display: flex; flex-direction: column; overflow: hidden; margin: 0 auto; position: relative; }
  .language-selector { padding: 12px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); display: flex; justify-content: flex-end; align-items: center; }
  .language-dropdown { padding: 6px 12px; border: 2px solid white; border-radius: 20px; background: rgba(255,255,255,0.95); color: #667eea; font-size: 13px; font-weight: 600; cursor: pointer; outline: none; transition: all 0.2s; }
  .chat-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; text-align: center; }
  .voice-status { padding: 10px 15px; text-align: center; font-size: 12px; border-bottom: 1px solid #e0e0e0; font-weight: 500; }
  .voice-status.listening { background: #e8f5e9; color: #2e7d32; animation: pulse 2s infinite; }
  .voice-status.stopped { background: #ffebee; color: #c62828; }
  .voice-status.speaking { background: #e1f5fe; color: #0277bd; animation: pulse 2s infinite; }
  @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.8; } }
  .chat-area { flex: 1; overflow-y: auto; padding: 20px; background: #f7f9fc; min-height: 300px; }
  .message { margin-bottom: 16px; display: flex; gap: 10px; }
  .message.assistant { flex-direction: row; }
  .message.user { flex-direction: row-reverse; }
  .message.system { justify-content: center; }
  .message-avatar { width: 36px; height: 36px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 16px; flex-shrink: 0; }
  .message.assistant .message-avatar { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
  .message.user .message-avatar { background: #e0e7ff; color: #667eea; }
  .message.system .message-avatar { background: #fff3e0; color: #f57c00; }
  .message-content { max-width: 70%; padding: 10px 14px; border-radius: 12px; line-height: 1.5; font-size: 14px; white-space: pre-wrap; }
  .message.assistant .message-content { background: white; border: 1px solid #e5e7eb; color: #1f2937; }
  .message.user .message-content { background: #667eea; color: white; }
  .message.system .message-content { background: #fff3e0; color: #e65100; font-size: 12px; }
  .summary-box { margin-top: 10px; padding: 10px; background: #fef3c7; border-left: 4px solid #f59e0b; border-radius: 8px; font-size: 13px; color: #92400e; }
  .final-summary { margin: 16px 0; padding: 16px; background: white; border: 2px solid #10b981; border-radius: 12px; }
  .input-area { padding: 16px; background: white; border-top: 1px solid #e5e7eb; }
  .input-group { display: flex; gap: 10px; align-items: center; margin-bottom: 10px; }
  #userInput { flex: 1; padding: 10px 14px; border: 2px solid #e5e7eb; border-radius: 20px; font-size: 14px; outline: none; transition: border-color 0.2s; }
  #userInput:focus { border-color: #667eea; }
  .btn { padding: 10px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 20px; font-size: 14px; font-weight: 600; cursor: pointer; transition: transform 0.2s, box-shadow 0.2s; }
  .btn:hover:not(:disabled) { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4); }
  .btn:disabled { opacity: 0.5; cursor: not-allowed; }
  .btn-reservation { background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; font-size: 13px; padding: 10px 16px; font-weight: 600; box-shadow: 0 4px 12px rgba(245, 158, 11, 0.3); }
  .btn-icon { padding: 10px; width: 40px; height: 40px; display: flex; align-items: center; justify-content: center; }
  .btn-speaker { background: #f59e0b; }
  .btn-speaker.disabled { background: #9ca3af; }
  .input-actions { display: flex; justify-content: flex-end; }
  .loading { display: inline-block; width: 20px; height: 20px; border: 3px solid #e5e7eb; border-radius: 50%; border-top-color: #667eea; animation: spin 1s ease-in-out infinite; }
  @keyframes spin { to { transform: rotate(360deg); } }
  .error-message { background: #fee2e2; color: #b91c1c; padding: 10px; border-radius: 8px; margin: 10px 0; font-size: 13px; text-align: center; }
  
  .splash-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; justify-content: center; z-index: 9999; border-radius: 16px; overflow: hidden; transition: opacity 0.8s ease-out; pointer-events: all; }
  .splash-overlay.fade-out { opacity: 0; pointer-events: none; }
  .splash-overlay.hidden { display: none; }
  .splash-video { width: 100%; height: 100%; object-fit: contain; position: absolute; top: 0; left: 0; transform: scale(0.5); }
  .splash-loading { position: absolute; bottom: 60px; display: flex; flex-direction: column; align-items: center; gap: 12px; z-index: 1; }
  .splash-loading .spinner { width: 40px; height: 40px; border: 4px solid rgba(102, 126, 234, 0.3); border-top-color: #667eea; border-radius: 50%; animation: spin 1s linear infinite; }
  .wait-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: rgba(255, 255, 255, 0.95); z-index: 500; display: flex; align-items: center; justify-content: center; border-radius: 16px; opacity: 1; transition: opacity 0.5s ease-out, visibility 0.5s; }
  .wait-overlay.hidden { opacity: 0; visibility: hidden; pointer-events: none; }
  .wait-content { text-align: center; width: 80%; max-width: 400px; }
  .wait-video { width: 100%; border-radius: 12px; box-shadow: 0 8px 30px rgba(0,0,0,0.1); margin-bottom: 16px; }
  .click-prompt { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); background: rgba(0, 0, 0, 0.8); color: white; padding: 20px; border-radius: 12px; text-align: center; z-index: 100; cursor: pointer; }

  .floating-buttons { position: fixed; bottom: 20px; right: 20px; display: flex; gap: 12px; z-index: 1000; transition: bottom 0.3s ease; }
  .floating-buttons.keyboard-active { bottom: 320px; }
  @media (max-width: 768px) { .floating-buttons.keyboard-active { bottom: 280px; } }
  .btn-floating { width: 56px; height: 56px; border-radius: 50%; border: none; font-size: 24px; cursor: pointer; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3); transition: transform 0.2s, box-shadow 0.2s; display: flex; align-items: center; justify-content: center; }
  .btn-floating:hover { transform: translateY(-2px); box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4); }
  .btn-stop { background: linear-gradient(135deg, #ff3b30 0%, #d32f2f 100%); color: white; }
  .btn-stop::before { content: 'â¹'; font-size: 24px; }
  .btn-mic-float { background: #999; color: white; position: relative; overflow: visible; }
  .btn-mic-float:not(:disabled) { background: #10b981; }
  .btn-mic-float::before { content: 'ğŸ¤'; font-size: 28px; }
  .btn-mic-float:disabled { cursor: not-allowed; opacity: 0.6; }
  .btn-mic-float.recording { background: #ef4444; }
  .btn-mic-float.recording::before { content: 'â¹'; }
  .btn-mic-float.recording::after { content: ''; position: absolute; width: 100%; height: 100%; border-radius: 50%; border: 3px solid #ef4444; opacity: 0; animation: ripple 1.5s ease-out infinite; }
  @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(1.8); opacity: 0; } }
</style>

<script src="https://cdn.socket.io/4.7.2/socket.io.min.js"></script>

<script define:vars={{ clientI18n }}>
  // ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æ¸¡ã•ã‚ŒãŸi18nãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
  const i18nData = clientI18n;

  // æ–‡å­—åˆ—åŒ–ã•ã‚Œã¦ã—ã¾ã£ãŸæ­£è¦è¡¨ç¾ã‚’ã€æœ¬ç‰©ã®æ­£è¦è¡¨ç¾ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«æˆ»ã™å‡¦ç†
  // ã“ã‚Œã«ã‚ˆã‚Šã€Œæ­£è¦è¡¨ç¾ã®ãƒ­ã‚¸ãƒƒã‚¯ã€ã¨ã€Œãƒ‡ãƒ¼ã‚¿ã®å¤–éƒ¨åŒ–ã€ã‚’ä¸¡ç«‹ã•ã›ã¾ã™
  function restoreRegExp() {
    Object.keys(i18nData).forEach(lang => {
      const patterns = i18nData[lang].patterns;
      if (patterns) {
        Object.keys(patterns).forEach(key => {
          // ã‚µãƒ¼ãƒãƒ¼å´ã§ .source ã«å¤‰æ›ã—ãŸæ–‡å­—åˆ—ã‚’ã€ã“ã“ã§ new RegExp() ã§å¾©å…ƒ
          // ãƒ•ãƒ©ã‚° 'i' (å¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–) ã‚„ 'g' (ã‚°ãƒ­ãƒ¼ãƒãƒ«) ã¯ç”¨é€”ã«åˆã‚ã›ã¦è¨­å®š
          // æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦èª¿æ•´
          patterns[key] = new RegExp(patterns[key], key === 'fillers' ? 'g' : 'i');
        });
      }
    });
  }
  
  // åˆæœŸåŒ–æ™‚ã«å¾©å…ƒã‚’å®Ÿè¡Œ
  restoreRegExp();

  // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ä½¿ã†å¤‰æ•°ã«ä»£å…¥
  const i18n = i18nData;

  const LANGUAGE_CODE_MAP = {
    ja: { tts: 'ja-JP', stt: 'ja-JP', voice: 'ja-JP-Chirp3-HD-Leda' },
    en: { tts: 'en-US', stt: 'en-US', voice: 'en-US-Studio-O' },
    zh: { tts: 'cmn-CN', stt: 'cmn-CN', voice: 'cmn-CN-Wavenet-A' },
    ko: { tts: 'ko-KR', stt: 'ko-KR', voice: 'ko-KR-Wavenet-A' }
  };
  const b64chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
  function fastArrayBufferToBase64(buffer) {
      let binary = '';
      const bytes = new Uint8Array(buffer);
      const len = bytes.byteLength;
      for (let i = 0; i < len; i += 3) {
        const c1 = bytes[i];
        const c2 = bytes[i + 1];
        const c3 = bytes[i + 2];
        const enc1 = c1 >> 2;
        const enc2 = ((c1 & 3) << 4) | (c2 >> 4);
        const enc3 = ((c2 & 15) << 2) | (c3 >> 6);
        const enc4 = c3 & 63;
        binary += b64chars[enc1] + b64chars[enc2];
        if (Number.isNaN(c2)) { binary += '=='; } 
        else if (Number.isNaN(c3)) { binary += b64chars[enc3] + '='; } 
        else { binary += b64chars[enc3] + b64chars[enc4]; }
      }
      return binary;
  }

  document.addEventListener('DOMContentLoaded', () => {
    const container = document.querySelector('.gourmet-chat-container');
    if (!container) return;

    const apiBase = container.dataset.apiBase || '';
    const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);
    const isAndroid = /Android/i.test(navigator.userAgent);

    const splashOverlay = document.getElementById('splashOverlay');
    const splashVideo = document.getElementById('splashVideo');
    function hideSplash() {
      if (splashVideo) splashVideo.loop = false;
      if (splashOverlay) {
        splashOverlay.classList.add('fade-out');
        setTimeout(() => splashOverlay.classList.add('hidden'), 800);
      }
    }
    setTimeout(() => hideSplash(), 10000);

    const chatArea = document.getElementById('chatArea');
    const userInput = document.getElementById('userInput');
    const sendBtn = document.getElementById('sendBtn');
    const speakerBtn = document.getElementById('speakerBtn');
    const reservationBtn = document.getElementById('reservationBtn');
    const voiceStatus = document.getElementById('voiceStatus');
    const languageSelect = document.getElementById('languageSelect');
    const stopBtn = document.getElementById('stopBtn');
    const micBtnFloat = document.getElementById('micBtnFloat');
    const waitOverlay = document.getElementById('waitOverlay');
    const waitVideo = document.getElementById('waitVideo');
    let waitOverlayTimer = null;
    let currentLanguage = 'ja';
    let sessionId = null;
    let isProcessing = false;
    let currentStage = 'conversation';
    let isRecording = false;
    let mediaRecorder = null;
    let audioChunks = [];
    let recordingTimer = null;
    const MAX_RECORDING_TIME = 55000;
    let isTTSEnabled = true;
    let isUserInteracted = false;
    let currentShops = [];
    let isFromVoiceInput = false;
    
    let lastAISpeech = '';
    let preGeneratedAcks = new Map();
    
    let globalAudioContext = null;
    let audioContext = null;
    
    let audioWorkletNode = null;
    let mediaStream = null;
    let socket = null;
    let streamingTranscript = '';
    let isStreamingSTT = false;
    let isSendingAudio = true;
    let isAISpeaking = false;
    let currentAISpeech = "";
    
    let analyser = null;
    let silenceTimer = null;
    let vadCheckInterval = null;
    let hasSpoken = false;
    let recordingStartTime = 0;
    const SILENCE_THRESHOLD = 35; 
    const SILENCE_DURATION = 2000;
    const MIN_RECORDING_TIME = 3000;

    const ttsPlayer = new Audio();
    
    // fallbackResponseé–¢æ•°ã¯JSONã§æ¸¡ã›ãªã„ãŸã‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§å†å®šç¾©
    function generateFallbackResponse(text) {
      if (currentLanguage === 'ja') return `ã€Œ${text}ã€ã§ã™ã­ã€ã‚ã‹ã‚Šã¾ã—ãŸã€‚\nå°‘ã—ãŠå¾…ã¡ãã ã•ã„...`;
      if (currentLanguage === 'en') return `I heard "${text}".\nPlease wait a moment...`;
      if (currentLanguage === 'zh') return `æˆ‘å¬åˆ°äº†â€œ${text}â€ã€‚\nè¯·ç¨ç­‰...`;
      if (currentLanguage === 'ko') return `"${text}"ë¼ê³  í•˜ì…¨êµ°ìš”.\nì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...`;
      return text;
    }

    function t(key, ...args) {
      const translation = i18n[currentLanguage][key];
      // fallbackResponseã‚­ãƒ¼ãŒæ¥ãŸã‚‰ç‰¹åˆ¥å‡¦ç†
      if (key === 'fallbackResponse') return generateFallbackResponse(args[0]);
      
      if (typeof translation === 'function') return translation(...args);
      return translation || key;
    }

    function addMessage(role, content, summary = null, isInitial = false) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${role}`;
      if (isInitial) messageDiv.setAttribute('data-initial', 'true');
      const avatar = document.createElement('div');
      avatar.className = 'message-avatar';
      avatar.innerHTML = role === 'assistant' ? 'ğŸ½' : role === 'user' ? 'ğŸ‘¤' : 'âš ';
      const contentDiv = document.createElement('div');
      contentDiv.className = 'message-content';
      const messageText = document.createElement('span');
      messageText.className = 'message-text';
      messageText.textContent = content;
      contentDiv.appendChild(messageText);
      messageDiv.appendChild(avatar);
      const wrapper = document.createElement('div');
      wrapper.appendChild(contentDiv);
      if (summary) {
        const summaryDiv = document.createElement('div');
        summaryDiv.className = 'summary-box';
        summaryDiv.innerHTML = `<strong>ğŸ” å†…å®¹ç¢ºèª</strong>${summary}`;
        wrapper.appendChild(summaryDiv);
      }
      messageDiv.appendChild(wrapper);
      chatArea.appendChild(messageDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showError(message) {
      const errorDiv = document.createElement('div');
      errorDiv.className = 'error-message';
      errorDiv.textContent = message;
      chatArea.appendChild(errorDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showWaitOverlay() {
      waitOverlay.classList.remove('hidden');
      waitVideo.currentTime = 0;
      waitVideo.play().catch(e => console.log('Video err', e));
    }

    function hideWaitOverlay() {
      if (waitOverlayTimer) { clearTimeout(waitOverlayTimer); waitOverlayTimer = null; }
      waitOverlay.classList.add('hidden');
      setTimeout(() => waitVideo.pause(), 500);
    }

    function unlockAudioParams() {
      ttsPlayer.play().then(() => { ttsPlayer.pause(); ttsPlayer.currentTime = 0; }).catch(e => {});
      if (globalAudioContext && globalAudioContext.state === 'suspended') {
        globalAudioContext.resume();
      }
    }

    function enableAudioPlayback() {
      if (!isUserInteracted) {
        isUserInteracted = true;
        const clickPrompt = container.querySelector('.click-prompt');
        if (clickPrompt) clickPrompt.remove();
        unlockAudioParams();
      }
    }

    function showClickPrompt() {
      const prompt = document.createElement('div');
      prompt.className = 'click-prompt';
      prompt.innerHTML = `<p>ğŸ”Š</p><p>${t('clickPrompt')}</p><p>ğŸ”Š</p>`;
      prompt.addEventListener('click', enableAudioPlayback);
      container.style.position = 'relative';
      container.appendChild(prompt);
    }

    function stopCurrentAudio() {
      ttsPlayer.pause();
      ttsPlayer.currentTime = 0;
    }

    function stripMarkdown(text) {
      return text.replace(/\*\*([^*]+)\*\*/g, '$1').replace(/\*([^*]+)\*/g, '$1').replace(/__([^_]+)__/g, '$1').replace(/_([^_]+)_/g, '$1').replace(/^#+\s*/gm, '').replace(/\[([^\]]+)\]\([^)]+\)/g, '$1').replace(/`([^`]+)`/g, '$1').replace(/^(\d+)\.\s+/gm, '$1ç•ªç›®ã€').replace(/\s+/g, ' ').trim();
    }

    function normalizeText(text) {
      return text.replace(/\s+/g, '').replace(/[ã€ã€‚ï¼ï¼Ÿ,.!?]/g, '').toLowerCase();
    }

    function removeFillers(text) {
      const pattern = i18n[currentLanguage].patterns.fillers;
      return text.replace(pattern, '');
    }

    function selectSmartAcknowledgment(userMessage) {
      const messageLower = userMessage.trim();
      const p = i18n[currentLanguage].patterns;
      if (p.ackQuestions.test(messageLower)) return { text: t('ackConfirm'), logText: `è³ªå•å½¢å¼` };
      if (p.ackLocation.test(messageLower)) return { text: t('ackSearch'), logText: `å ´æ‰€` };
      if (p.ackSearch.test(messageLower)) return { text: t('ackUnderstood'), logText: `æ¤œç´¢` };
      return { text: t('ackYes'), logText: `ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ` };
    }

    function extractShopsFromResponse(text) {
      const shops = [];
      const pattern = /(\d+)\.\s*\*\*([^*]+)\*\*[::\s]*([^\n]+)/g;
      let match;
      while ((match = pattern.exec(text)) !== null) {
        const fullName = match[2].trim();
        const description = match[3].trim();
        let name = fullName;
        const nameMatch = fullName.match(/^([^(]+)[(]([^)]+)[)]/);
        if (nameMatch) name = nameMatch[1].trim();
        const encodedName = encodeURIComponent(name);
        shops.push({ name: name, description: description, category: 'ã‚¤ã‚¿ãƒªã‚¢ãƒ³', hotpepper_url: `https://www.hotpepper.jp/SA11/srchRS/?keyword=${encodedName}`, maps_url: `https://www.google.com/maps/search/${encodedName}`, tabelog_url: `https://tabelog.com/rstLst/?vs=1&sa=&sk=${encodedName}` });
      }
      return shops;
    }

    function updateUILanguage() {
      voiceStatus.innerHTML = t('voiceStatusStopped');
      userInput.placeholder = t('inputPlaceholder');
      micBtnFloat.title = t('btnVoiceInput');
      speakerBtn.title = isTTSEnabled ? t('btnTTSOn') : t('btnTTSOff');
      sendBtn.textContent = t('btnSend');
      reservationBtn.innerHTML = t('btnReservation');
      const waitText = document.querySelector('.wait-text');
      if (waitText) waitText.textContent = t('waitMessage');

      const pageTitle = document.getElementById('pageTitle');
      if (pageTitle) pageTitle.innerHTML = `<img src="/pwa-152x152.png" alt="Logo" class="app-logo" /> ${t('pageTitle')}`;
      const pageSubtitle = document.getElementById('pageSubtitle');
      if (pageSubtitle) pageSubtitle.textContent = t('pageSubtitle');
      const shopListTitle = document.getElementById('shopListTitle');
      if (shopListTitle) shopListTitle.innerHTML = `ğŸ½ ${t('shopListTitle')}`;
      const shopListEmpty = document.getElementById('shopListEmpty');
      if (shopListEmpty) shopListEmpty.textContent = t('shopListEmpty');
      const pageFooter = document.getElementById('pageFooter');
      if (pageFooter) pageFooter.innerHTML = `${t('footerMessage')} âœ¨`;

      const initialMessage = chatArea.querySelector('.message.assistant[data-initial="true"]');
      if (initialMessage) {
        const messageText = initialMessage.querySelector('.message-text');
        if (messageText) messageText.textContent = t('initialGreeting');
      }

      document.dispatchEvent(new CustomEvent('languageChange', { detail: { language: currentLanguage } }));
    }

    async function speakTextGCP(text, stopPrevious = true, autoRestartMic = false) {
      if (!isTTSEnabled || !text) return;
      if (stopPrevious) ttsPlayer.pause();
      
      const cleanText = stripMarkdown(text);

      try {
        isAISpeaking = true;
        if (isAndroid && isRecording) {
          stopStreamingSTT();
        }
        
        voiceStatus.innerHTML = t('voiceStatusSynthesizing');
        voiceStatus.className = 'voice-status speaking';
        const langConfig = LANGUAGE_CODE_MAP[currentLanguage];
        const response = await fetch(`${apiBase}/api/tts/synthesize`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text: cleanText, language_code: langConfig.tts, voice_name: langConfig.voice })
        });
        const data = await response.json();
        if (data.success && data.audio) {
          ttsPlayer.src = `data:audio/mp3;base64,${data.audio}`;
          const playPromise = new Promise((resolve) => {
            ttsPlayer.onended = async () => {
              voiceStatus.innerHTML = t('voiceStatusStopped');
              voiceStatus.className = 'voice-status stopped';
              isAISpeaking = false;
              
              
              if (autoRestartMic) {
                if (isAndroid) {
                  try {
                    await startStreamingSTT();
                  } catch (error) {
                    showMicPrompt();
                  }
                } else if (!isRecording) {
                  try {
                    await startStreamingSTT();
                  } catch (error) {
                    showMicPrompt();
                  }
                }
              }
              resolve();
            };
            ttsPlayer.onerror = () => { 
              isAISpeaking = false;
              resolve(); 
            };
          });
          if (isUserInteracted) {
            lastAISpeech = normalizeText(cleanText);
            await ttsPlayer.play();
            await playPromise;
          } else {
            showClickPrompt();
            voiceStatus.innerHTML = t('voiceStatusStopped');
            voiceStatus.className = 'voice-status stopped';
            isAISpeaking = false;
          }
        } else {
          isAISpeaking = false;
        }
      } catch (error) {
        voiceStatus.innerHTML = t('voiceStatusStopped');
        voiceStatus.className = 'voice-status stopped';
        isAISpeaking = false;
      }
    }

    function showMicPrompt() {
      const modal = document.createElement('div');
      modal.id = 'mic-prompt-modal';
      modal.style.cssText = `position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: rgba(0, 0, 0, 0.8);
      display: flex; align-items: center; justify-content: center; z-index: 10000; animation: fadeIn 0.3s ease;`;
      modal.innerHTML = `
        <div style="background: white; border-radius: 16px; padding: 24px; max-width: 90%; width: 350px; text-align: center; box-shadow: 0 8px 32px rgba(0,0,0,0.3);">
          <div style="font-size: 48px; margin-bottom: 16px;">ğŸ¤</div>
          <div style="font-size: 18px; font-weight: 700; margin-bottom: 8px; color: #333;">ãƒã‚¤ã‚¯ã‚’ONã«ã—ã¦ãã ã•ã„</div>
          <div style="font-size: 14px; color: #666; margin-bottom: 20px;">AIã®å›ç­”ãŒçµ‚ã‚ã‚Šã¾ã—ãŸã€‚<br>ç¶šã‘ã¦è©±ã™ã«ã¯ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’ã‚¿ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚</div>
          <button id="mic-prompt-btn" style="background: linear-gradient(135deg, #10b981 0%, #059669 100%); color: white; border: none; padding: 14px 32px; 
          border-radius: 24px; font-size: 16px; font-weight: 600; cursor: pointer; box-shadow: 0 4px 12px rgba(16, 185, 129, 0.3);">ğŸ¤ ãƒã‚¤ã‚¯ON</button>
        </div>
      `;
      const style = document.createElement('style');
      style.textContent = `@keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }`;
      document.head.appendChild(style);
      document.body.appendChild(modal);
      const btn = document.getElementById('mic-prompt-btn');
      btn?.addEventListener('click', async () => {
        modal.remove();
        await toggleRecording();
      });
      setTimeout(() => { if (document.getElementById('mic-prompt-modal')) { modal.remove(); } }, 3000);
    }

    function isSemanticEcho(transcript, aiText) {
      if (!aiText || !transcript) return false;
      const normTranscript = normalizeText(transcript);
      const normAI = normalizeText(aiText);
      if (normAI === normTranscript) return true;
      if (normAI.includes(normTranscript) && normTranscript.length > 5) return true;
      return false;
    }

    async function startStreamingSTT() {
      if (isIOS) {
        await startStreamingSTT_iOS();
      } else {
        await startStreamingSTT_Default();
      }
    }

    function stopStreamingSTT() {
      if (isIOS) {
        stopStreamingSTT_iOS();
      } else {
        stopStreamingSTT_Default();
      }
    }

    function stopVAD_Default() {
      if (vadCheckInterval) { clearInterval(vadCheckInterval); vadCheckInterval = null; }
      if (silenceTimer) { clearTimeout(silenceTimer); silenceTimer = null; }
      if (audioContext) { audioContext.close(); audioContext = null; }
      analyser = null;
      hasSpoken = false;
    }

    // â˜… iPhoneå®Ÿè£…ï¼ˆæ”¹å–„ç‰ˆ - éŸ³é£›ã³ãƒ»èªå°¾åˆ‡ã‚Œå¯¾ç­–æ¸ˆã¿ï¼‰
    async function startStreamingSTT_iOS() {
      try {
        // 1. AudioContextã‚’å³åº§ã«å†é–‹ï¼ˆã“ã‚ŒãŒUser Gestureå¿…é ˆéƒ¨åˆ†ï¼‰
        if (splashVideo) { splashVideo.pause(); }
        if (waitVideo) { waitVideo.pause(); }
        if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
        
        // AudioContextä½œæˆï¼ˆåˆå›ã®ã¿ï¼‰
        if (!globalAudioContext) {
          try {
            // sampleRateæŒ‡å®šã‚’å‰Šé™¤ï¼ˆOSã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã«å¾“ã†ï¼‰
            globalAudioContext = new AudioContext({ 
              latencyHint: 'interactive'
            });
          } catch (e) {
            addMessage('system', 'AudioContextä½œæˆã‚¨ãƒ©ãƒ¼');
            throw e;
          }
        }
        
        if (globalAudioContext.state === 'suspended') {
          await globalAudioContext.resume();
        }

        // Workletã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆé…å»¶ãªã—ï¼‰
        if (audioWorkletNode) { 
          audioWorkletNode.port.onmessage = null;
          audioWorkletNode.disconnect(); 
          audioWorkletNode = null; 
        }

        // MediaStreamå–å¾—ãƒ»å†åˆ©ç”¨
        if (mediaStream) {
          const tracks = mediaStream.getAudioTracks();
          if (tracks.length > 0 && tracks[0].readyState === 'live') {
            console.log('æ—¢å­˜ã®MediaStreamã‚’å†åˆ©ç”¨');
          } else {
            mediaStream.getTracks().forEach(track => track.stop());
            mediaStream = null;
          }
        }
        
        if (!mediaStream) {
          try {
            // sampleRateæŒ‡å®šã‚’å‰Šé™¤
            const audioConstraints = { 
              channelCount: 1,
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true
            };
            mediaStream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });
          } catch (micError) {
            addMessage('system', `ãƒã‚¤ã‚¯ã‚¨ãƒ©ãƒ¼: ${micError.message}`);
            throw micError;
          }
        }
        
        const targetSampleRate = 16000;
        const nativeSampleRate = globalAudioContext.sampleRate;
        const downsampleRatio = nativeSampleRate / targetSampleRate;
        
        const source = globalAudioContext.createMediaStreamSource(mediaStream);
        const processorName = 'audio-processor-ios';
        try {
          audioWorkletNode = new AudioWorkletNode(globalAudioContext, processorName);
        } catch (e) {
          // bufferSizeã‚’4096ã«ç¸®å°ã—ã€flushåˆ¤å®šã‚’200msã«çŸ­ç¸®ï¼ˆèªå°¾åˆ‡ã‚Œé˜²æ­¢ï¼‰
          const audioProcessorCode = `
          class AudioProcessor extends AudioWorkletProcessor {
            constructor() {
              super();
              this.bufferSize = 4096;
              this.buffer = new Int16Array(this.bufferSize); 
              this.writeIndex = 0;
              this.ratio = ${downsampleRatio}; 
              this.inputSampleCount = 0;
              this.lastFlushTime = Date.now();
            }

            process(inputs, outputs, parameters) {
              const input = inputs[0];
              if (!input || input.length === 0) return true;
              const channelData = input[0];
              if (!channelData || channelData.length === 0) return true;
              for (let i = 0; i < channelData.length; i++) {
                this.inputSampleCount++;
                if (this.inputSampleCount >= this.ratio) {
                  this.inputSampleCount -= this.ratio;
                  if (this.writeIndex < this.bufferSize) {
                    const s = Math.max(-1, Math.min(1, channelData[i]));
                    const int16Value = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    this.buffer[this.writeIndex++] = int16Value;
                  }
                  
                  // å¼·åˆ¶æ’å‡ºã‚’200msã«çŸ­ç¸®
                  if (this.writeIndex >= this.bufferSize || 
                      (this.writeIndex > 0 && Date.now() - this.lastFlushTime > 200)) {
                    this.flush();
                  }
                }
              }
              return true;
            }
            
            flush() {
              if (this.writeIndex === 0) return;
              const chunk = this.buffer.slice(0, this.writeIndex);
              this.port.postMessage({ audioChunk: chunk }, [chunk.buffer]);
              this.writeIndex = 0;
              this.lastFlushTime = Date.now();
            }
          }
          registerProcessor('${processorName}', AudioProcessor);
          `;

          try {
            const blob = new Blob([audioProcessorCode], { type: 'application/javascript' });
            const processorUrl = URL.createObjectURL(blob);
            await globalAudioContext.audioWorklet.addModule(processorUrl);
            URL.revokeObjectURL(processorUrl);
          } catch (workletError) {
            addMessage('system', `éŸ³å£°å‡¦ç†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: ${workletError.message}`);
            throw workletError;
          }
          
          audioWorkletNode = new AudioWorkletNode(globalAudioContext, processorName);
        }
        
        audioWorkletNode.port.onmessage = (event) => {
          const { audioChunk } = event.data;
          if (!isSendingAudio || !socket || !socket.connected) return;
          
          try {
            const base64 = fastArrayBufferToBase64(audioChunk.buffer);
            socket.emit('audio_chunk', { 
              chunk: base64,
              sample_rate: 16000
            });
          } catch (e) {
            console.error('Audio convert error', e);
          }
        };
        
        // å…ˆã«ã‚½ã‚±ãƒƒãƒˆã®é–‹å§‹åˆå›³ã‚’é€ã‚‹ï¼ˆå†’é ­æ¬ è½å¯¾ç­–ï¼‰
        if (socket && socket.connected) {
          socket.emit('stop_stream');
        }
        
        socket.emit('start_stream', { 
          language_code: LANGUAGE_CODE_MAP[currentLanguage].stt,
          sample_rate: 16000
        });

        // ã‚µãƒ¼ãƒãƒ¼æº–å‚™å¾…ã¡ï¼ˆUser Gestureå†…ãªã®ã§OKï¼‰
        await new Promise(resolve => setTimeout(resolve, 100));

        // æœ€å¾Œã«ãƒã‚¤ã‚¯éŸ³å£°ã‚’æ¥ç¶š
        source.connect(audioWorkletNode);
        audioWorkletNode.connect(globalAudioContext.destination);
        
        isSendingAudio = true;
        isRecording = true; micBtnFloat.classList.add('recording');
        voiceStatus.innerHTML = t('voiceStatusListening');
        recordingTimer = window.setTimeout(() => { 
          if (isRecording) { 
            stopStreamingSTT(); 
            addMessage('system', t('recordingTimeLimit')); 
          } 
        }, MAX_RECORDING_TIME);
      } catch (error) {
        if (audioWorkletNode) { 
          audioWorkletNode.port.onmessage = null;
          audioWorkletNode.disconnect(); 
          audioWorkletNode = null; 
        }
        if (!error.message?.includes('ãƒã‚¤ã‚¯')) { 
          addMessage('system', `${t('micAccessError')} ${error.message || 'Unknown error'}`);
        }
      }
    }

    // MediaStreamã‚’ä¿æŒ
    function stopStreamingSTT_iOS() {
      if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
      if (audioWorkletNode) { 
        audioWorkletNode.port.onmessage = null;
        audioWorkletNode.disconnect(); 
        audioWorkletNode = null; 
      }
      if (socket && socket.connected) { socket.emit('stop_stream'); }
      isSendingAudio = false; isRecording = false; micBtnFloat.classList.remove('recording');
    }

    // PC/Androidå®Ÿè£…ï¼ˆå¾“æ¥ç‰ˆï¼‰
    async function startStreamingSTT_Default() {
      try {
        if (splashVideo) { splashVideo.pause(); }
        if (waitVideo) { waitVideo.pause(); }
        if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
        
        if (audioWorkletNode) { audioWorkletNode.port.onmessage = null; audioWorkletNode.disconnect(); audioWorkletNode = null; }
        
        if (!audioContext) {
          try {
            audioContext = new AudioContext({ latencyHint: 'playback' });
          } catch (e) {
            addMessage('system', 'AudioContextä½œæˆã‚¨ãƒ©ãƒ¼');
            throw e;
          }
        }
        
        if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }
        
        if (mediaStream) { mediaStream.getTracks().forEach(track => track.stop()); mediaStream = null; }
        
        try {
          const audioConstraints = { 
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true 
          };
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });
        } catch (micError) {
          addMessage('system', `ãƒã‚¤ã‚¯ã‚¨ãƒ©ãƒ¼: ${micError.message}`);
          throw micError;
        }
        
        const targetSampleRate = 16000;
        const nativeSampleRate = audioContext.sampleRate;
        const downsampleRatio = nativeSampleRate / targetSampleRate;
        
        const source = audioContext.createMediaStreamSource(mediaStream);
        const audioProcessorCode = `
        class AudioProcessor extends AudioWorkletProcessor {
          constructor() {
            super();
            this.bufferSize = 16000;
            this.buffer = new Int16Array(this.bufferSize); 
            this.writeIndex = 0;
            this.ratio = ${downsampleRatio}; 
            this.inputSampleCount = 0;
            this.flushThreshold = 8000;
          }

          process(inputs, outputs, parameters) {
            const input = inputs[0];
            if (!input || input.length === 0) return true;
            const channelData = input[0];
            if (!channelData || channelData.length === 0) return true;
            for (let i = 0; i < channelData.length; i++) {
              this.inputSampleCount++;
              if (this.inputSampleCount >= this.ratio) {
                this.inputSampleCount -= this.ratio;
                if (this.writeIndex < this.bufferSize) {
                  const s = Math.max(-1, Math.min(1, channelData[i]));
                  const int16Value = s < 0 ? s * 0x8000 : s * 0x7FFF;
                  this.buffer[this.writeIndex++] = int16Value;
                }
                
                if (this.writeIndex >= this.bufferSize) {
                  this.flush();
                }
              }
            }
            return true;
          }
          
          flush() {
            if (this.writeIndex === 0) return;
            const chunk = this.buffer.slice(0, this.writeIndex);
            this.port.postMessage({ audioChunk: chunk }, [chunk.buffer]);
            this.writeIndex = 0;
          }
        }
        registerProcessor('audio-processor', AudioProcessor);
        `;
        try {
          const blob = new Blob([audioProcessorCode], { type: 'application/javascript' });
          const processorUrl = URL.createObjectURL(blob);
          await audioContext.audioWorklet.addModule(processorUrl);
          URL.revokeObjectURL(processorUrl);
        } catch (workletError) {
          addMessage('system', `éŸ³å£°å‡¦ç†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: ${workletError.message}`);
          throw workletError;
        }
        
        audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');
        audioWorkletNode.port.onmessage = (event) => {
          const { audioChunk } = event.data;
          if (!isSendingAudio || !socket || !socket.connected) return;
          
          try {
            const blob = new Blob([audioChunk], { type: 'application/octet-stream' });
            const reader = new FileReader();
            reader.onload = () => {
                const result = reader.result as string;
                const base64 = result.split(',')[1];
                socket.emit('audio_chunk', { chunk: base64, sample_rate: 16000 });
            };
            reader.readAsDataURL(blob);
          } catch (e) {
            console.error('Audio convert error', e);
          }
        };
        
        source.connect(audioWorkletNode);
        audioWorkletNode.connect(audioContext.destination);

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        hasSpoken = false;
        recordingStartTime = Date.now();
        vadCheckInterval = window.setInterval(() => {
          if (!analyser || !isRecording) return;
          if (Date.now() - recordingStartTime < MIN_RECORDING_TIME) return;
          analyser.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
          
          if (average > SILENCE_THRESHOLD) { 
             hasSpoken = true; 
             if (silenceTimer) clearTimeout(silenceTimer); 
             voiceStatus.innerHTML = t('voiceStatusRecording'); 
          } else if (hasSpoken && !silenceTimer) { 
             voiceStatus.innerHTML = t('voiceStatusWaiting'); 
             silenceTimer = window.setTimeout(() => { stopStreamingSTT(); }, SILENCE_DURATION); 
          }
        }, 100);
        if (socket && socket.connected) {
          socket.emit('stop_stream');
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        socket.emit('start_stream', { 
          language_code: LANGUAGE_CODE_MAP[currentLanguage].stt,
          sample_rate: 16000
        });
        isSendingAudio = true;
        isRecording = true; micBtnFloat.classList.add('recording');
        voiceStatus.innerHTML = t('voiceStatusListening');
        recordingTimer = window.setTimeout(() => { 
          if (isRecording) { 
            stopStreamingSTT(); 
            addMessage('system', t('recordingTimeLimit')); 
          } 
        }, MAX_RECORDING_TIME);
      } catch (error) {
        if (mediaStream) { mediaStream.getTracks().forEach(track => track.stop()); mediaStream = null; }
        if (!error.message?.includes('ãƒã‚¤ã‚¯')) { addMessage('system', `${t('micAccessError')} ${error.message || 'Unknown error'}`); }
      }
    }

    function stopStreamingSTT_Default() {
      stopVAD_Default();
      if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
      if (audioWorkletNode) { audioWorkletNode.port.onmessage = null; audioWorkletNode.disconnect(); audioWorkletNode = null; }
      if (audioContext && audioContext.state !== 'closed') { audioContext.close(); audioContext = null; }
      if (mediaStream) { mediaStream.getTracks().forEach(track => track.stop()); mediaStream = null; }
      if (socket && socket.connected) { socket.emit('stop_stream'); }
      isSendingAudio = false; isRecording = false; micBtnFloat.classList.remove('recording');
    }

    // å®Œå…¨ãƒªã‚»ãƒƒãƒˆé–¢æ•°
    function fullResetAudioResources() {
      if (audioWorkletNode) { 
        audioWorkletNode.port.onmessage = null;
        audioWorkletNode.disconnect(); 
        audioWorkletNode = null; 
      }
      
      if (mediaStream) { 
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null; 
      }
      
      if (globalAudioContext && globalAudioContext.state !== 'closed') {
        globalAudioContext.close();
        globalAudioContext = null;
      }
      
      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
        audioContext = null;
      }
      
      isSendingAudio = false;
      isRecording = false;
      micBtnFloat.classList.remove('recording');
    }

    async function startLegacyRecording() {
       try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, sampleRate: 16000, echoCancellation: true, noiseSuppression: true } });
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
        audioChunks = []; hasSpoken = false; recordingStartTime = Date.now();
        audioContext = new AudioContext();
        const source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        vadCheckInterval = window.setInterval(() => {
          if (!analyser || !isRecording) return;
          if (Date.now() - recordingStartTime < MIN_RECORDING_TIME) return;
          analyser.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
          if (average > SILENCE_THRESHOLD) { hasSpoken = true; if (silenceTimer) clearTimeout(silenceTimer); voiceStatus.innerHTML = t('voiceStatusRecording'); }
          else if (hasSpoken && !silenceTimer) { voiceStatus.innerHTML = t('voiceStatusWaiting'); silenceTimer = window.setTimeout(() => { if (mediaRecorder && mediaRecorder.state === 'recording') mediaRecorder.stop(); }, SILENCE_DURATION); }
        }, 100);
        mediaRecorder.ondataavailable = (event) => { if (event.data.size > 0) audioChunks.push(event.data); };
        mediaRecorder.onstop = async () => {
          stopVAD_Default(); stream.getTracks().forEach(track => track.stop());
          if (recordingTimer) clearTimeout(recordingTimer);
          if (audioChunks.length > 0) { const audioBlob = new Blob(audioChunks, { type: 'audio/webm' }); await transcribeAudio(audioBlob); }
        };
        mediaRecorder.start();
        isRecording = true; micBtnFloat.classList.add('recording'); voiceStatus.innerHTML = t('voiceStatusListening');
        recordingTimer = window.setTimeout(() => { if (isRecording && mediaRecorder && mediaRecorder.state === 'recording') { stopVAD_Default(); mediaRecorder.stop(); isRecording = false; micBtnFloat.classList.remove('recording'); addMessage('system', t('recordingTimeLimit')); } }, MAX_RECORDING_TIME);
      } catch (error) { addMessage('system', `${t('micAccessError')} ${(error.message || error)}`); }
    }

    async function transcribeAudio(audioBlob) { }

    function initializeWebSocketSTT() {
      try {
        const wsUrl = apiBase || window.location.origin;
        socket = io(wsUrl);
        socket.on('connect', () => { isStreamingSTT = true; });
        socket.on('disconnect', () => { isStreamingSTT = false; });
        socket.on('transcript', (data) => {
          const { text, is_final } = data;
          if (isAISpeaking) return;
          if (is_final) { 
            streamingTranscript = text; 
            handleStreamingSTTComplete(text);
            currentAISpeech = "";
          } else { 
            userInput.value = text;
          }
        });
        socket.on('error', (data) => { 
          addMessage('system', `${t('sttError')} ${data.message}`);
          if (isRecording) stopStreamingSTT();
        });
      } catch (error) { isStreamingSTT = false; }
    }

    async function handleStreamingSTTComplete(transcript) {
      stopStreamingSTT();
      voiceStatus.innerHTML = t('voiceStatusComplete');
      voiceStatus.className = 'voice-status';

      const normTranscript = normalizeText(transcript);
      if (isSemanticEcho(normTranscript, lastAISpeech)) {
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          lastAISpeech = '';
          return;
      }

      userInput.value = transcript;
      if (i18n[currentLanguage].patterns.dateCheck.test(transcript)) {
        const msg = t('dateWarningMsg');
        currentAISpeech = msg;
        addMessage('assistant', msg);
        if (isTTSEnabled && isUserInteracted) {
          await speakTextGCP(msg, true, true);
        } else { await new Promise(r => setTimeout(r, 2000)); }
        userInput.value = '';
        voiceStatus.innerHTML = t('voiceStatusStopped');
        voiceStatus.className = 'voice-status stopped';
        return;
      }

      addMessage('user', transcript);
      const textLength = transcript.trim().replace(/\s+/g, '').length;
      if (textLength < 4) {
          const msg = t('shortMsgWarning');
          addMessage('assistant', msg);
          isSendingAudio = false;
          if (isTTSEnabled && isUserInteracted) {
            await speakTextGCP(msg, true);
          } else { await new Promise(r => setTimeout(r, 2000)); }
          isSendingAudio = true;
          userInput.value = '';
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          return;
      }

      const ack = selectSmartAcknowledgment(transcript);
      const preGeneratedAudio = preGeneratedAcks.get(ack.text);
      let firstAckPromise = null;
      if (preGeneratedAudio && isTTSEnabled && isUserInteracted) {
        firstAckPromise = new Promise((resolve) => {
          lastAISpeech = normalizeText(ack.text);
          ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
          ttsPlayer.onended = () => resolve();
          ttsPlayer.play().catch(e => resolve());
        });
      } else if (isTTSEnabled) { firstAckPromise = speakTextGCP(ack.text, false); }
      addMessage('assistant', ack.text);
      (async () => {
        try {
          if (firstAckPromise) await firstAckPromise;
          const cleanText = removeFillers(transcript);
          const fallbackResponse = generateFallbackResponse(cleanText);
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
          addMessage('assistant', fallbackResponse);
          setTimeout(async () => {
            const additionalResponse = t('additionalResponse');
            if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
            addMessage('assistant', additionalResponse);
          }, 3000);
          if (userInput.value.trim()) {
            isFromVoiceInput = true;
            sendMessage();
          }
        } catch (error) { 
          if (userInput.value.trim()) {
            isFromVoiceInput = true;
            sendMessage();
          }
        }
      })();
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
    }

    async function sendMessage() {
      let firstAckPromise = null; 
      unlockAudioParams();
      const message = userInput.value.trim();
      if (!message || isProcessing) return;
      isProcessing = true; sendBtn.disabled = true;
      micBtnFloat.disabled = true; userInput.disabled = true;

      if (!isFromVoiceInput) {
        addMessage('user', message);
        if (i18n[currentLanguage].patterns.dateCheck.test(message)) {
             const msg = t('dateWarningMsg');
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             addMessage('assistant', msg);
             userInput.value = ''; isProcessing = false; sendBtn.disabled = false;
             micBtnFloat.disabled = false; userInput.disabled = false; userInput.focus();
             return;
        }
        const textLength = message.trim().replace(/\s+/g, '').length;
        if (textLength < 4) {
             const msg = t('shortMsgWarning');
             addMessage('assistant', msg);
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             userInput.value = ''; isProcessing = false; sendBtn.disabled = false;
             micBtnFloat.disabled = false; userInput.disabled = false; userInput.focus();
             return;
        }
        userInput.value = '';
        const ack = selectSmartAcknowledgment(message);
        currentAISpeech = ack.text;
        addMessage('assistant', ack.text);
        if (isTTSEnabled) {
          try {
            const preGeneratedAudio = preGeneratedAcks.get(ack.text);
            if (preGeneratedAudio && isUserInteracted) {
              firstAckPromise = new Promise((resolve) => {
                lastAISpeech = normalizeText(ack.text);
                ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
                ttsPlayer.onended = () => resolve();
                ttsPlayer.play().catch(e => resolve());
              });
            } else { firstAckPromise = speakTextGCP(ack.text, false); }
          } catch (e) {}
        }
        if (firstAckPromise) await firstAckPromise;
        const cleanText = removeFillers(message);
        const fallbackResponse = generateFallbackResponse(cleanText);
        if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
        addMessage('assistant', fallbackResponse);
        setTimeout(async () => {
          const additionalResponse = t('additionalResponse');
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
          addMessage('assistant', additionalResponse);
        }, 3000);
      }

      const wasVoiceInput = isFromVoiceInput;
      isFromVoiceInput = false;
      if (waitOverlayTimer) clearTimeout(waitOverlayTimer);
      waitOverlayTimer = window.setTimeout(() => { showWaitOverlay(); }, 4000);

      try {
        const response = await fetch(`${apiBase}/api/chat`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ session_id: sessionId, message: message, stage: currentStage, language: currentLanguage }) });
        const data = await response.json();
        hideWaitOverlay();
        currentAISpeech = data.response;
        addMessage('assistant', data.response, data.summary);
        stopCurrentAudio();
        if (data.shops && data.shops.length > 0) {
          currentShops = data.shops;
          reservationBtn.disabled = false;
          userInput.value = '';
          document.dispatchEvent(new CustomEvent('displayShops', { detail: { shops: data.shops, language: currentLanguage } }));
          const section = document.getElementById('shopListSection');
          if (section) section.classList.add('has-shops');
          if (window.innerWidth < 1024) {
            setTimeout(() => {
              const shopSection = document.getElementById('shopListSection');
              if (shopSection) {
                shopSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
              }
             }, 300);
          }
          
          (async () => {
            try {
              isAISpeaking = true;
              if (isRecording) { stopStreamingSTT(); }

              await speakTextGCP(t('ttsIntro'));
              const lines = data.response.split('\n\n');
              let introText = ""; let shopLines = lines;
              if (lines[0].includes('ã”å¸Œæœ›ã«åˆã†ãŠåº—') && lines[0].includes('ã”ç´¹ä»‹ã—ã¾ã™')) { introText = lines[0]; shopLines = lines.slice(1); }
              let introPart2Promise = null;
              if (introText && isTTSEnabled && isUserInteracted) {
                const preGeneratedIntro = preGeneratedAcks.get(introText);
                if (preGeneratedIntro) {
                  introPart2Promise = new Promise((resolve) => {
                    lastAISpeech = normalizeText(introText);
                    ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedIntro}`;
                    ttsPlayer.onended = () => resolve();
                    ttsPlayer.play();
                  });
                } else { introPart2Promise = speakTextGCP(introText, false); }
              }

              let firstShopAudioPromise = null;
              let remainingAudioPromise = null;
              const shopLangConfig = LANGUAGE_CODE_MAP[currentLanguage];
              if (shopLines.length > 0 && isTTSEnabled && isUserInteracted) {
                const firstShop = shopLines[0];
                const restShops = shopLines.slice(1).join('\n\n');
                firstShopAudioPromise = (async () => {
                  const cleanText = stripMarkdown(firstShop);
                  const response = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: cleanText, language_code: shopLangConfig.tts, voice_name: shopLangConfig.voice }) });
                  const result = await response.json();
                  return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                })();
                if (restShops) {
                  remainingAudioPromise = (async () => {
                    const cleanText = stripMarkdown(restShops);
                    const response = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: cleanText, language_code: shopLangConfig.tts, voice_name: shopLangConfig.voice }) });
                    const result = await response.json();
                    return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                  })();
                }
              }

              if (introPart2Promise) await introPart2Promise;
              if (firstShopAudioPromise) {
                const firstShopAudio = await firstShopAudioPromise;
                if (firstShopAudio) {
                  const firstShopText = stripMarkdown(shopLines[0]);
                  lastAISpeech = normalizeText(firstShopText);
                  stopCurrentAudio(); ttsPlayer.src = firstShopAudio;
                  await new Promise((resolve) => { ttsPlayer.onended = () => { voiceStatus.innerHTML = t('voiceStatusStopped'); voiceStatus.className = 'voice-status stopped'; resolve(); }; voiceStatus.innerHTML = t('voiceStatusSpeaking'); voiceStatus.className = 'voice-status speaking'; ttsPlayer.play(); });
                  if (remainingAudioPromise) {
                    const remainingAudio = await remainingAudioPromise;
                    if (remainingAudio) {
                      const restShopsText = stripMarkdown(shopLines.slice(1).join('\n\n'));
                      lastAISpeech = normalizeText(restShopsText);
                      await new Promise(r => setTimeout(r, 500));
                      stopCurrentAudio(); ttsPlayer.src = remainingAudio;
                      await new Promise((resolve) => { ttsPlayer.onended = () => { voiceStatus.innerHTML = 'ğŸ¤ éŸ³å£°èªè­˜: åœæ­¢ä¸­'; voiceStatus.className = 'voice-status stopped'; resolve(); }; voiceStatus.innerHTML = 'ğŸ”Š éŸ³å£°å†ç”Ÿä¸­...'; voiceStatus.className = 'voice-status speaking'; ttsPlayer.play(); });
                    }
                  }
                }
              }
              isAISpeaking = false;
            } catch (e) { isAISpeaking = false; }
          })();
        } else {
          if (data.response) {
            const extractedShops = extractShopsFromResponse(data.response);
            if (extractedShops.length > 0) {
              currentShops = extractedShops;
              reservationBtn.disabled = false;
              document.dispatchEvent(new CustomEvent('displayShops', { detail: { shops: extractedShops, language: currentLanguage } }));
              const section = document.getElementById('shopListSection');
              if (section) section.classList.add('has-shops');
              speakTextGCP(data.response);
            } else { speakTextGCP(data.response); }
          }
        }
      } catch (error) { console.error('é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
      hideWaitOverlay(); showError('ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚'); }
      finally { isProcessing = false; sendBtn.disabled = false; micBtnFloat.disabled = false;
      userInput.disabled = false; if (currentShops.length === 0) userInput.focus(); else userInput.blur();
      }
    }

    // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
    function openReservationModal() {
      if (currentShops.length === 0) { showError(t('searchError')); return; }
      document.dispatchEvent(new CustomEvent('openReservationModal', { detail: { shops: currentShops } }));
    }

    async function toggleRecording() {
      enableAudioPlayback();
      userInput.value = '';
      stopCurrentAudio();
      if (isRecording) { 
        stopAllActivities();
        return;
      }
      if (isStreamingSTT) { 
        // iOSå¯¾ç­–: é…å»¶(setTimeout)ã‚’å‰Šé™¤ã—ã¦UserGestureã‚’ç¶­æŒ
        await startStreamingSTT(); 
      } else { 
        await startLegacyRecording();
      }
    }

    function toggleTTS() {
      if (!isUserInteracted) { enableAudioPlayback(); return; }
      enableAudioPlayback();
      isTTSEnabled = !isTTSEnabled;
      speakerBtn.innerHTML = isTTSEnabled ? 'ğŸ”Š' : 'ğŸ”‡';
      speakerBtn.title = isTTSEnabled ? t('btnTTSOn') : t('btnTTSOff');
      speakerBtn.className = isTTSEnabled ? 'btn btn-icon btn-speaker' : 'btn btn-icon btn-speaker disabled';
      if (!isTTSEnabled) stopCurrentAudio();
    }

    function stopAllActivities() {
      if (isProcessing) {
        fetch(`${apiBase}/api/cancel`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ session_id: sessionId })
        }).catch(err => console.error('ä¸­æ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—:', err));
      }
      if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
      if (isRecording) stopStreamingSTT();
      stopCurrentAudio();
      waitOverlay.classList.add('hidden');
      if (waitOverlayTimer) { clearTimeout(waitOverlayTimer); waitOverlayTimer = null; }
      isProcessing = false;
      isAISpeaking = false;
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
      userInput.value = '';
      userInput.focus();
      if (window.innerWidth < 1024) {
        setTimeout(() => { chatArea.scrollIntoView({ behavior: 'smooth', block: 'start' }); }, 100);
      }
    }

    // åˆæœŸåŒ–é–¢æ•°
    async function initialize() {
        try {
            const response = await fetch(`${apiBase}/api/session/start`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ user_info: {}, language: currentLanguage }) });
            const data = await response.json(); sessionId = data.session_id;
            addMessage('assistant', t('initialGreeting'), null, true);
            const ackTexts = [t('ackConfirm'), t('ackSearch'), t('ackUnderstood'), t('ackYes'), t('ttsIntro')];
            const langConfig = LANGUAGE_CODE_MAP[currentLanguage];
            const ackPromises = ackTexts.map(async (text) => {
              try {
                const ackResponse = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: text, language_code: langConfig.tts, voice_name: langConfig.voice }) });
                const ackData = await ackResponse.json();
                if (ackData.success && ackData.audio) preGeneratedAcks.set(text, ackData.audio);
              } catch (e) {}
            });
            await Promise.all([speakTextGCP(t('initialGreeting')), ...ackPromises]);
            userInput.disabled = false; sendBtn.disabled = false; micBtnFloat.disabled = false; speakerBtn.disabled = false; userInput.focus();
            if (splashOverlay) hideSplash();
            initializeWebSocketSTT();
            updateUILanguage();
        } catch(e) { console.error(e); }
    }

    // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ç™»éŒ²
    languageSelect.addEventListener('change', () => { currentLanguage = languageSelect.value; updateUILanguage(); });
    sendBtn.addEventListener('click', sendMessage);
    micBtnFloat.addEventListener('click', toggleRecording);
    speakerBtn.addEventListener('click', toggleTTS);
    userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') sendMessage(); });
    reservationBtn.addEventListener('click', openReservationModal);
    // ã‚½ãƒ•ãƒˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æ¤œçŸ¥
    const floatingButtons = document.querySelector('.floating-buttons');
    userInput.addEventListener('focus', () => {
      setTimeout(() => { if (floatingButtons) floatingButtons.classList.add('keyboard-active'); }, 300);
    });
    userInput.addEventListener('blur', () => {
      if (floatingButtons) floatingButtons.classList.remove('keyboard-active');
    });
    stopBtn.addEventListener('click', () => { stopAllActivities(); });
    
    // æœ€å¾Œã«åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
    initialize();
  });
</script>
