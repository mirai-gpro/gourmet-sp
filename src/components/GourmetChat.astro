---
    async function startLegacyRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, sampleRate: 16000, echoCancellation: true, noiseSuppression: true } });
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
        audioChunks = []; hasSpoken = false; recordingStartTime = Date.now();
        
        if (!isIOS) {
          audioContext = new AudioContext();
        } else if (!globalAudioContext) {
          globalAudioContext = new AudioContext({ latencyHint: 'playback' });
        }
        const contextToUse = isIOS ? globalAudioContext : audioContext;
        
        if (!contextToUse) return;
        
        const source = contextToUse.createMediaStreamSource(stream);
        analyser = contextToUse.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        vadCheckInterval = window.setInterval(() => {
          if (!analyser || !isRecording) return;
          if (Date.now() - recordingStartTime < MIN_RECORDING_TIME) return;
          analyser.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
          if (average > SILENCE_THRESHOLD) { hasSpoken = true; if (silenceTimer) clearTimeout(silenceTimer); voiceStatus.innerHTML = t('voiceStatusRecording'); }
          else if (hasSpoken && !silenceTimer) { voiceStatus.innerHTML = t('voiceStatusWaiting'); silenceTimer = window.setTimeout(() => { autoStopRecording(); }, SILENCE_DURATION); }
        }, 100);
        mediaRecorder.ondataavailable = (event) => { if (event.data.size > 0) audioChunks.push(event.data); };
        mediaRecorder.onstop = async () => {
          stopVAD(); stream.getTracks().forEach(track => track.stop());
          if (recordingTimer) clearTimeout(recordingTimer);
          if (audioChunks.length > 0) { const audioBlob = new Blob(audioChunks, { type: 'audio/webm' }); await transcribeAudio(audioBlob); }
        };
        mediaRecorder.start();
        isRecording = true; micBtnFloat.classList.add('recording'); voiceStatus.innerHTML = t('voiceStatusListening');
        recordingTimer = window.setTimeout(() => { if (isRecording && mediaRecorder && mediaRecorder.state === 'recording') { stopVAD(); mediaRecorder.stop(); isRecording = false; micBtnFloat.classList.remove('recording'); addMessage('system', t('recordingTimeLimit')); } }, MAX_RECORDING_TIME);
      } catch (error) { addMessage('system', `${t('micAccessError')} ${(error as Error).message}`); }
    }

    async function transcribeAudio(audioBlob: Blob) {
      try {
        voiceStatus.innerHTML = t('voiceStatusRecognizing');
        voiceStatus.className = 'voice-status';
        const reader = new FileReader();
        reader.readAsDataURL(audioBlob);
        reader.onloadend = async () => {
          const base64Audio = (reader.result as string).split(',')[1];
          const response = await fetch(`${apiBase}/api/stt/transcribe`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ audio: base64Audio, language_code: LANGUAGE_CODE_MAP[currentLanguage].stt }) });
          const data = await response.json();

          if (data.success && data.transcript) {
            const normTranscript = normalizeText(data.transcript);
            if (isSemanticEcho(normTranscript, lastAISpeech)) {
                console.log('[„Ç®„Ç≥„ÉºÊ§úÁü•] ÁÑ°Ë¶ñ:', data.transcript);
                voiceStatus.innerHTML = t('voiceStatusStopped');
                voiceStatus.className = 'voice-status stopped';
                lastAISpeech = '';
                return;
            }

            userInput.value = data.transcript;
            voiceStatus.innerHTML = t('voiceStatusComplete');
            voiceStatus.className = 'voice-status';
            
            addMessage('user', data.transcript);
            // @ts-ignore
            if (i18n[currentLanguage].patterns.dateCheck.test(data.transcript)) {
              const msg = t('dateWarningMsg');
              addMessage('assistant', msg);
              
              const wasRecording = isRecording;
              if (wasRecording) {
                console.log('[Èå≤Èü≥Âà∂Âæ°] AIÈü≥Â£∞ÂÜçÁîü„ÅÆ„Åü„ÇÅ‰∏ÄÊôÇÂÅúÊ≠¢');
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                  mediaRecorder.stop();
                }
                stopStreamingSTT();
                isRecording = false;
                micBtnFloat.classList.remove('recording');
              }
              
              if (isTTSEnabled && isUserInteracted) {
                await speakTextGCP(msg, true, true);  // ‚òÖ autoRestartMic=true
                await new Promise(r => setTimeout(r, 1000));
              } else {
                await new Promise(r => setTimeout(r, 2000));
              }
              
              userInput.value = '';
              voiceStatus.innerHTML = t('voiceStatusStopped');
              voiceStatus.className = 'voice-status stopped';
              return;
            }

            const textLength = data.transcript.trim().replace(/\s+/g, '').length;
            if (textLength < 4) {
                const msg = t('shortMsgWarning');
                addMessage('assistant', msg);
                if (isTTSEnabled && isUserInteracted) {
                  await speakTextGCP(msg, true, true);  // ‚òÖ autoRestartMic=true
                  await new Promise(r => setTimeout(r, 500));
                } else {
                  await new Promise(r => setTimeout(r, 2000));
                }
                userInput.value = '';
                voiceStatus.innerHTML = t('voiceStatusStopped');
                voiceStatus.className = 'voice-status stopped';
                return;
            }

            const ack = selectSmartAcknowledgment(data.transcript);
            const preGeneratedAudio = preGeneratedAcks.get(ack.text);
            let firstAckPromise: Promise<void> | null = null;
            if (preGeneratedAudio && isTTSEnabled && isUserInteracted) {
              firstAckPromise = new Promise<void>((resolve) => {
                lastAISpeech = normalizeText(ack.text);
                ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
                ttsPlayer.onended = () => resolve();
                ttsPlayer.play().catch(e => resolve());
              });
            } else if (isTTSEnabled) { firstAckPromise = speakTextGCP(ack.text, false); }
            addMessage('assistant', ack.text);
            (async () => {
                if (firstAckPromise) await firstAckPromise;
                const cleanText = removeFillers(data.transcript);
                const fallbackResponse = generateFallbackResponse(cleanText);
                if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
                addMessage('assistant', fallbackResponse);
 
                setTimeout(async () => {
                  const additionalResponse = t('additionalResponse');
                  if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
                  addMessage('assistant', additionalResponse);
                }, 3000);
 
                if (userInput.value.trim()) { isFromVoiceInput = true; sendMessage(); }
            })();
            voiceStatus.innerHTML = t('voiceStatusStopped');
            voiceStatus.className = 'voice-status stopped';
          }
        };
      } catch (error) { console.error('STT Error:', error); }
    }

    function initializeWebSocketSTT() {
      try {
        const wsUrl = apiBase || window.location.origin;
        socket = io(wsUrl);
        socket.on('connect', () => { isStreamingSTT = true; });
        socket.on('disconnect', () => { isStreamingSTT = false; });
        socket.on('transcript', (data: any) => {
          const { text, is_final } = data;
          
          if (isAISpeaking) {
            return;
          }
          
          if (is_final) { 
            streamingTranscript = text; 
            handleStreamingSTTComplete(text);
            currentAISpeech = "";
          } else { 
            userInput.value = text;
          }
        });
        socket.on('error', (data: any) => { 
          addMessage('system', `${t('sttError')} ${data.message}`);
          if (isRecording) {
            stopStreamingSTT();
          }
        });
      } catch (error) { isStreamingSTT = false; }
    }

    async function handleStreamingSTTComplete(transcript: string) {
      stopStreamingSTT();
      voiceStatus.innerHTML = t('voiceStatusComplete');
      voiceStatus.className = 'voice-status';

      const normTranscript = normalizeText(transcript);
      if (isSemanticEcho(normTranscript, lastAISpeech)) {
          console.log('[„Ç®„Ç≥„ÉºÊ§úÁü•WS] ÁÑ°Ë¶ñ:', transcript);
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          lastAISpeech = '';
          return;
      }

      userInput.value = transcript;
      // @ts-ignore
      if (i18n[currentLanguage].patterns.dateCheck.test(transcript)) {
        const msg = t('dateWarningMsg');
        currentAISpeech = msg;
        addMessage('assistant', msg);
        
        if (isTTSEnabled && isUserInteracted) {
          await speakTextGCP(msg, true, true);  // ‚òÖ autoRestartMic=true
        } else {
          await new Promise(r => setTimeout(r, 2000));
        }
        
        userInput.value = '';
        voiceStatus.innerHTML = t('voiceStatusStopped');
        voiceStatus.className = 'voice-status stopped';
        return;
      }

      addMessage('user', transcript);
      const textLength = transcript.trim().replace(/\s+/g, '').length;
      if (textLength < 4) {
          const msg = t('shortMsgWarning');
          addMessage('assistant', msg);
          
          isSendingAudio = false;
          if (isTTSEnabled && isUserInteracted) {
            await speakTextGCP(msg, true, true);  // ‚òÖ autoRestartMic=true
          } else {
            await new Promise(r => setTimeout(r, 2000));
          }
          
          isSendingAudio = true;
          userInput.value = '';
          voiceStatus.innerHTML = t('voiceStatusStopped');
          voiceStatus.className = 'voice-status stopped';
          return;
      }

      const ack = selectSmartAcknowledgment(transcript);
      const preGeneratedAudio = preGeneratedAcks.get(ack.text);
      let firstAckPromise: Promise<void> | null = null;
      if (preGeneratedAudio && isTTSEnabled && isUserInteracted) {
        firstAckPromise = new Promise<void>((resolve) => {
          lastAISpeech = normalizeText(ack.text);
          ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
          ttsPlayer.onended = () => resolve();
          ttsPlayer.play().catch(e => resolve());
        });
      } else if (isTTSEnabled) { firstAckPromise = speakTextGCP(ack.text, false); }
      addMessage('assistant', ack.text);

      (async () => {
        try {
          if (firstAckPromise) await firstAckPromise;
          const cleanText = removeFillers(transcript);
          const fallbackResponse = generateFallbackResponse(cleanText);
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
          addMessage('assistant', fallbackResponse);
          setTimeout(async () => {
            const additionalResponse = t('additionalResponse');
            if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
            addMessage('assistant', additionalResponse);
          }, 3000);
          
          if (userInput.value.trim()) {
            isFromVoiceInput = true;
            sendMessage();
          }
        } catch (error) { 
          if (userInput.value.trim()) {
            isFromVoiceInput = true;
            sendMessage();
          }
        }
      })();
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
    }

    async function sendMessage() {
      let firstAckPromise: Promise<void> | null = null; 
      unlockAudioParams();
      const message = userInput.value.trim();
      if (!message || isProcessing) return;
      isProcessing = true; sendBtn.disabled = true;
      micBtnFloat.disabled = true; userInput.disabled = true;

      if (!isFromVoiceInput) {
        addMessage('user', message);
        // @ts-ignore
        if (i18n[currentLanguage].patterns.dateCheck.test(message)) {
             const msg = t('dateWarningMsg');
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             addMessage('assistant', msg);
             userInput.value = ''; isProcessing = false; sendBtn.disabled = false;
             micBtnFloat.disabled = false; userInput.disabled = false; userInput.focus();
             return;
        }
        const textLength = message.trim().replace(/\s+/g, '').length;
        if (textLength < 4) {
             const msg = t('shortMsgWarning');
             addMessage('assistant', msg);
             if (isTTSEnabled && isUserInteracted) await speakTextGCP(msg, true);
             userInput.value = ''; isProcessing = false; sendBtn.disabled = false;
             micBtnFloat.disabled = false; userInput.disabled = false; userInput.focus();
             return;
        }
        userInput.value = '';
        const ack = selectSmartAcknowledgment(message);
        currentAISpeech = ack.text;
        addMessage('assistant', ack.text);
        if (isTTSEnabled) {
          try {
            const preGeneratedAudio = preGeneratedAcks.get(ack.text);
            if (preGeneratedAudio && isUserInteracted) {
              firstAckPromise = new Promise<void>((resolve) => {
                lastAISpeech = normalizeText(ack.text);
                ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedAudio}`;
                ttsPlayer.onended = () => resolve();
                ttsPlayer.play().catch(e => resolve());
              });
            } else { firstAckPromise = speakTextGCP(ack.text, false); }
          } catch (e) {}
        }
        if (firstAckPromise) await firstAckPromise;
        const cleanText = removeFillers(message);
        const fallbackResponse = generateFallbackResponse(cleanText);
        if (isTTSEnabled && isUserInteracted) await speakTextGCP(fallbackResponse, false);
        addMessage('assistant', fallbackResponse);
        setTimeout(async () => {
          const additionalResponse = t('additionalResponse');
          if (isTTSEnabled && isUserInteracted) await speakTextGCP(additionalResponse, false);
          addMessage('assistant', additionalResponse);
        }, 3000);
      }

      const wasVoiceInput = isFromVoiceInput;
      isFromVoiceInput = false;
      if (waitOverlayTimer) clearTimeout(waitOverlayTimer);
      waitOverlayTimer = window.setTimeout(() => { showWaitOverlay(); }, 4000);

      try {
        const response = await fetch(`${apiBase}/api/chat`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ session_id: sessionId, message: message, stage: currentStage, language: currentLanguage }) });
        const data = await response.json();
        hideWaitOverlay();
        
        currentAISpeech = data.response;
        addMessage('assistant', data.response, data.summary);
        stopCurrentAudio();

        if (data.shops && data.shops.length > 0) {
          currentShops = data.shops;
          reservationBtn.disabled = false;
          userInput.value = '';
          document.dispatchEvent(new CustomEvent('displayShops', { detail: { shops: data.shops, language: currentLanguage } }));
          const section = document.getElementById('shopListSection');
          if (section) section.classList.add('has-shops');
          if (window.innerWidth < 1024) {
            setTimeout(() => {
              const shopSection = document.getElementById('shopListSection');
              if (shopSection) {
                shopSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
              }
            }, 300);
          }
          
          (async () => {
            try {
              isAISpeaking = true;
              if (isAndroid && isRecording) {
                stopStreamingSTT();
              }
              
              await speakTextGCP(t('ttsIntro'));
              const lines = data.response.split('\n\n');
              let introText = ""; let shopLines = lines;
              if (lines[0].includes('„ÅîÂ∏åÊúõ„Å´Âêà„ÅÜ„ÅäÂ∫ó') && lines[0].includes('„ÅîÁ¥π‰ªã„Åó„Åæ„Åô')) { introText = lines[0]; shopLines = lines.slice(1); }
              
              let introPart2Promise: Promise<void> | null = null;
              if (introText && isTTSEnabled && isUserInteracted) {
                const preGeneratedIntro = preGeneratedAcks.get(introText);
                if (preGeneratedIntro) {
                  introPart2Promise = new Promise<void>((resolve) => {
                    lastAISpeech = normalizeText(introText);
                    ttsPlayer.src = `data:audio/mp3;base64,${preGeneratedIntro}`;
                    ttsPlayer.onended = () => resolve();
                    ttsPlayer.play();
                  });
                } else { introPart2Promise = speakTextGCP(introText, false); }
              }

              let firstShopAudioPromise: Promise<string | null> | null = null;
              let remainingAudioPromise: Promise<string | null> | null = null;
              const shopLangConfig = LANGUAGE_CODE_MAP[currentLanguage];
              if (shopLines.length > 0 && isTTSEnabled && isUserInteracted) {
                const firstShop = shopLines[0];
                const restShops = shopLines.slice(1).join('\n\n');
                firstShopAudioPromise = (async () => {
                  const cleanText = stripMarkdown(firstShop);
                  const response = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: cleanText, language_code: shopLangConfig.tts, voice_name: shopLangConfig.voice }) });
                  const result = await response.json();
                  return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                })();
                if (restShops) {
                  remainingAudioPromise = (async () => {
                    const cleanText = stripMarkdown(restShops);
                    const response = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: cleanText, language_code: shopLangConfig.tts, voice_name: shopLangConfig.voice }) });
                    const result = await response.json();
                    return result.success ? `data:audio/mp3;base64,${result.audio}` : null;
                  })();
                }
              }

              if (introPart2Promise) await introPart2Promise;
              if (firstShopAudioPromise) {
                const firstShopAudio = await firstShopAudioPromise;
                if (firstShopAudio) {
                  const firstShopText = stripMarkdown(shopLines[0]);
                  lastAISpeech = normalizeText(firstShopText);
                  stopCurrentAudio(); ttsPlayer.src = firstShopAudio;
                  await new Promise<void>((resolve) => { ttsPlayer.onended = () => { voiceStatus.innerHTML = t('voiceStatusStopped'); voiceStatus.className = 'voice-status stopped'; resolve(); }; voiceStatus.innerHTML = t('voiceStatusSpeaking'); voiceStatus.className = 'voice-status speaking'; ttsPlayer.play(); });
                  if (remainingAudioPromise) {
                    const remainingAudio = await remainingAudioPromise;
                    if (remainingAudio) {
                      const restShopsText = stripMarkdown(shopLines.slice(1).join('\n\n'));
                      lastAISpeech = normalizeText(restShopsText);
                      await new Promise(r => setTimeout(r, 500));
                      stopCurrentAudio(); ttsPlayer.src = remainingAudio;
                      await new Promise<void>((resolve) => { ttsPlayer.onended = () => { voiceStatus.innerHTML = '√∞≈∏≈Ω¬§ √©≈∏¬≥√•¬£¬∞√®¬™√®¬≠Àú: √•≈ì√¶¬≠¬¢√§¬∏¬≠'; voiceStatus.className = 'voice-status stopped'; resolve(); }; voiceStatus.innerHTML = '√∞≈∏"≈† √©≈∏¬≥√•¬£¬∞√•‚Ä†√ß"≈∏√§¬∏¬≠...'; voiceStatus.className = 'voice-status speaking'; ttsPlayer.play(); });
                    }
                  }
                }
              }
              isAISpeaking = false;
            } catch (e) { isAISpeaking = false; }
          })();
        } else {
          if (data.response) {
            const extractedShops = extractShopsFromResponse(data.response);
            if (extractedShops.length > 0) {
              currentShops = extractedShops;
              reservationBtn.disabled = false;
              document.dispatchEvent(new CustomEvent('displayShops', { detail: { shops: extractedShops, language: currentLanguage } }));
              const section = document.getElementById('shopListSection');
              if (section) section.classList.add('has-shops');
              speakTextGCP(data.response);
            } else { speakTextGCP(data.response); }
          }
        }
      } catch (error) { console.error('ÈÄÅ‰ø°„Ç®„É©„Éº:', error);
      hideWaitOverlay(); showError('„É°„ÉÉ„Çª„Éº„Ç∏„ÅÆÈÄÅ‰ø°„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ'); }
      finally { isProcessing = false; sendBtn.disabled = false; micBtnFloat.disabled = false;
      userInput.disabled = false; if (currentShops.length === 0) userInput.focus(); else userInput.blur();
      }
    }

    function openReservationModal() {
      if (currentShops.length === 0) { showError(t('searchError')); return; }
      document.dispatchEvent(new CustomEvent('openReservationModal', { detail: { shops: currentShops } }));
    }

    function stopAllActivities() {
      if (isProcessing) {
        fetch(`${apiBase}/api/cancel`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ session_id: sessionId })
        }).catch(err => console.error('‰∏≠Ê≠¢„É™„ÇØ„Ç®„Çπ„ÉàÂ§±Êïó:', err));
      }
      if (recordingTimer) { clearTimeout(recordingTimer); recordingTimer = null; }
      if (isRecording) stopStreamingSTT();
      stopCurrentAudio();
      waitOverlay.classList.add('hidden');
      if (waitOverlayTimer) { clearTimeout(waitOverlayTimer); waitOverlayTimer = null; }
      isProcessing = false;
      isAISpeaking = false;
      voiceStatus.innerHTML = t('voiceStatusStopped');
      voiceStatus.className = 'voice-status stopped';
      userInput.value = '';
      userInput.focus();
      if (window.innerWidth < 1024) {
        setTimeout(() => { chatArea.scrollIntoView({ behavior: 'smooth', block: 'start' }); }, 100);
      }
    }

    async function initialize() {
        try {
            const response = await fetch(`${apiBase}/api/session/start`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ user_info: {}, language: currentLanguage }) });
            const data = await response.json(); sessionId = data.session_id;
            addMessage('assistant', t('initialGreeting'), null, true);
            const ackTexts = [t('ackConfirm'), t('ackSearch'), t('ackUnderstood'), t('ackYes'), t('ttsIntro')];
            const langConfig = LANGUAGE_CODE_MAP[currentLanguage];
            const ackPromises = ackTexts.map(async (text) => {
              try {
                const ackResponse = await fetch(`${apiBase}/api/tts/synthesize`, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ text: text, language_code: langConfig.tts, voice_name: langConfig.voice }) });
                const ackData = await ackResponse.json();
                if (ackData.success && ackData.audio) preGeneratedAcks.set(text, ackData.audio);
              } catch (e) {}
            });
            await Promise.all([speakTextGCP(t('initialGreeting')), ...ackPromises]);
            userInput.disabled = false; sendBtn.disabled = false; micBtnFloat.disabled = false; speakerBtn.disabled = false; userInput.focus();
            if (splashOverlay) hideSplash();
            initializeWebSocketSTT();
            updateUILanguage();
        } catch(e) { console.error(e); }
    }

    languageSelect.addEventListener('change', () => { currentLanguage = languageSelect.value as any; updateUILanguage(); });
    sendBtn.addEventListener('click', sendMessage);
    micBtnFloat.addEventListener('click', toggleRecording);
    speakerBtn.addEventListener('click', toggleTTS);
    userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') sendMessage(); });
    reservationBtn.addEventListener('click', openReservationModal);
    
    const floatingButtons = document.querySelector('.floating-buttons') as HTMLElement;
    userInput.addEventListener('focus', () => {
      setTimeout(() => { if (floatingButtons) floatingButtons.classList.add('keyboard-active'); }, 300);
    });
    userInput.addEventListener('blur', () => {
      if (floatingButtons) floatingButtons.classList.remove('keyboard-active');
    });
    
    stopBtn.addEventListener('click', () => { stopAllActivities(); });
    
    initialize();
  });
</script>// GourmetChat.astro - „Ç∞„É´„É°„Çµ„Éù„Éº„Éà„ÉÅ„É£„ÉÉ„Éà„Ç≥„É≥„Éù„Éº„Éç„É≥„ÉàÔºàÁµ±ÂêàÁâàÔºâ
export interface Props {
  apiBaseUrl?: string;
}

const { apiBaseUrl = '' } = Astro.props;
---

<div class="gourmet-chat-container" data-api-base={apiBaseUrl}>
  <div class="splash-overlay" id="splashOverlay">
    <video id="splashVideo" class="splash-video" autoplay muted playsinline loop>
      <source src="/splash.mp4" type="video/mp4">
    </video>
    <div class="splash-loading"><div class="spinner"></div><p>Ê∫ñÂÇô‰∏≠...</p></div>
  </div>

  <div class="wait-overlay hidden" id="waitOverlay">
    <div class="wait-content">
      <video id="waitVideo" class="wait-video" muted playsinline loop>
        <source src="/wait.mp4" type="video/mp4">
      </video>
      <p class="wait-text">AI„Åå„ÅäÂ∫ó„ÇíÊ§úÁ¥¢„Åó„Å¶„ÅÑ„Åæ„Åô...</p>
    </div>
  </div>

  <div class="language-selector">
    <select id="languageSelect" class="language-dropdown">
      <option value="ja">Êó•Êú¨Ë™û (Japanese)</option>
      <option value="en">English</option>
      <option value="zh">‰∏≠Êñá (Chinese)</option>
      <option value="ko">ÌïúÍµ≠Ïñ¥ (Korean)</option>
    </select>
  </div>

  <div class="voice-status stopped" id="voiceStatus">üé§ Èü≥Â£∞Ë™çË≠ò: ÂÅúÊ≠¢‰∏≠</div>
  <div class="chat-area" id="chatArea"></div>

  <div class="input-area">
    <div class="input-group">
      <input type="text" id="userInput" placeholder="„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂÖ•Âäõ..." disabled />
      <button class="btn btn-icon btn-speaker" id="speakerBtn" title="Èü≥Â£∞Ë™≠„Åø‰∏ä„ÅíON" disabled>üîä</button>
      <button class="btn" id="sendBtn" disabled>ÈÄÅ‰ø°</button>
    </div>
    <div class="input-actions">
      <button class="btn btn-reservation" id="reservationBtn" disabled>üìû ‰∫àÁ¥Ñ‰æùÈ†º„Åô„Çã</button>
    </div>
  </div>
  
  <div class="floating-buttons">
    <button class="btn-floating btn-stop" id="stopBtn" title="‰∏≠Ê≠¢"></button>
    <button class="btn-floating btn-mic-float" id="micBtnFloat" title="Èü≥Â£∞ÂÖ•Âäõ" disabled></button>
  </div>
</div>

<style>
  .gourmet-chat-container { background: white; border-radius: 16px; box-shadow: 0 20px 60px rgba(0,0,0,0.15); width: 100%; max-width: 800px; max-height: 600px; display: flex; flex-direction: column; overflow: hidden; margin: 0 auto; position: relative; }
  .language-selector { padding: 12px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); display: flex; justify-content: flex-end; align-items: center; }
  .language-dropdown { padding: 6px 12px; border: 2px solid white; border-radius: 20px; background: rgba(255,255,255,0.95); color: #667eea; font-size: 13px; font-weight: 600; cursor: pointer; outline: none; transition: all 0.2s; }
  .language-dropdown:hover { background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.15); }
  .language-dropdown:focus { border-color: #fbbf24; }
  .chat-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; text-align: center; }
  .chat-header h2 { font-size: 20px; font-weight: 600; margin: 0 0 4px 0; }
  .chat-header p { font-size: 13px; opacity: 0.9; margin: 0; }
  .voice-status { padding: 10px 15px; text-align: center; font-size: 12px; border-bottom: 1px solid #e0e0e0; font-weight: 500; }
  .voice-status.listening { background: #e8f5e9; color: #2e7d32; animation: pulse 2s infinite; }
  .voice-status.stopped { background: #ffebee; color: #c62828; }
  .voice-status.speaking { background: #e1f5fe; color: #0277bd; animation: pulse 2s infinite; }
  @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.8; } }
  .chat-area { flex: 1; overflow-y: auto; padding: 20px; background: #f7f9fc; min-height: 300px; }
  .message { margin-bottom: 16px; display: flex; gap: 10px; }
  .message.assistant { flex-direction: row; }
  .message.user { flex-direction: row-reverse; }
  .message.system { justify-content: center; }
  .message-avatar { width: 36px; height: 36px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 16px; flex-shrink: 0; }
  .message.assistant .message-avatar { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
  .message.user .message-avatar { background: #e0e7ff; color: #667eea; }
  .message.system .message-avatar { background: #fff3e0; color: #f57c00; }
  .message-content { max-width: 70%; padding: 10px 14px; border-radius: 12px; line-height: 1.5; font-size: 14px; white-space: pre-wrap; }
  .message.assistant .message-content { background: white; border: 1px solid #e5e7eb; color: #1f2937; }
  .message.user .message-content { background: #667eea; color: white; }
  .message.system .message-content { background: #fff3e0; color: #e65100; font-size: 12px; }
  .summary-box { margin-top: 10px; padding: 10px; background: #fef3c7; border-left: 4px solid #f59e0b; border-radius: 8px; font-size: 13px; color: #92400e; }
  .summary-box strong { display: block; margin-bottom: 6px; color: #78350f; }
  .final-summary { margin: 16px 0; padding: 16px; background: white; border: 2px solid #10b981; border-radius: 12px; }
  .final-summary h3 { color: #065f46; margin: 0 0 10px 0; font-size: 16px; }
  .final-summary-content { white-space: pre-wrap; line-height: 1.7; color: #1f2937; font-size: 13px; }
  .input-area { padding: 16px; background: white; border-top: 1px solid #e5e7eb; }
  .input-group { display: flex; gap: 10px; align-items: center; margin-bottom: 10px; }
  #userInput { flex: 1; padding: 10px 14px; border: 2px solid #e5e7eb; border-radius: 20px; font-size: 14px; outline: none; transition: border-color 0.2s; }
  #userInput:focus { border-color: #667eea; }
  .btn { padding: 10px 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 20px; font-size: 14px; font-weight: 600; cursor: pointer; transition: transform 0.2s, box-shadow 0.2s; }
  .btn:hover:not(:disabled) { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4); }
  .btn:disabled { opacity: 0.5; cursor: not-allowed; }
  .btn-reservation { background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; font-size: 13px; padding: 10px 16px; font-weight: 600; box-shadow: 0 4px 12px rgba(245, 158, 11, 0.3); }
  .btn-reservation:hover:not(:disabled) { box-shadow: 0 6px 16px rgba(245, 158, 11, 0.4); transform: translateY(-1px); }
  .btn-reservation:disabled { opacity: 0.5; cursor: not-allowed; }
  .btn-icon { padding: 10px; width: 40px; height: 40px; display: flex; align-items: center; justify-content: center; }
  .btn-mic { background: #10b981; }
  .btn-mic:hover:not(:disabled) { box-shadow: 0 4px 12px rgba(16, 185, 129, 0.4); }
  .btn-mic.recording { background: #ef4444; animation: pulse-btn 1.5s infinite; }
  @keyframes pulse-btn { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }
  .btn-speaker { background: #f59e0b; }
  .btn-speaker:hover:not(:disabled) { box-shadow: 0 4px 12px rgba(245, 158, 11, 0.4); }
  .btn-speaker.disabled { background: #9ca3af; }
  .input-actions { display: flex; justify-content: flex-end; }
  .loading { display: inline-block; width: 20px; height: 20px; border: 3px solid #e5e7eb; border-radius: 50%; border-top-color: #667eea; animation: spin 1s ease-in-out infinite; }
  @keyframes spin { to { transform: rotate(360deg); } }
  .error-message { background: #fee2e2; color: #b91c1c; padding: 10px; border-radius: 8px; margin: 10px 0; font-size: 13px; text-align: center; }
  .splash-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; justify-content: center; z-index: 9999; border-radius: 16px; overflow: hidden; transition: opacity 0.8s ease-out; pointer-events: all; }
  .splash-overlay.fade-out { opacity: 0; pointer-events: none; }
  .splash-overlay.hidden { display: none; }
  .splash-video { width: 100%; height: 100%; object-fit: contain; position: absolute; top: 0; left: 0; transform: scale(0.5); }
  .splash-loading { position: absolute; bottom: 60px; display: flex; flex-direction: column; align-items: center; gap: 12px; z-index: 1; }
  .splash-loading .spinner { width: 40px; height: 40px; border: 4px solid rgba(102, 126, 234, 0.3); border-top-color: #667eea; border-radius: 50%; animation: spin 1s linear infinite; }
  .splash-loading p { color: #667eea; font-size: 14px; font-weight: 600; margin: 0; text-shadow: 0 1px 2px rgba(255, 255, 255, 0.8); }
  .click-prompt { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); background: rgba(0, 0, 0, 0.8); color: white; padding: 20px; border-radius: 12px; text-align: center; z-index: 100; cursor: pointer; }
  .click-prompt p { margin: 5px 0; }
  .wait-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: rgba(255, 255, 255, 0.95); z-index: 500; display: flex; align-items: center; justify-content: center; border-radius: 16px; opacity: 1; transition: opacity 0.5s ease-out, visibility 0.5s; }
  .wait-overlay.hidden { opacity: 0; visibility: hidden; pointer-events: none; }
  .wait-content { text-align: center; width: 80%; max-width: 400px; }
  .wait-video { width: 100%; border-radius: 12px; box-shadow: 0 8px 30px rgba(0,0,0,0.1); margin-bottom: 16px; }
  .wait-text { color: #667eea; font-weight: 600; font-size: 14px; animation: pulse 1.5s infinite; }
  
  .floating-buttons {
    position: fixed;
    bottom: 20px;
    right: 20px;
    display: flex;
    gap: 12px;
    z-index: 1000;
    transition: bottom 0.3s ease;
  }
  
  .floating-buttons.keyboard-active {
    bottom: 320px;
  }
  
  @media (max-width: 768px) {
    .floating-buttons.keyboard-active {
      bottom: 280px;
    }
  }
  
  .btn-floating {
    width: 56px;
    height: 56px;
    border-radius: 50%;
    border: none;
    font-size: 24px;
    cursor: pointer;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    transition: transform 0.2s, box-shadow 0.2s;
  }
  
  .btn-floating:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
  }
  
  .btn-floating:active {
    transform: translateY(0);
  }
  
  .btn-stop {
    background: linear-gradient(135deg, #ff3b30 0%, #d32f2f 100%);
    color: white;
    position: relative;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  
  .btn-stop::before {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    background: url('/stop.svg') center/60% no-repeat;
  }
  
  .btn-mic-float {
    background: transparent;
    color: white;
    position: relative;
    display: flex;
    align-items: center;
    justify-content: center;
    overflow: visible;
    box-shadow: none;
  }
  
  .btn-mic-float::before {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    background: url('/mic-off.svg') center/100% no-repeat;
  }
  
  .btn-mic-float:disabled {
    cursor: not-allowed;
    opacity: 0.6;
  }
  
  .btn-mic-float:disabled::before {
    opacity: 0.5;
  }
  
  .btn-mic-float.recording {
    background: transparent;
  }
  
  .btn-mic-float.recording::before {
    background: url('/mic-on.svg') center/100% no-repeat;
  }
  
  .btn-mic-float.recording::after {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    border-radius: 50%;
    border: 3px solid #42A5F5;
    opacity: 0;
    animation: ripple 1.5s ease-out infinite;
  }
  
  @keyframes ripple {
    0% {
      transform: scale(1);
      opacity: 0.8;
    }
    100% {
      transform: scale(1.8);
      opacity: 0;
    }
  }
</style>

<script src="https://cdn.socket.io/4.7.2/socket.io.min.js"></script>

<script>
  import { i18n } from '../constants/i18n';
  const LANGUAGE_CODE_MAP = {
    ja: { tts: 'ja-JP', stt: 'ja-JP', voice: 'ja-JP-Chirp3-HD-Leda' },
    en: { tts: 'en-US', stt: 'en-US', voice: 'en-US-Studio-O' },
    zh: { tts: 'cmn-CN', stt: 'cmn-CN', voice: 'cmn-CN-Wavenet-A' },
    ko: { tts: 'ko-KR', stt: 'ko-KR', voice: 'ko-KR-Wavenet-A' }
  };
  document.addEventListener('DOMContentLoaded', () => {
    const container = document.querySelector('.gourmet-chat-container') as HTMLElement;
    if (!container) return;

    const apiBase = container.dataset.apiBase || '';

    // „Çπ„Éó„É©„ÉÉ„Ç∑„É•Âà∂Âæ°
    const splashOverlay = document.getElementById('splashOverlay') as HTMLDivElement;
    const splashVideo = document.getElementById('splashVideo') as HTMLVideoElement;
    function hideSplash() {
      splashVideo.loop = false;
      splashOverlay.classList.add('fade-out');
      setTimeout(() => splashOverlay.classList.add('hidden'), 800);
    }
    setTimeout(() => hideSplash(), 10000);

    // DOMË¶ÅÁ¥†
    const chatArea = document.getElementById('chatArea')!;
    const userInput = document.getElementById('userInput') as HTMLInputElement;
    const sendBtn = document.getElementById('sendBtn') as HTMLButtonElement;
    const speakerBtn = document.getElementById('speakerBtn') as HTMLButtonElement;
    const reservationBtn = document.getElementById('reservationBtn') as HTMLButtonElement;
    const voiceStatus = document.getElementById('voiceStatus')!;
    const languageSelect = document.getElementById('languageSelect') as HTMLSelectElement;
    const stopBtn = document.getElementById('stopBtn') as HTMLButtonElement;
    const micBtnFloat = document.getElementById('micBtnFloat') as HTMLButtonElement;
    const waitOverlay = document.getElementById('waitOverlay') as HTMLDivElement;
    const waitVideo = document.getElementById('waitVideo') as HTMLVideoElement;
    let waitOverlayTimer: number | null = null;

    // Áä∂ÊÖãÂ§âÊï∞
    let currentLanguage: 'ja' | 'en' | 'zh' | 'ko' = 'ja';
    let sessionId: string | null = null;
    let isProcessing = false;
    let currentStage = 'conversation';
    let isRecording = false;
    let mediaRecorder: MediaRecorder | null = null;
    let audioChunks: Blob[] = [];
    let recordingTimer: number | null = null;
    const MAX_RECORDING_TIME = 55000;
    let isTTSEnabled = true;
    let isUserInteracted = false;
    let currentShops: any[] = [];
    let isFromVoiceInput = false;
    
    let lastAISpeech: string = '';
    let preGeneratedAcks: Map<string, string> = new Map();
    let audioContext: AudioContext | null = null;
    let analyser: AnalyserNode | null = null;
    let silenceTimer: number | null = null;
    let vadCheckInterval: number | null = null;
    let hasSpoken = false;
    let recordingStartTime = 0;
    let socket: any = null;
    let audioWorkletNode: AudioWorkletNode | null = null;
    let streamingTranscript = '';
    let isStreamingSTT = false;
    let isSendingAudio = true;

    const ttsPlayer = new Audio();
    const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);
    const isAndroid = /Android/i.test(navigator.userAgent);
    
    // ‚òÖ „Éá„Éê„Ç§„ÇπÂà•„ÅÆË®≠ÂÆö
    const SILENCE_THRESHOLD = isIOS ? 30 : 35;
    const SILENCE_DURATION = isIOS ? 2500 : 2000;
    const MIN_RECORDING_TIME = 3000;
    
    let mediaStream: MediaStream | null = null;
    let isAISpeaking = false;
    let currentAISpeech = "";
    
    // ‚òÖ iPhoneÁî®: „Ç∞„É≠„Éº„Éê„É´AudioContextÔºà„Ç∑„É≥„Ç∞„É´„Éà„É≥ÂåñÔºâ
    let globalAudioContext: AudioContext | null = null;

    function debugLog(message: string) {
      const debugDiv = document.getElementById('debugLog') || (() => {
        const div = document.createElement('div');
        div.id = 'debugLog';
        div.style.cssText = 'position: fixed; top: 0; left: 0; right: 0; background: rgba(0,0,0,0.9); color: lime; padding: 10px; max-height: 200px; overflow-y: auto; z-index: 99999; font-size: 11px; font-family: monospace;';
        document.body.appendChild(div);
        return div;
      })();
      const time = new Date().toLocaleTimeString();
      debugDiv.innerHTML = `[${time}] ${message}<br>` + debugDiv.innerHTML;
    }

    // --- ‰æøÂà©Èñ¢Êï∞Áæ§ ---

    function t(key: string, ...args: any[]): string {
      // @ts-ignore
      const translation = i18n[currentLanguage][key];
      if (typeof translation === 'function') return translation(...args);
      return translation || key;
    }

    (window as any).gourmetI18n = {
      i18n: i18n,
      getCurrentLanguage: () => currentLanguage,
      t: (key: string, ...args: any[]) => t(key, ...args)
    };
    
    function addMessage(role: string, content: string, summary: string | null = null, isInitial: boolean = false) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${role}`;
      if (isInitial) messageDiv.setAttribute('data-initial', 'true');
      const avatar = document.createElement('div');
      avatar.className = 'message-avatar';
      avatar.innerHTML = role === 'assistant' ? 'üçΩ' : role === 'user' ? 'üë§' : '‚ö†';
      const contentDiv = document.createElement('div');
      contentDiv.className = 'message-content';
      const messageText = document.createElement('span');
      messageText.className = 'message-text';
      messageText.textContent = content;
      contentDiv.appendChild(messageText);
      messageDiv.appendChild(avatar);
      const wrapper = document.createElement('div');
      wrapper.appendChild(contentDiv);
      if (summary) {
        const summaryDiv = document.createElement('div');
        summaryDiv.className = 'summary-box';
        summaryDiv.innerHTML = `<strong>üìù ÂÜÖÂÆπÁ¢∫Ë™ç</strong>${summary}`;
        wrapper.appendChild(summaryDiv);
      }
      messageDiv.appendChild(wrapper);
      chatArea.appendChild(messageDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showError(message: string) {
      const errorDiv = document.createElement('div');
      errorDiv.className = 'error-message';
      errorDiv.textContent = message;
      chatArea.appendChild(errorDiv);
      chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showWaitOverlay() {
      waitOverlay.classList.remove('hidden');
      waitVideo.currentTime = 0;
      waitVideo.play().catch(e => console.log('Video err', e));
    }

    function hideWaitOverlay() {
      if (waitOverlayTimer) { clearTimeout(waitOverlayTimer); waitOverlayTimer = null; }
      waitOverlay.classList.add('hidden');
      setTimeout(() => waitVideo.pause(), 500);
    }

    function unlockAudioParams() {
      ttsPlayer.play().then(() => { ttsPlayer.pause(); ttsPlayer.currentTime = 0; }).catch(e => {});
      // ‚òÖ iPhone: „Ç∞„É≠„Éº„Éê„É´AudioContext„ÅÆ„É¨„Ç∏„É•„Éº„É†
      if (isIOS && globalAudioContext && globalAudioContext.state === 'suspended') {
        globalAudioContext.resume();
      }
    }

    function enableAudioPlayback() {
      if (!isUserInteracted) {
        isUserInteracted = true;
        const clickPrompt = container.querySelector('.click-prompt');
        if (clickPrompt) clickPrompt.remove();
        unlockAudioParams();
      }
    }

    function showClickPrompt() {
      const prompt = document.createElement('div');
      prompt.className = 'click-prompt';
      prompt.innerHTML = `<p>üîä</p><p>${t('clickPrompt')}</p><p>üîä</p>`;
      prompt.addEventListener('click', enableAudioPlayback);
      container.style.position = 'relative';
      container.appendChild(prompt);
    }

    function stopCurrentAudio() {
      ttsPlayer.pause();
      ttsPlayer.currentTime = 0;
    }

    function stripMarkdown(text: string): string {
      return text.replace(/\*\*([^*]+)\*\*/g, '$1').replace(/\*([^*]+)\*/g, '$1').replace(/__([^_]+)__/g, '$1').replace(/_([^_]+)_/g, '$1').replace(/^#+\s*/gm, '').replace(/\[([^\]]+)\]\([^)]+\)/g, '$1').replace(/`([^`]+)`/g, '$1').replace(/^(\d+)\.\s+/gm, '$1Áï™ÁõÆ„ÄÅ').replace(/\s+/g, ' ').trim();
    }

    function normalizeText(text: string): string {
      return text.replace(/[!?,.„ÄÅ„ÄÇ\s√£‚Ç¨‚Ç¨]/g, '').toLowerCase().trim();
    }

    function removeFillers(text: string): string {
      // @ts-ignore
      const pattern = i18n[currentLanguage].patterns.fillers;
      return text.replace(pattern, '');
    }

    function generateFallbackResponse(text: string): string {
      return t('fallbackResponse', text);
    }

    function selectSmartAcknowledgment(userMessage: string): { text: string, logText: string } {
      const messageLower = userMessage.trim();
      // @ts-ignore
      const p = i18n[currentLanguage].patterns;
      if (p.ackQuestions.test(messageLower)) return { text: t('ackConfirm'), logText: `Ë≥™ÂïèÂΩ¢Âºè` };
      if (p.ackLocation.test(messageLower)) return { text: t('ackSearch'), logText: `Â†¥ÊâÄ` };
      if (p.ackSearch.test(messageLower)) return { text: t('ackUnderstood'), logText: `Ê§úÁ¥¢` };
      return { text: t('ackYes'), logText: `„Éá„Éï„Ç©„É´„Éà` };
    }

    function extractShopsFromResponse(text: string): any[] {
      const shops: any[] = [];
      const pattern = /(\d+)\.\s*\*\*([^*]+)\*\*[√Ø¬º≈°:]\s*([^\n]+)/g;
      let match;
      while ((match = pattern.exec(text)) !== null) {
        const fullName = match[2].trim();
        const description = match[3].trim();
        let name = fullName;
        const nameMatch = fullName.match(/^([^√Ø¬ºÀÜ(]+)[√Ø¬ºÀÜ(]([^√Ø¬º‚Ä∞)]+)[√Ø¬º‚Ä∞)]/);
        if (nameMatch) name = nameMatch[1].trim();
        const encodedName = encodeURIComponent(name);
        shops.push({ name: name, description: description, category: '„Ç§„Çø„É™„Ç¢„É≥', hotpepper_url: `https://www.hotpepper.jp/SA11/srchRS/?keyword=${encodedName}`, maps_url: `https://www.google.com/maps/search/${encodedName}`, tabelog_url: `https://tabelog.com/rstLst/?vs=1&sa=&sk=${encodedName}` });
      }
      return shops;
    }

    function updateUILanguage() {
      voiceStatus.innerHTML = t('voiceStatusStopped');
      userInput.placeholder = t('inputPlaceholder');
      micBtnFloat.title = t('btnVoiceInput');
      speakerBtn.title = isTTSEnabled ? t('btnTTSOn') : t('btnTTSOff');
      sendBtn.textContent = t('btnSend');
      reservationBtn.innerHTML = t('btnReservation');
      const waitText = document.querySelector('.wait-text');
      if (waitText) waitText.textContent = t('waitMessage');

      const pageTitle = document.getElementById('pageTitle');
      if (pageTitle) pageTitle.innerHTML = `<img src="/pwa-152x152.png" alt="Logo" class="app-logo" /> ${t('pageTitle')}`;
      const pageSubtitle = document.getElementById('pageSubtitle');
      if (pageSubtitle) pageSubtitle.textContent = t('pageSubtitle');
      const shopListTitle = document.getElementById('shopListTitle');
      if (shopListTitle) shopListTitle.innerHTML = `üçΩ ${t('shopListTitle')}`;
      const shopListEmpty = document.getElementById('shopListEmpty');
      if (shopListEmpty) shopListEmpty.textContent = t('shopListEmpty');
      const pageFooter = document.getElementById('pageFooter');
      if (pageFooter) pageFooter.innerHTML = `${t('footerMessage')} ‚ú®`;

      const initialMessage = chatArea.querySelector('.message.assistant[data-initial="true"]');
      if (initialMessage) {
        const messageText = initialMessage.querySelector('.message-text');
        if (messageText) messageText.textContent = t('initialGreeting');
      }
